[2022-03-10 01:10:56] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:10:56] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:10:56] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:10:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:36451/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:10:57] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:36451 (connectionpool.py:232)
[2022-03-10 01:10:57] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:36451 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:10:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:10:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:36451/session/be8caa671b296129a31506b8857c9ab9/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:10:57] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:36451 "POST /session/be8caa671b296129a31506b8857c9ab9/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:10:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:10:57] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:10:57] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:10:57] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:10:57] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:10:57] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:10:57] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:10:57] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:10:57] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:10:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43773/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:10:58] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:43773 (connectionpool.py:232)
[2022-03-10 01:10:59] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43773 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:10:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:10:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43773/session/71cf0d0478bb4d316b966c33ce5365e4/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:10:59] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43773 "POST /session/71cf0d0478bb4d316b966c33ce5365e4/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:10:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:10:59] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:10:59] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:10:59] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:10:59] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:10:59] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:10:59] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:10:59] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:10:59] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38251/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:00] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:38251 (connectionpool.py:232)
[2022-03-10 01:11:00] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38251 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38251/session/41c88dbc38b32ea7373cef0ef5b3cd80/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:00] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38251 "POST /session/41c88dbc38b32ea7373cef0ef5b3cd80/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:00] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:00] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:00] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:00] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:00] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:00] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:00] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:00] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:01] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:52849/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:01] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:52849 (connectionpool.py:232)
[2022-03-10 01:11:01] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:52849 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:01] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:01] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:52849/session/0f1c829ad1ece979a1a58a852cbbd8d2/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:01] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:52849 "POST /session/0f1c829ad1ece979a1a58a852cbbd8d2/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:01] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:01] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:01] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:01] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:01] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:01] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:01] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:01] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:01] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:39819/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:02] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:39819 (connectionpool.py:232)
[2022-03-10 01:11:02] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:39819 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:39819/session/6ace6cdb9605d0e2359c120d01af7149/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:02] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:39819 "POST /session/6ace6cdb9605d0e2359c120d01af7149/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:02] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:02] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:02] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:02] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:02] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:02] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:02] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:02] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45901/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:03] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:45901 (connectionpool.py:232)
[2022-03-10 01:11:03] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45901 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45901/session/318f8e300b4fe88cb6d851f8e1b6fdb8/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:03] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45901 "POST /session/318f8e300b4fe88cb6d851f8e1b6fdb8/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:03] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:03] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:03] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:03] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:03] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:03] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:03] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:03] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:04] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:55065/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:04] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:55065 (connectionpool.py:232)
[2022-03-10 01:11:04] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:55065 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:04] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:04] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:55065/session/f21e0ee4467c7cac89de0e4ad9af8aa8/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:04] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:55065 "POST /session/f21e0ee4467c7cac89de0e4ad9af8aa8/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:04] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:04] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:04] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:04] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:04] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:04] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:04] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:04] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:04] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:05] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:56159/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:05] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:56159 (connectionpool.py:232)
[2022-03-10 01:11:05] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:56159 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:05] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:05] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:56159/session/2bd99921f1968a72b0df98e202be7fad/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:05] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:56159 "POST /session/2bd99921f1968a72b0df98e202be7fad/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:05] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:05] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:05] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:05] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:05] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:05] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:05] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:05] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:05] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59351/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:06] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:59351 (connectionpool.py:232)
[2022-03-10 01:11:06] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59351 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59351/session/86da56dd386919d1444ed611aec7c9dc/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:06] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59351 "POST /session/86da56dd386919d1444ed611aec7c9dc/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:06] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:06] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:06] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:06] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:06] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:06] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:06] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:06] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:07] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:56709/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:07] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:56709 (connectionpool.py:232)
[2022-03-10 01:11:08] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:56709 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:56709/session/8d4d9215ef97bdddea556a62ecb75c75/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:08] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:56709 "POST /session/8d4d9215ef97bdddea556a62ecb75c75/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:08] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:08] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:08] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:08] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:08] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:08] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:08] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:08] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45605/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:09] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:45605 (connectionpool.py:232)
[2022-03-10 01:11:09] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45605 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45605/session/68e21dc9392b38aafdce3dc6c95a10fb/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:09] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45605 "POST /session/68e21dc9392b38aafdce3dc6c95a10fb/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:09] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:09] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:09] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:09] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:09] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:09] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:09] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:09] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:37827/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:10] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:37827 (connectionpool.py:232)
[2022-03-10 01:11:10] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:37827 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:37827/session/8588c25fde9657bd955a9fc135d14792/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:10] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:37827 "POST /session/8588c25fde9657bd955a9fc135d14792/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:10] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:10] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:10] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:10] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:10] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:10] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:10] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:10] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45019/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:11] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:45019 (connectionpool.py:232)
[2022-03-10 01:11:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45019 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45019/session/019d17def69d7c46f3ab4b99e7cb1f14/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45019 "POST /session/019d17def69d7c46f3ab4b99e7cb1f14/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:11] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:11] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:11] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:11] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:11] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:11] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:11] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:11] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:53363/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:12] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:53363 (connectionpool.py:232)
[2022-03-10 01:11:12] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:53363 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:53363/session/c7eac1d5d458301e1a6f6494f688ab42/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:12] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:53363 "POST /session/c7eac1d5d458301e1a6f6494f688ab42/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:12] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:12] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:12] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:12] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:12] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:12] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:12] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:12] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47751/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:13] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:47751 (connectionpool.py:232)
[2022-03-10 01:11:13] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47751 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47751/session/3055e92adea33caceaa39a57c9c8d7e1/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:13] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47751 "POST /session/3055e92adea33caceaa39a57c9c8d7e1/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:13] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:13] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:13] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:13] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:13] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:13] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:13] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:13] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42727/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:14] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:42727 (connectionpool.py:232)
[2022-03-10 01:11:14] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42727 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42727/session/c610558cce21a3b4199c92bcb7daf306/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:14] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42727 "POST /session/c610558cce21a3b4199c92bcb7daf306/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:14] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:14] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:14] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:14] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:14] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:14] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:14] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:14] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:15] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42117/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:15] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:42117 (connectionpool.py:232)
[2022-03-10 01:11:16] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42117 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:16] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:16] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42117/session/5d9dad5f4c7abf09a894119539c59829/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:16] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42117 "POST /session/5d9dad5f4c7abf09a894119539c59829/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:16] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:16] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57031/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:17] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:57031 (connectionpool.py:232)
[2022-03-10 01:11:17] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57031 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57031/session/5250f6b92002e3867f46dae4ce90a5d7/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:17] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57031 "POST /session/5250f6b92002e3867f46dae4ce90a5d7/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:17] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:17] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:17] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:17] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:17] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:17] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:17] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:17] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38637/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:18] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:38637 (connectionpool.py:232)
[2022-03-10 01:11:18] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38637 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38637/session/12261a41d9dc6de824aed775ff8d7a63/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:18] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38637 "POST /session/12261a41d9dc6de824aed775ff8d7a63/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:18] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:18] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:18] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:18] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:18] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:18] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:18] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:18] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:41433/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:19] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:41433 (connectionpool.py:232)
[2022-03-10 01:11:19] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:41433 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:41433/session/63898e308ae07525e85975bd7e03513b/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:19] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:41433 "POST /session/63898e308ae07525e85975bd7e03513b/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:19] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:19] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:19] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:19] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:19] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:19] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:19] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:19] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:20] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:53529/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:20] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:53529 (connectionpool.py:232)
[2022-03-10 01:11:20] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:53529 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:20] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:20] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:53529/session/d6e870f9124ade51e03ff5054cdf9e92/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:20] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:53529 "POST /session/d6e870f9124ade51e03ff5054cdf9e92/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:20] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:20] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:20] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:20] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:20] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:20] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:20] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:20] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:20] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:21] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:51927/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:21] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:51927 (connectionpool.py:232)
[2022-03-10 01:11:21] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:51927 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:21] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:21] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:51927/session/98968a04051b2b8433fc5fbaf57f4b5c/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:21] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:51927 "POST /session/98968a04051b2b8433fc5fbaf57f4b5c/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:21] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:21] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:22] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54863/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:22] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:54863 (connectionpool.py:232)
[2022-03-10 01:11:22] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54863 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:22] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:22] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54863/session/19e2080c565bdd9e205da31b8abc04a7/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:22] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54863 "POST /session/19e2080c565bdd9e205da31b8abc04a7/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:22] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:22] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42695/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:23] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:42695 (connectionpool.py:232)
[2022-03-10 01:11:25] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42695 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42695/session/a08a4f422f340d03bf93d427c50c3748/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:25] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42695 "POST /session/a08a4f422f340d03bf93d427c50c3748/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:25] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:25] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:25] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:25] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:25] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:25] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:25] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:25] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:37273/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:26] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:37273 (connectionpool.py:232)
[2022-03-10 01:11:26] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:37273 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:37273/session/7c579c6354b7b5f25ab86a2817e23fe8/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:26] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:37273 "POST /session/7c579c6354b7b5f25ab86a2817e23fe8/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:26] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:26] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:26] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:26] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:26] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:26] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:26] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47391/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:27] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:47391 (connectionpool.py:232)
[2022-03-10 01:11:30] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47391 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:30] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:30] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47391/session/d10847447af5b1b18fe5af46fd2ff372/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:30] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47391 "POST /session/d10847447af5b1b18fe5af46fd2ff372/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:30] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:30] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:30] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:30] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:30] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:30] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:30] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:31] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:31] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:32] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43617/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:32] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:43617 (connectionpool.py:232)
[2022-03-10 01:11:34] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43617 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43617/session/670e03332768430fb068259a3e933567/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:34] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43617 "POST /session/670e03332768430fb068259a3e933567/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:34] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:34] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:34] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:34] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:34] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:34] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:34] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:34] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:35] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54045/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:35] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:54045 (connectionpool.py:232)
[2022-03-10 01:11:37] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54045 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:37] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:37] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54045/session/166fe1a27332afb6d160b360a263616b/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:37] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54045 "POST /session/166fe1a27332afb6d160b360a263616b/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:37] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:37] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:37] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:37] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:37] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:37] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:37] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:37] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:37] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:38] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:37423/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:38] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:37423 (connectionpool.py:232)
[2022-03-10 01:11:41] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:37423 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:37423/session/59582785ea8d4bd643a208730df9d50f/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:41] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:37423 "POST /session/59582785ea8d4bd643a208730df9d50f/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:41] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:41] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:41] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:41] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:41] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:41] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:41] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:41] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57009/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:42] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:57009 (connectionpool.py:232)
[2022-03-10 01:11:47] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57009 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57009/session/2b54eb57acfbf99102092583ca339af0/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:47] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57009 "POST /session/2b54eb57acfbf99102092583ca339af0/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:47] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43669/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:48] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:43669 (connectionpool.py:232)
[2022-03-10 01:11:49] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43669 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43669/session/50c2832a483b7a2af0fb1d90bdfa7312/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:49] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43669 "POST /session/50c2832a483b7a2af0fb1d90bdfa7312/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:49] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:49] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:49] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:49] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:49] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:49] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:49] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:49] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47435/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:50] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:47435 (connectionpool.py:232)
[2022-03-10 01:11:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47435 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47435/session/49cb352b983ba4da0cb54c2954a44791/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47435 "POST /session/49cb352b983ba4da0cb54c2954a44791/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:51] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:51] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:51] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:51] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:51] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:51] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:51] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:51] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:52] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50087/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:52] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:50087 (connectionpool.py:232)
[2022-03-10 01:11:52] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50087 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:52] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:52] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50087/session/18e4c87d297c1328f488a5fe0673cdea/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:52] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50087 "POST /session/18e4c87d297c1328f488a5fe0673cdea/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:52] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:52] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:52] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:52] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:52] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:52] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:52] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:52] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:52] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:49797/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:53] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:49797 (connectionpool.py:232)
[2022-03-10 01:11:53] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:49797 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:49797/session/8ae743414c6901caeb6d59004f814487/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:53] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:49797 "POST /session/8ae743414c6901caeb6d59004f814487/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:53] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:53] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:53] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:53] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:53] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:53] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:53] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:53] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42341/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:54] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:42341 (connectionpool.py:232)
[2022-03-10 01:11:54] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42341 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42341/session/7059b40025b212d44cce3e0263fbbd71/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:54] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42341 "POST /session/7059b40025b212d44cce3e0263fbbd71/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:54] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:54] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:54] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:54] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:54] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:54] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:54] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:54] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43973/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:55] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:43973 (connectionpool.py:232)
[2022-03-10 01:11:56] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43973 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43973/session/bef2cddcc2e500a6131fadc82e1b395f/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:56] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43973 "POST /session/bef2cddcc2e500a6131fadc82e1b395f/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:56] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:56] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:56] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:56] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:56] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:56] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:56] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:56] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34515/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:57] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:34515 (connectionpool.py:232)
[2022-03-10 01:11:58] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34515 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:11:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34515/session/c07e6bd219318bd314718f3c634ab80b/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:11:58] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34515 "POST /session/c07e6bd219318bd314718f3c634ab80b/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:11:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:11:58] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:11:58] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:11:58] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:11:58] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:11:58] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:11:58] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:11:58] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:11:58] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:11:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:39047/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:11:59] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:39047 (connectionpool.py:232)
[2022-03-10 01:12:00] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:39047 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:39047/session/4a94baf68905ebb6ba357780f4fdac09/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:00] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:39047 "POST /session/4a94baf68905ebb6ba357780f4fdac09/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:00] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:00] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:00] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:00] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:00] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:00] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:00] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:00] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:01] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43139/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:01] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:43139 (connectionpool.py:232)
[2022-03-10 01:12:01] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43139 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:01] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:01] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43139/session/073d6c33988d3577276a16f2eb30ed74/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:01] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43139 "POST /session/073d6c33988d3577276a16f2eb30ed74/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:01] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:01] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:01] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:01] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:01] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:01] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:01] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:01] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:01] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54185/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:02] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:54185 (connectionpool.py:232)
[2022-03-10 01:12:02] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54185 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54185/session/bdf61e8707da8f40f853ccb01033b0c7/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:02] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54185 "POST /session/bdf61e8707da8f40f853ccb01033b0c7/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:02] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:02] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:02] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:02] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:02] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:02] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:03] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:03] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:04] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:36963/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:04] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:36963 (connectionpool.py:232)
[2022-03-10 01:12:05] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:36963 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:05] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:05] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:36963/session/a0daad6f01443279c37a664042b07a20/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:05] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:36963 "POST /session/a0daad6f01443279c37a664042b07a20/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:05] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:05] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:05] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:05] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:05] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:05] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:05] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:05] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:05] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:51565/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:06] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:51565 (connectionpool.py:232)
[2022-03-10 01:12:07] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:51565 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:07] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:07] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:51565/session/f3b8b29e25ba8ae767b3293b6b045d3b/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:07] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:51565 "POST /session/f3b8b29e25ba8ae767b3293b6b045d3b/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:07] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:07] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:07] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:07] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:07] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:44789/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:09] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:44789 (connectionpool.py:232)
[2022-03-10 01:12:09] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:44789 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:44789/session/e1a8247ef0c085c62f3c976d19ee029b/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:09] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:44789 "POST /session/e1a8247ef0c085c62f3c976d19ee029b/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:09] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:09] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:09] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:09] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:09] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:09] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:09] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:09] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57593/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:11] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:57593 (connectionpool.py:232)
[2022-03-10 01:12:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57593 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57593/session/5a0439652d735043987e6faa78265971/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57593 "POST /session/5a0439652d735043987e6faa78265971/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:11] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:11] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:11] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:11] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:11] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:11] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:11] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:11] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43559/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:12] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:43559 (connectionpool.py:232)
[2022-03-10 01:12:13] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43559 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43559/session/0ad591e5e3f834c24a4c84d43c489a7b/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:13] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43559 "POST /session/0ad591e5e3f834c24a4c84d43c489a7b/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:13] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:13] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:13] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:13] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:13] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:13] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:13] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:13] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46201/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:14] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:46201 (connectionpool.py:232)
[2022-03-10 01:12:15] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46201 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:15] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:15] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46201/session/383025a47b7ac452fbbb259421da2abe/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:15] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46201 "POST /session/383025a47b7ac452fbbb259421da2abe/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:15] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:15] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:15] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:15] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:15] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:15] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:15] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:15] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:15] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:16] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:56115/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:16] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:56115 (connectionpool.py:232)
[2022-03-10 01:12:17] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:56115 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:56115/session/d1c6d662f8fc010f45b33a8671af03f7/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:17] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:56115 "POST /session/d1c6d662f8fc010f45b33a8671af03f7/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:17] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:17] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:17] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:17] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:17] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:17] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:17] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:17] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57125/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:18] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:57125 (connectionpool.py:232)
[2022-03-10 01:12:19] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57125 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57125/session/2ba5becc63c28a28ac7acf4cd48775c7/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:19] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57125 "POST /session/2ba5becc63c28a28ac7acf4cd48775c7/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:19] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:19] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:19] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:19] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:19] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:19] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:19] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:19] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:20] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35365/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:20] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:35365 (connectionpool.py:232)
[2022-03-10 01:12:22] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35365 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:22] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:22] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35365/session/2b964011d04eb0aad15561d39a240be1/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:22] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35365 "POST /session/2b964011d04eb0aad15561d39a240be1/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:22] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:22] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:40353/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:25] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:40353 (connectionpool.py:232)
[2022-03-10 01:12:27] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:40353 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:40353/session/dc6b83bd2f7056520fe10367a35f6dc4/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:27] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:40353 "POST /session/dc6b83bd2f7056520fe10367a35f6dc4/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:27] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:27] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:27] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:27] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:27] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:27] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:27] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:29] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57821/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:29] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:57821 (connectionpool.py:232)
[2022-03-10 01:12:31] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57821 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57821/session/e021ae4a49c41d75a768951fcc503d22/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:31] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57821 "POST /session/e021ae4a49c41d75a768951fcc503d22/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:31] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:31] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:31] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:31] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:31] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:31] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:31] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:31] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:32] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47553/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:32] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:47553 (connectionpool.py:232)
[2022-03-10 01:12:33] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47553 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:33] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:33] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47553/session/b45786a68c86ec6527d5db187d8ecfbc/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:33] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47553 "POST /session/b45786a68c86ec6527d5db187d8ecfbc/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:33] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:33] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:33] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:33] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:33] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:33] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:33] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:33] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:33] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46789/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:34] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:46789 (connectionpool.py:232)
[2022-03-10 01:12:37] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46789 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:37] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:37] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46789/session/ba8544fe18d1da4493a6b90c72214860/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:37] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46789 "POST /session/ba8544fe18d1da4493a6b90c72214860/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:37] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:37] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:37] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:37] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:37] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:37] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:37] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:37] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:37] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:38] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48027/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:38] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:48027 (connectionpool.py:232)
[2022-03-10 01:12:41] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48027 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48027/session/650cf1e56205e674eddc153a5a790550/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:41] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48027 "POST /session/650cf1e56205e674eddc153a5a790550/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:41] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:41] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:41] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:41] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:41] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:41] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:41] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:41] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35831/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:42] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:35831 (connectionpool.py:232)
[2022-03-10 01:12:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35831 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35831/session/b4c02eec49b2be9e083d89c86c35708a/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35831 "POST /session/b4c02eec49b2be9e083d89c86c35708a/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:44] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:44] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:44] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:44] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:44] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:44] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:44] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:44] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54525/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:45] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:54525 (connectionpool.py:232)
[2022-03-10 01:12:46] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54525 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54525/session/34d4634d352bb17691e488b903ea8f3f/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:46] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54525 "POST /session/34d4634d352bb17691e488b903ea8f3f/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:46] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:46] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:46] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:46] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:46] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:46] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:46] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:46] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:36093/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:47] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:36093 (connectionpool.py:232)
[2022-03-10 01:12:48] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:36093 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:36093/session/23937f2222ae0f3f51d2dfb14a1847c1/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:48] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:36093 "POST /session/23937f2222ae0f3f51d2dfb14a1847c1/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:48] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:48] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:48] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:48] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:48] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:48] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:48] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:48] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:32977/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:49] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:32977 (connectionpool.py:232)
[2022-03-10 01:12:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:32977 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:32977/session/5c51990ffef14e359d13758fd591c69e/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:32977 "POST /session/5c51990ffef14e359d13758fd591c69e/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:51] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:51] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:51] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:51] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:51] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:51] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:51] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:51] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:52] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54595/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:52] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:54595 (connectionpool.py:232)
[2022-03-10 01:12:53] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54595 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54595/session/874081381aff261a1611de40a3cf576b/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:53] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54595 "POST /session/874081381aff261a1611de40a3cf576b/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:53] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:53] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:53] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:53] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:53] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:53] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:53] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:53] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59191/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:54] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:59191 (connectionpool.py:232)
[2022-03-10 01:12:55] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59191 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59191/session/f30f77e4491e5e9ea493a01eba259e93/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:55] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59191 "POST /session/f30f77e4491e5e9ea493a01eba259e93/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:55] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:55] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:55] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:55] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:56] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:56] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:56] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:56] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45075/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:57] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:45075 (connectionpool.py:232)
[2022-03-10 01:12:58] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45075 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:12:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45075/session/5ebd0b91846baf3099b461e5020ca7df/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:12:58] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45075 "POST /session/5ebd0b91846baf3099b461e5020ca7df/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:12:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:12:58] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:12:58] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:12:58] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:12:58] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:12:58] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:12:58] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:12:58] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:12:58] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:12:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:55617/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:12:59] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:55617 (connectionpool.py:232)
[2022-03-10 01:13:02] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:55617 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:13:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:13:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:55617/session/43cd5d517aba80ef7ef6ca4cf9d9023e/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:13:02] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:55617 "POST /session/43cd5d517aba80ef7ef6ca4cf9d9023e/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:13:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:13:02] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:13:02] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:13:02] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:13:02] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:13:02] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:02] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:13:02] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:13:02] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:13:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38787/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:13:03] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:38787 (connectionpool.py:232)
[2022-03-10 01:13:06] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38787 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:13:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:13:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38787/session/5b5eeb84c189ac3fd90fd53dc61fa547/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:13:06] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38787 "POST /session/5b5eeb84c189ac3fd90fd53dc61fa547/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:13:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:13:06] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:13:06] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:13:06] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:13:06] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:13:06] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:06] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:13:06] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:13:06] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:13:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59193/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:13:08] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:59193 (connectionpool.py:232)
[2022-03-10 01:13:10] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59193 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:13:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:13:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59193/session/6886bf570db85e4162d3f01a5ea06dd2/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:13:10] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59193 "POST /session/6886bf570db85e4162d3f01a5ea06dd2/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:13:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:13:10] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:13:10] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:13:10] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:13:10] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:13:10] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:10] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:13:10] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_0.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:13:10] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:13:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46807/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:13:12] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:46807 (connectionpool.py:232)
[2022-03-10 01:13:21] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46807 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:13:21] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:13:21] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46807/session/fbaaf4fe687eb2e1c5a70c6348f22c54/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:13:21] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46807 "POST /session/fbaaf4fe687eb2e1c5a70c6348f22c54/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:13:21] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:13:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:13:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:13:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:13:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:13:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:21] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:33] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:34] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:34] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:34] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:34] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:37] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:37] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:39] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%8E%AB%E8%BF%AA%E4%BC%9A%E8%A7%81%E7%BE%8E%E5%9B%BD%E5%9B%BD%E5%8A%A1%E5%8D%BF> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:41] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:41] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:43] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%8E%AB%E8%BF%AA%E4%BC%9A%E8%A7%81%E6%B3%95%E5%9B%BD%E9%98%B2%E9%95%BF> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:43] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E7%BA%B3%E8%90%A8%E5%B0%94%E5%B7%B4%E9%87%8C%E8%BF%90%E5%8A%A8> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:43] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E8%AE%AE%E4%BC%9A%E9%80%89%E4%B8%BE> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:44] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:44] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E5%A4%A7%E9%80%89%E6%8A%95%E7%A5%A8> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:44] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E9%9D%9E%E6%9A%B4%E5%8A%9B%E4%B8%8D%E5%90%88%E4%BD%9C%E8%BF%90%E5%8A%A8> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:44] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E4%B8%8D%E7%BB%93%E7%9B%9F%E8%BF%90%E5%8A%A8> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:44] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E6%B0%91%E6%97%8F%E7%8B%AC%E7%AB%8B%E8%BF%90%E5%8A%A8> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:44] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E5%85%B1%E5%92%8C%E5%9B%BD%E6%88%90%E7%AB%8B> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:44] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E2%80%9C%E8%AF%AD%E8%A8%80%E5%88%86%E7%A6%BB%E4%B8%BB%E4%B9%89%E2%80%9D%E6%B4%BB%E8%B7%83> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:46] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:48] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/11%C2%B712%E5%8D%B0%E5%BA%A6%E5%8D%A1%E7%BA%B3%E5%A1%94%E5%85%8B%E9%82%A6%E5%B1%B1%E4%BD%93%E6%BB%91%E5%9D%A1> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:48] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/7%C2%B725%E5%8D%B0%E5%BA%A6%E5%B1%B1%E4%BD%93%E6%BB%91%E5%9D%A1%E4%BA%8B%E6%95%85> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:48] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/7%C2%B730%E5%8D%B0%E5%BA%A6%E9%A9%AC%E5%93%88%E6%8B%89%E6%96%BD%E7%89%B9%E6%8B%89%E9%82%A6%E6%B3%A5%E7%9F%B3%E6%B5%81> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:48] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:49] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:49] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E6%97%B1%E7%81%BE> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:49] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/2019%E5%B9%B4%E5%8D%B0%E5%BA%A6%E6%B4%AA%E7%81%BE> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:49] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/2015%E5%8D%B0%E5%BA%A6%E9%AB%98%E6%B8%A9%E7%81%BE%E5%AE%B3> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:49] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/2021%E5%B9%B4%E5%8D%B0%E5%BA%A6%E6%9A%B4%E9%9B%A8%E7%81%BE%E5%AE%B3> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:51] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:51] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:52] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:52] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%9D%97%E8%99%AB%E8%A2%AD%E5%87%BB%E6%96%B0%E5%BE%B7%E9%87%8C> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:52] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/2%C2%B77%E5%8D%B0%E5%BA%A6%E5%8C%97%E9%83%A8%E5%86%B0%E5%B7%9D%E6%96%AD%E8%A3%82> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:53] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:53] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E6%96%B0%E5%86%A0%E7%96%AB%E6%83%85> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:53] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/12%C2%B717%E5%8D%B0%E5%BA%A6%E5%AF%8C%E5%A3%AB%E5%BA%B7%E9%A3%9F%E7%89%A9%E4%B8%AD%E6%AF%92%E4%BA%8B%E4%BB%B6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:53] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E6%96%B0%E5%BE%B7%E9%87%8C%E5%9C%B0%E9%9C%87> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:53] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E9%BC%A0%E7%96%AB> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:53] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E5%8D%9A%E5%B8%95%E5%B0%94%E7%81%BE%E9%9A%BE> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:53] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E6%B0%A7%E6%B0%94%E5%8D%B1%E6%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:53] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:53] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/12%C2%B714%E5%8D%B0%E5%BA%A6%E9%A3%9F%E7%89%A9%E4%B8%AD%E6%AF%92%E4%BA%8B%E4%BB%B6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:54] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6H5N1%E7%A6%BD%E6%B5%81%E6%84%9F> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:54] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:56] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:56] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:57] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E8%B4%AD%E4%B9%B0%E7%BE%8E%E5%9B%BDF-16%E6%88%98%E6%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:57] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E6%B5%B7%E5%86%9B%E8%88%AA%E9%81%93%E6%BC%94%E4%B9%A0> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:57] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/1962%E5%B9%B4%E6%8C%91%E8%B5%B7%E4%B8%AD%E5%8D%B0%E8%BE%B9%E7%95%8C%E4%BA%89%E7%AB%AF> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:57] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:58] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:58] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:13:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E5%8D%B0%E5%BA%A6%E8%AF%95%E5%B0%84%E6%96%B0%E5%9E%8B%E5%8F%8D%E9%9B%B7%E8%BE%BE%E5%AF%BC%E5%BC%B9> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/5%C2%B77%E5%8D%B0%E5%BA%A6%E5%8C%96%E5%B7%A5%E5%8E%82%E6%AF%92%E6%B0%94%E6%B3%84%E6%BC%8F%E4%BA%8B%E6%95%85> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:13:59] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:14:41] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.000400 (DataCleaning.py:41)
[2022-03-10 01:14:41] [    INFO] [  __main__ ] - upload crawl file success (MultisiteSchedule.py:395)
[2022-03-10 01:14:41] [   ERROR] [  __main__ ] - [Errno 2] No such file or directory: 'result/url' (MultisiteSchedule.py:261)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 235, in upload_crawl_img_new
    img_file_list = os.listdir(file_index)
FileNotFoundError: [Errno 2] No such file or directory: 'result/url'
[2022-03-10 01:14:41] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:398)
[2022-03-10 01:14:41] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 01:22:24] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:22:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_1.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:22:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:22:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:52909/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:22:25] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:52909 (connectionpool.py:232)
[2022-03-10 01:22:25] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:52909 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:22:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:52909/session/b3ef0a82fa796325437b035221420471/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:22:25] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:52909 "POST /session/b3ef0a82fa796325437b035221420471/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:22:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:25] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:22:25] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:22:25] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:22:25] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:22:25] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:22:25] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:22:25] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_1.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:22:25] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:22:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38011/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:22:26] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:38011 (connectionpool.py:232)
[2022-03-10 01:22:26] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38011 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:22:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38011/session/add0e7bcb79ac104acd0e3c3cbf55f4f/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:22:26] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38011 "POST /session/add0e7bcb79ac104acd0e3c3cbf55f4f/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:22:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:26] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:22:26] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:22:26] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:22:26] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:22:26] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:22:26] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:22:26] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_1.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:22:26] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:22:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48873/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:22:27] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:48873 (connectionpool.py:232)
[2022-03-10 01:22:27] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48873 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:22:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48873/session/155381ee683fdb1b0c3bb19f53148a43/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:22:27] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48873 "POST /session/155381ee683fdb1b0c3bb19f53148a43/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:22:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:27] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:22:27] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:22:27] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:22:27] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:22:27] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:22:27] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:22:27] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_1.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:22:27] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:22:28] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:51453/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:22:28] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:51453 (connectionpool.py:232)
[2022-03-10 01:22:29] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:51453 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:22:29] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:29] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:51453/session/ad689a91a3387edda82ebc8f9732cf28/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:22:29] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:51453 "POST /session/ad689a91a3387edda82ebc8f9732cf28/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:22:29] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:29] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:22:29] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:22:29] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:22:29] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:22:29] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:22:29] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:22:29] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_1.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:22:29] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:22:30] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:33031/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:22:30] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:33031 (connectionpool.py:232)
[2022-03-10 01:22:30] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:33031 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:22:30] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:30] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:33031/session/292a60411db45e68efd1797902dc4b42/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:22:30] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:33031 "POST /session/292a60411db45e68efd1797902dc4b42/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:22:30] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:30] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:22:30] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:22:30] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:22:30] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:22:30] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:22:30] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:22:30] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_1.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:22:30] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:22:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48797/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:22:31] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:48797 (connectionpool.py:232)
[2022-03-10 01:22:31] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48797 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:22:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48797/session/195eab9b80ab4da1b397647770d2c425/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:22:31] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48797 "POST /session/195eab9b80ab4da1b397647770d2c425/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:22:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:31] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:22:31] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:22:31] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:22:31] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:22:31] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:22:31] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:22:31] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_1.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:22:31] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:22:32] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:33999/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:22:32] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:33999 (connectionpool.py:232)
[2022-03-10 01:22:32] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:33999 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:22:32] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:32] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:33999/session/b31045a5b393859d4d124360f975511a/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:22:32] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:33999 "POST /session/b31045a5b393859d4d124360f975511a/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:22:32] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:32] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:22:32] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:22:32] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:22:32] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:22:32] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:22:32] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:22:32] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_1.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:22:32] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:22:33] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43421/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:22:33] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:43421 (connectionpool.py:232)
[2022-03-10 01:22:33] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43421 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:22:33] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:33] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:43421/session/9dd5d8daf0a2a432078accbc96866d30/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:22:33] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:43421 "POST /session/9dd5d8daf0a2a432078accbc96866d30/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:22:33] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:33] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:22:33] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:22:33] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:22:33] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:22:33] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:22:33] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:22:33] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_1.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:22:33] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:22:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47655/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:22:34] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:47655 (connectionpool.py:232)
[2022-03-10 01:22:34] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47655 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:22:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47655/session/7878e79ff5d63f7190c75dfff3983724/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:22:34] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47655 "POST /session/7878e79ff5d63f7190c75dfff3983724/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:22:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:34] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:22:34] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:22:34] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:22:34] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:22:34] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:22:34] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:22:34] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_1.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:22:34] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:22:35] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:58371/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:22:35] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:58371 (connectionpool.py:232)
[2022-03-10 01:22:35] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:58371 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:22:35] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:35] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:58371/session/5bf7cd48243f46e1c70d6359a72509cf/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:22:35] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:58371 "POST /session/5bf7cd48243f46e1c70d6359a72509cf/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:22:35] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:35] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:22:35] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:22:35] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:22:35] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:22:35] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:22:35] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:22:35] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_1.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:22:35] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:22:36] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:33151/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:22:36] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:33151 (connectionpool.py:232)
[2022-03-10 01:22:36] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:33151 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:22:36] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:36] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:33151/session/cde34cf44a9fd87908f24a63804acfb9/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:22:36] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:33151 "POST /session/cde34cf44a9fd87908f24a63804acfb9/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:22:36] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:22:36] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:22:36] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:22:36] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:22:36] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:22:36] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:22:36] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:22:40] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:40] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:40] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:40] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:40] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/earth%20fortification> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:40] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:40] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:44] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/earth%20fortification> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:44] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:46] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:49] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:49] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:49] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:50] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:50] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:52] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:53] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:22:53] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/earth%20fortification> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:22:53] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:22:53] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:22:53] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:22:53] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/earth%20fortification (Baidu.py:151)
[2022-03-10 01:22:53] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:22:53] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1259,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 18.190328,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 22, 53, 944137),
 'log_count/DEBUG': 32,
 'log_count/ERROR': 6,
 'log_count/INFO': 17,
 'memusage/max': 68251648,
 'memusage/startup': 68251648,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 22, 35, 753809)} (statscollectors.py:47)
[2022-03-10 01:22:53] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:22:53] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:22:53] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1174,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 28.289135,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 22, 53, 975195),
 'log_count/DEBUG': 95,
 'log_count/ERROR': 6,
 'log_count/INFO': 92,
 'memusage/max': 66367488,
 'memusage/startup': 66367488,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 22, 25, 686060)} (statscollectors.py:47)
[2022-03-10 01:22:53] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:22:54] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:55] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:22:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:55] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:22:55] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA (Baidu.py:151)
[2022-03-10 01:22:55] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:22:55] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1232,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 27.458326,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 22, 55, 374700),
 'log_count/DEBUG': 83,
 'log_count/ERROR': 9,
 'log_count/INFO': 79,
 'memusage/max': 66871296,
 'memusage/startup': 66871296,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 22, 27, 916374)} (statscollectors.py:47)
[2022-03-10 01:22:55] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:22:55] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:22:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:55] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:22:55] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:22:56] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:22:56] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1259,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 23.699587,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 22, 56, 45121),
 'log_count/DEBUG': 56,
 'log_count/ERROR': 12,
 'log_count/INFO': 50,
 'memusage/max': 67674112,
 'memusage/startup': 67665920,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 22, 32, 345534)} (statscollectors.py:47)
[2022-03-10 01:22:56] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:22:56] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:22:56] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:22:56] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:22:56] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:22:56] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:22:56] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1250,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 21.802793,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 22, 56, 422504),
 'log_count/DEBUG': 43,
 'log_count/ERROR': 15,
 'log_count/INFO': 37,
 'memusage/max': 68067328,
 'memusage/startup': 68067328,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 22, 34, 619711)} (statscollectors.py:47)
[2022-03-10 01:22:56] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:22:57] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:22:57] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:22:57] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA (Baidu.py:151)
[2022-03-10 01:22:57] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:22:57] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1245,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 31.041805,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 22, 57, 826566),
 'log_count/DEBUG': 92,
 'log_count/ERROR': 18,
 'log_count/INFO': 96,
 'memusage/max': 66670592,
 'memusage/startup': 66670592,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 22, 26, 784761)} (statscollectors.py:47)
[2022-03-10 01:22:57] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:22:59] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:22:59] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:22:59] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA (Baidu.py:151)
[2022-03-10 01:22:59] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:22:59] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1225,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 29.171226,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 22, 59, 300252),
 'log_count/DEBUG': 71,
 'log_count/ERROR': 21,
 'log_count/INFO': 75,
 'memusage/max': 67264512,
 'memusage/startup': 67264512,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 22, 30, 129026)} (statscollectors.py:47)
[2022-03-10 01:22:59] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:23:00] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:23:00] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:23:00] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:23:00] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:23:00] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1261,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 26.936493,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 23, 0, 417306),
 'log_count/DEBUG': 50,
 'log_count/ERROR': 24,
 'log_count/INFO': 54,
 'memusage/max': 67874816,
 'memusage/startup': 67874816,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 22, 33, 480813)} (statscollectors.py:47)
[2022-03-10 01:23:00] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:23:00] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:23:00] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:23:00] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99 (Baidu.py:151)
[2022-03-10 01:23:00] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:23:00] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1243,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 31.696341,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 23, 0, 712606),
 'log_count/DEBUG': 78,
 'log_count/ERROR': 27,
 'log_count/INFO': 89,
 'memusage/max': 67067904,
 'memusage/startup': 67059712,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 22, 29, 16265)} (statscollectors.py:47)
[2022-03-10 01:23:00] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:23:01] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:23:01] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:23:01] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA (Baidu.py:151)
[2022-03-10 01:23:01] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:23:01] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1196,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 30.153269,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 23, 1, 394540),
 'log_count/DEBUG': 64,
 'log_count/ERROR': 30,
 'log_count/INFO': 76,
 'memusage/max': 67465216,
 'memusage/startup': 67465216,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 22, 31, 241271)} (statscollectors.py:47)
[2022-03-10 01:23:01] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:23:01] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:23:01] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:23:01] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:23:01] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:23:01] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1243,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 24.894032,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 23, 1, 780998),
 'log_count/DEBUG': 29,
 'log_count/ERROR': 33,
 'log_count/INFO': 39,
 'memusage/max': 68435968,
 'memusage/startup': 68435968,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 22, 36, 886966)} (statscollectors.py:47)
[2022-03-10 01:23:01] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:23:01] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.000102 (DataCleaning.py:41)
[2022-03-10 01:23:01] [    INFO] [  __main__ ] - upload crawl file success (MultisiteSchedule.py:395)
[2022-03-10 01:23:01] [   ERROR] [  __main__ ] - [Errno 2] No such file or directory: 'result/url' (MultisiteSchedule.py:261)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 235, in upload_crawl_img_new
    img_file_list = os.listdir(file_index)
FileNotFoundError: [Errno 2] No such file or directory: 'result/url'
[2022-03-10 01:23:01] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:398)
[2022-03-10 01:23:01] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 01:23:38] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:23:38] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_2.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:23:38] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:23:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:39989/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:23:39] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:39989 (connectionpool.py:232)
[2022-03-10 01:23:39] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:39989 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:23:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:39989/session/bf6c7ad2490bc41f180b93e91d335ed9/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:23:39] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:39989 "POST /session/bf6c7ad2490bc41f180b93e91d335ed9/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:23:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:39] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:23:39] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:23:39] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:23:39] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:23:39] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:23:39] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:23:39] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_2.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:23:39] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:23:40] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:56233/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:23:40] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:56233 (connectionpool.py:232)
[2022-03-10 01:23:41] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:56233 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:23:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:56233/session/85e5e709fbdf0910eeac3fda143e542d/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:23:41] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:56233 "POST /session/85e5e709fbdf0910eeac3fda143e542d/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:23:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:41] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:23:41] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:23:41] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:23:41] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:23:41] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:23:41] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:23:41] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_2.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:23:41] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:23:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35145/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:23:42] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:35145 (connectionpool.py:232)
[2022-03-10 01:23:42] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35145 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:23:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35145/session/cc92ca7e82679260eb0908b6b8462bae/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:23:42] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35145 "POST /session/cc92ca7e82679260eb0908b6b8462bae/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:23:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:23:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:23:42] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:23:42] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:23:42] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:23:42] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:23:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_2.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:23:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:23:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38219/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:23:43] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:38219 (connectionpool.py:232)
[2022-03-10 01:23:43] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38219 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:23:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38219/session/a6f2b47e15ce61dd538c3fb5e2f421f2/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:23:43] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38219 "POST /session/a6f2b47e15ce61dd538c3fb5e2f421f2/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:23:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:43] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:23:43] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:23:43] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:23:43] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:23:43] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:23:43] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:23:43] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_2.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:23:43] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:23:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:55891/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:23:44] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:55891 (connectionpool.py:232)
[2022-03-10 01:23:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:55891 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:23:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:55891/session/cc3cbc34b71895edcb55023cbc416628/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:23:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:55891 "POST /session/cc3cbc34b71895edcb55023cbc416628/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:23:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:44] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:23:44] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:23:44] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:23:44] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:23:44] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:23:44] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:23:44] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_2.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:23:44] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:23:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:53173/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:23:45] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:53173 (connectionpool.py:232)
[2022-03-10 01:23:45] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:53173 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:23:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:53173/session/55ba520cd8c8fcea869489d6f22d38e0/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:23:45] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:53173 "POST /session/55ba520cd8c8fcea869489d6f22d38e0/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:23:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:45] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:23:45] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:23:45] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:23:45] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:23:45] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:23:45] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:23:45] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_2.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:23:45] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:23:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46123/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:23:46] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:46123 (connectionpool.py:232)
[2022-03-10 01:23:46] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46123 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:23:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46123/session/cbd8508725e955ad46c67e43e67e668d/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:23:46] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46123 "POST /session/cbd8508725e955ad46c67e43e67e668d/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:23:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:46] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:23:46] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:23:46] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:23:46] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:23:46] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:23:46] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:23:46] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_2.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:23:46] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:23:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48323/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:23:47] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:48323 (connectionpool.py:232)
[2022-03-10 01:23:47] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48323 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:23:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48323/session/539ee63be9e1ddda0cb8aab4963dc53f/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:23:47] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48323 "POST /session/539ee63be9e1ddda0cb8aab4963dc53f/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:23:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:23:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:23:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:23:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:23:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:23:47] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:23:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_2.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:23:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:23:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:56041/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:23:48] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:56041 (connectionpool.py:232)
[2022-03-10 01:23:49] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:56041 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:23:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:56041/session/d9b7f485dbbb336e63da99a0430048e8/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:23:49] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:56041 "POST /session/d9b7f485dbbb336e63da99a0430048e8/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:23:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:49] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:23:49] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:23:49] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:23:49] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:23:49] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:23:49] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:23:49] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_2.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:23:49] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:23:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59963/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:23:50] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:59963 (connectionpool.py:232)
[2022-03-10 01:23:50] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59963 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:23:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59963/session/01187af33153098c87dad0673385b745/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:23:50] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59963 "POST /session/01187af33153098c87dad0673385b745/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:23:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:50] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:23:50] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:23:50] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:23:50] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:23:50] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:23:50] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:23:50] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_2.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:23:50] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:23:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50099/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:23:51] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:50099 (connectionpool.py:232)
[2022-03-10 01:23:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50099 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:23:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50099/session/aa7d6aa782ef21a1482633c584bd237a/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:23:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50099 "POST /session/aa7d6aa782ef21a1482633c584bd237a/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:23:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:23:51] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:23:51] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:23:51] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:23:51] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:23:51] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:23:51] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:23:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:23:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/earth%20fortification> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:23:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:23:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:23:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:23:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:23:59] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:23:59] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:00] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:00] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:01] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:01] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:04] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:24:04] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:24:04] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA (Baidu.py:151)
[2022-03-10 01:24:04] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:24:04] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1212,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 23.404384,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 24, 4, 493335),
 'log_count/DEBUG': 85,
 'log_count/ERROR': 3,
 'log_count/INFO': 81,
 'memusage/max': 66994176,
 'memusage/startup': 66994176,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 23, 41, 88951)} (statscollectors.py:47)
[2022-03-10 01:24:04] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:24:05] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:05] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:05] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/earth%20fortification> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:08] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:24:08] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:24:08] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:24:08] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:24:08] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99 (Baidu.py:151)
[2022-03-10 01:24:08] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:24:08] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA (Baidu.py:151)
[2022-03-10 01:24:08] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:24:08] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:24:08] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:24:08] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1273,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 25.07345,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 24, 8, 427952),
 'log_count/DEBUG': 75,
 'log_count/ERROR': 12,
 'log_count/INFO': 68,
 'memusage/max': 67399680,
 'memusage/startup': 67391488,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 23, 43, 354502)} (statscollectors.py:47)
[2022-03-10 01:24:08] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:24:08] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:24:08] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1210,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 26.233714,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 24, 8, 430555),
 'log_count/DEBUG': 82,
 'log_count/ERROR': 12,
 'log_count/INFO': 79,
 'memusage/max': 67198976,
 'memusage/startup': 67198976,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 23, 42, 196841)} (statscollectors.py:47)
[2022-03-10 01:24:08] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:24:08] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:24:08] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1250,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 21.65091,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 24, 8, 432480),
 'log_count/DEBUG': 54,
 'log_count/ERROR': 12,
 'log_count/INFO': 50,
 'memusage/max': 68001792,
 'memusage/startup': 68001792,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 23, 46, 781570)} (statscollectors.py:47)
[2022-03-10 01:24:08] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:24:09] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:09] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:24:09] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:09] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:24:09] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:24:09] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:24:09] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1244,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 19.65258,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 24, 9, 855271),
 'log_count/DEBUG': 35,
 'log_count/ERROR': 15,
 'log_count/INFO': 29,
 'memusage/max': 68591616,
 'memusage/startup': 68591616,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 23, 50, 202691)} (statscollectors.py:47)
[2022-03-10 01:24:09] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:24:10] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:24:10] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:24:10] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/earth%20fortification> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:24:10] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:24:10] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:24:10] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:24:10] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/earth%20fortification (Baidu.py:151)
[2022-03-10 01:24:10] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:24:10] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1251,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 21.808171,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 24, 10, 846588),
 'log_count/DEBUG': 43,
 'log_count/ERROR': 21,
 'log_count/INFO': 40,
 'memusage/max': 68407296,
 'memusage/startup': 68407296,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 23, 49, 38417)} (statscollectors.py:47)
[2022-03-10 01:24:10] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:24:10] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:24:10] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1185,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 30.955889,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 24, 10, 939560),
 'log_count/DEBUG': 99,
 'log_count/ERROR': 21,
 'log_count/INFO': 107,
 'memusage/max': 66699264,
 'memusage/startup': 66699264,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 23, 39, 983671)} (statscollectors.py:47)
[2022-03-10 01:24:10] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:24:12] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:24:12] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:24:12] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA (Baidu.py:151)
[2022-03-10 01:24:12] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:24:12] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1192,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 26.628219,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 24, 12, 273356),
 'log_count/DEBUG': 64,
 'log_count/ERROR': 24,
 'log_count/INFO': 70,
 'memusage/max': 67805184,
 'memusage/startup': 67805184,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 23, 45, 645137)} (statscollectors.py:47)
[2022-03-10 01:24:12] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:24:14] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:24:14] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:24:14] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:24:14] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:24:14] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1254,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 26.956005,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 24, 14, 853903),
 'log_count/DEBUG': 50,
 'log_count/ERROR': 27,
 'log_count/INFO': 57,
 'memusage/max': 68210688,
 'memusage/startup': 68210688,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 23, 47, 897898)} (statscollectors.py:47)
[2022-03-10 01:24:14] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:24:14] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:24:15] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:24:15] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA (Baidu.py:151)
[2022-03-10 01:24:15] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:24:15] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1223,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 30.68273,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 24, 15, 193482),
 'log_count/DEBUG': 71,
 'log_count/ERROR': 30,
 'log_count/INFO': 84,
 'memusage/max': 67608576,
 'memusage/startup': 67608576,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 23, 44, 510752)} (statscollectors.py:47)
[2022-03-10 01:24:15] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:24:16] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:24:16] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:24:16] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:24:16] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:24:16] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1264,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 24.89418,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 24, 16, 227518),
 'log_count/DEBUG': 29,
 'log_count/ERROR': 33,
 'log_count/INFO': 39,
 'memusage/max': 68784128,
 'memusage/startup': 68784128,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 23, 51, 333338)} (statscollectors.py:47)
[2022-03-10 01:24:16] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:24:16] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.000102 (DataCleaning.py:41)
[2022-03-10 01:24:16] [    INFO] [  __main__ ] - upload crawl file success (MultisiteSchedule.py:395)
[2022-03-10 01:24:16] [   ERROR] [  __main__ ] - [Errno 2] No such file or directory: 'result/url' (MultisiteSchedule.py:261)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 235, in upload_crawl_img_new
    img_file_list = os.listdir(file_index)
FileNotFoundError: [Errno 2] No such file or directory: 'result/url'
[2022-03-10 01:24:16] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:398)
[2022-03-10 01:24:16] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 01:25:47] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:25:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_3.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:25:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:25:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50777/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:25:48] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:50777 (connectionpool.py:232)
[2022-03-10 01:25:48] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50777 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:25:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50777/session/d2dfdb661d14991a7d19f55a8fbbf2a7/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:25:48] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50777 "POST /session/d2dfdb661d14991a7d19f55a8fbbf2a7/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:25:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:48] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:25:48] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:25:48] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:25:48] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:25:48] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:25:48] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:25:48] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_3.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:25:48] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:25:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:60531/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:25:49] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:60531 (connectionpool.py:232)
[2022-03-10 01:25:50] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:60531 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:25:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:60531/session/7789ac8e5126ca628b56fe5bed37a76c/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:25:50] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:60531 "POST /session/7789ac8e5126ca628b56fe5bed37a76c/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:25:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:50] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:25:50] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:25:50] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:25:50] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:25:50] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:25:50] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:25:50] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_3.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:25:50] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:25:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48425/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:25:51] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:48425 (connectionpool.py:232)
[2022-03-10 01:25:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48425 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:25:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48425/session/ab74d036838d9919aad3f182f9b7f37a/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:25:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48425 "POST /session/ab74d036838d9919aad3f182f9b7f37a/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:25:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:51] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:25:51] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:25:51] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:25:51] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:25:51] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:25:51] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:25:51] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_3.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:25:51] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:25:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:44451/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:25:51] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:44451 (connectionpool.py:232)
[2022-03-10 01:25:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:44451 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:25:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:44451/session/b6e936be11a1cfd6fc1276ab7f0256fe/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:25:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:44451 "POST /session/b6e936be11a1cfd6fc1276ab7f0256fe/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:25:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:51] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:25:51] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:25:51] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:25:51] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:25:51] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:25:51] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:25:51] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_3.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:25:51] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:25:52] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59327/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:25:52] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:59327 (connectionpool.py:232)
[2022-03-10 01:25:53] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59327 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:25:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59327/session/43eed24c7ddb5c9bef9976741c9dc943/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:25:53] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59327 "POST /session/43eed24c7ddb5c9bef9976741c9dc943/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:25:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:53] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:25:53] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:25:53] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:25:53] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:25:53] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:25:53] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:25:53] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_3.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:25:53] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:25:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45673/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:25:54] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:45673 (connectionpool.py:232)
[2022-03-10 01:25:54] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45673 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:25:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45673/session/acaaad0f6b42c3ff6a933eded368849a/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:25:54] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45673 "POST /session/acaaad0f6b42c3ff6a933eded368849a/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:25:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:54] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:25:54] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:25:54] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:25:54] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:25:54] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:25:54] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:25:54] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_3.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:25:54] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:25:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:33535/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:25:55] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:33535 (connectionpool.py:232)
[2022-03-10 01:25:55] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:33535 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:25:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:33535/session/0e0956b1d0b84379b1c5aab7ed1b584f/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:25:55] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:33535 "POST /session/0e0956b1d0b84379b1c5aab7ed1b584f/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:25:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:55] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:25:55] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:25:55] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:25:55] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:25:55] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:25:55] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:25:55] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_3.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:25:55] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:25:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:53911/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:25:56] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:53911 (connectionpool.py:232)
[2022-03-10 01:25:56] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:53911 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:25:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:53911/session/83fb815e321580bc8969e8801c266677/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:25:56] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:53911 "POST /session/83fb815e321580bc8969e8801c266677/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:25:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:56] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:25:56] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:25:56] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:25:56] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:25:56] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:25:56] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:25:56] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_3.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:25:56] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:25:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:44991/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:25:57] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:44991 (connectionpool.py:232)
[2022-03-10 01:25:57] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:44991 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:25:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:44991/session/08ed775b9d84ed6ddffda88efe0e0dc8/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:25:57] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:44991 "POST /session/08ed775b9d84ed6ddffda88efe0e0dc8/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:25:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:57] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:25:57] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:25:57] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:25:57] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:25:57] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:25:57] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:25:57] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_3.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:25:57] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:25:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:55585/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:25:58] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:55585 (connectionpool.py:232)
[2022-03-10 01:25:58] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:55585 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:25:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:55585/session/ae9530ccb931d5570e615f1ff0544de0/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:25:58] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:55585 "POST /session/ae9530ccb931d5570e615f1ff0544de0/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:25:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:25:58] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:25:58] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:25:58] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:25:58] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:25:58] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:25:58] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:25:58] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_3.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:25:58] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:25:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57361/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:25:59] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:57361 (connectionpool.py:232)
[2022-03-10 01:26:00] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57361 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:26:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:26:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57361/session/b4cbf0fdb64434d421a2303379abb294/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:26:00] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57361 "POST /session/b4cbf0fdb64434d421a2303379abb294/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:26:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:26:00] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:26:00] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:26:00] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:26:00] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:26:00] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:26:00] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:26:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/earth%20fortification> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:08] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:08] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:09] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:09] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:10] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:10] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:10] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:26:19] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.000082 (DataCleaning.py:41)
[2022-03-10 01:26:19] [    INFO] [  __main__ ] - upload crawl file success (MultisiteSchedule.py:395)
[2022-03-10 01:26:19] [   ERROR] [  __main__ ] - [Errno 2] No such file or directory: 'result/url' (MultisiteSchedule.py:261)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 235, in upload_crawl_img_new
    img_file_list = os.listdir(file_index)
FileNotFoundError: [Errno 2] No such file or directory: 'result/url'
[2022-03-10 01:26:19] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:398)
[2022-03-10 01:26:19] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 01:27:38] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:27:38] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_4.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:27:38] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:27:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59633/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:27:39] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:59633 (connectionpool.py:232)
[2022-03-10 01:27:39] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59633 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:27:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59633/session/325043ca2f1649a9df01c0868b8b594e/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:27:39] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59633 "POST /session/325043ca2f1649a9df01c0868b8b594e/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:27:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:39] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:27:39] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:27:39] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:27:39] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:27:39] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:27:39] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:27:39] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_4.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:27:39] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:27:40] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57357/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:27:40] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:57357 (connectionpool.py:232)
[2022-03-10 01:27:41] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57357 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:27:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57357/session/14095f5e5095a6989b101093f3faa822/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:27:41] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57357 "POST /session/14095f5e5095a6989b101093f3faa822/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:27:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:41] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:27:41] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:27:41] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:27:41] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:27:41] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:27:41] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:27:41] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_4.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:27:41] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:27:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:41095/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:27:42] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:41095 (connectionpool.py:232)
[2022-03-10 01:27:42] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:41095 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:27:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:41095/session/59673a1ad1413c53f820264a40b8bd40/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:27:42] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:41095 "POST /session/59673a1ad1413c53f820264a40b8bd40/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:27:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:27:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:27:42] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:27:42] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:27:42] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:27:42] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:27:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_4.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:27:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:27:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:33125/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:27:43] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:33125 (connectionpool.py:232)
[2022-03-10 01:27:43] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:33125 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:27:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:33125/session/a7e9373275c01bc90d6eb8867038687a/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:27:43] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:33125 "POST /session/a7e9373275c01bc90d6eb8867038687a/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:27:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:43] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:27:43] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:27:43] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:27:43] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:27:43] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:27:43] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:27:43] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_4.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:27:43] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:27:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:40229/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:27:44] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:40229 (connectionpool.py:232)
[2022-03-10 01:27:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:40229 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:27:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:40229/session/583b73e3d9b6462315fa5eff7b9245c5/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:27:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:40229 "POST /session/583b73e3d9b6462315fa5eff7b9245c5/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:27:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:44] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:27:44] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:27:44] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:27:44] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:27:44] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:27:44] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:27:44] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_4.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:27:44] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:27:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:49405/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:27:45] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:49405 (connectionpool.py:232)
[2022-03-10 01:27:45] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:49405 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:27:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:49405/session/bb952723758520e6b848a07d575f43fa/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:27:45] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:49405 "POST /session/bb952723758520e6b848a07d575f43fa/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:27:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:45] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:27:45] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:27:45] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:27:45] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:27:45] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:27:45] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:27:45] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_4.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:27:45] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:27:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59211/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:27:46] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:59211 (connectionpool.py:232)
[2022-03-10 01:27:46] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59211 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:27:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:59211/session/9ea70bc8d0df883fde2c154af41b4a8e/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:27:46] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:59211 "POST /session/9ea70bc8d0df883fde2c154af41b4a8e/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:27:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:46] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:27:46] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:27:46] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:27:46] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:27:46] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:27:46] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:27:46] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_4.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:27:46] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:27:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42979/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:27:47] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:42979 (connectionpool.py:232)
[2022-03-10 01:27:47] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42979 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:27:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42979/session/64df93f3ab9cdbd40deccb03ae6b91cc/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:27:47] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42979 "POST /session/64df93f3ab9cdbd40deccb03ae6b91cc/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:27:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:27:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:27:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:27:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:27:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:27:47] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:27:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_4.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:27:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:27:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48047/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:27:48] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:48047 (connectionpool.py:232)
[2022-03-10 01:27:48] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48047 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:27:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48047/session/b7325dd04ae242d653b76085b059f8da/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:27:48] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48047 "POST /session/b7325dd04ae242d653b76085b059f8da/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:27:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:48] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:27:48] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:27:48] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:27:48] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:27:48] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:27:48] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:27:48] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_4.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:27:48] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:27:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:58953/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:27:49] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:58953 (connectionpool.py:232)
[2022-03-10 01:27:50] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:58953 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:27:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:58953/session/3136dbc30d22487c607ca49e74ddd8b6/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:27:50] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:58953 "POST /session/3136dbc30d22487c607ca49e74ddd8b6/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:27:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:50] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:27:50] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:27:50] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:27:50] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:27:50] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:27:50] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:27:50] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_4.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:27:50] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:27:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35885/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:27:51] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:35885 (connectionpool.py:232)
[2022-03-10 01:27:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35885 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:27:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35885/session/e8611690a24147f7269408c3a3efa7c2/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:27:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35885 "POST /session/e8611690a24147f7269408c3a3efa7c2/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:27:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:27:51] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:27:51] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:27:51] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:27:51] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:27:51] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:27:51] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:27:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:27:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:27:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/earth%20fortification> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:27:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:27:55] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:27:59] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:00] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:00] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:00] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:00] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:01] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6> (failed 1 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/earth%20fortification> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:05] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:05] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:09] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:09] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:09] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/earth%20fortification> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:28:09] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:09] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:28:09] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/earth%20fortification (Baidu.py:151)
[2022-03-10 01:28:09] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:28:09] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1178,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 29.303729,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 28, 9, 266492),
 'log_count/DEBUG': 97,
 'log_count/ERROR': 3,
 'log_count/INFO': 89,
 'memusage/max': 66600960,
 'memusage/startup': 66600960,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 27, 39, 962763)} (statscollectors.py:47)
[2022-03-10 01:28:09] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:28:09] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:09] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:28:09] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6> (failed 2 times): DNS lookup failed: http_proxy. (retry.py:99)
[2022-03-10 01:28:09] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:28:09] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99 (Baidu.py:151)
[2022-03-10 01:28:09] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:28:09] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1257,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 26.237443,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 28, 9, 558574),
 'log_count/DEBUG': 78,
 'log_count/ERROR': 6,
 'log_count/INFO': 68,
 'memusage/max': 67289088,
 'memusage/startup': 67289088,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 27, 43, 321131)} (statscollectors.py:47)
[2022-03-10 01:28:09] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:28:10] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:28:10] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:28:10] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:28:10] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:28:10] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1250,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 20.264047,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 28, 10, 300949),
 'log_count/DEBUG': 36,
 'log_count/ERROR': 9,
 'log_count/INFO': 23,
 'memusage/max': 68489216,
 'memusage/startup': 68489216,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 27, 50, 36902)} (statscollectors.py:47)
[2022-03-10 01:28:10] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:28:10] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:28:10] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:28:10] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA (Baidu.py:151)
[2022-03-10 01:28:10] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:28:10] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1223,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 28.495582,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 28, 10, 701674),
 'log_count/DEBUG': 85,
 'log_count/ERROR': 12,
 'log_count/INFO': 82,
 'memusage/max': 67100672,
 'memusage/startup': 67100672,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 27, 42, 206092)} (statscollectors.py:47)
[2022-03-10 01:28:10] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:28:11] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:28:11] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:28:11] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:28:12] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:28:12] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1257,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 23.102842,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 28, 12, 30342),
 'log_count/DEBUG': 43,
 'log_count/ERROR': 15,
 'log_count/INFO': 37,
 'memusage/max': 68296704,
 'memusage/startup': 68296704,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 27, 48, 927500)} (statscollectors.py:47)
[2022-03-10 01:28:12] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:28:14] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:28:14] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:28:14] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA (Baidu.py:151)
[2022-03-10 01:28:14] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA (Baidu.py:151)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:28:14] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1210,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 28.976108,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 28, 14, 544940),
 'log_count/DEBUG': 64,
 'log_count/ERROR': 25,
 'log_count/INFO': 64,
 'memusage/max': 67706880,
 'memusage/startup': 67706880,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 27, 45, 568832)} (statscollectors.py:47)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:28:14] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1241,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 27.872438,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 28, 14, 560024),
 'log_count/DEBUG': 57,
 'log_count/ERROR': 27,
 'log_count/INFO': 59,
 'memusage/max': 67899392,
 'memusage/startup': 67899392,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 27, 46, 687586)} (statscollectors.py:47)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:28:14] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1232,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 33.535487,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 28, 14, 605923),
 'log_count/DEBUG': 92,
 'log_count/ERROR': 27,
 'log_count/INFO': 102,
 'memusage/max': 66904064,
 'memusage/startup': 66904064,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 27, 41, 70436)} (statscollectors.py:47)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:28:14] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1250,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 26.833196,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 28, 14, 653010),
 'log_count/DEBUG': 50,
 'log_count/ERROR': 27,
 'log_count/INFO': 57,
 'memusage/max': 68108288,
 'memusage/startup': 68108288,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 27, 47, 819814)} (statscollectors.py:47)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:28:14] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:28:14] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6> (failed 3 times): DNS lookup failed: http_proxy. (retry.py:122)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA (Baidu.py:151)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - <twisted.python.failure.Failure twisted.internet.error.DNSLookupError: DNS lookup failed: http_proxy.> (Baidu.py:137)
[2022-03-10 01:28:14] [   ERROR] [     baidu ] - DNSLookupError on https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6 (Baidu.py:151)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:28:14] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1222,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 30.449156,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 28, 14, 904423),
 'log_count/DEBUG': 71,
 'log_count/ERROR': 33,
 'log_count/INFO': 84,
 'memusage/max': 67506176,
 'memusage/startup': 67506176,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 27, 44, 455267)} (statscollectors.py:47)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:28:14] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 1240,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 23.806296,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 28, 14, 951751),
 'log_count/DEBUG': 29,
 'log_count/ERROR': 33,
 'log_count/INFO': 39,
 'memusage/max': 68681728,
 'memusage/startup': 68681728,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 27, 51, 145455)} (statscollectors.py:47)
[2022-03-10 01:28:14] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:28:14] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.000062 (DataCleaning.py:41)
[2022-03-10 01:28:14] [    INFO] [  __main__ ] - upload crawl file success (MultisiteSchedule.py:395)
[2022-03-10 01:28:14] [   ERROR] [  __main__ ] - [Errno 2] No such file or directory: 'result/url' (MultisiteSchedule.py:261)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 235, in upload_crawl_img_new
    img_file_list = os.listdir(file_index)
FileNotFoundError: [Errno 2] No such file or directory: 'result/url'
[2022-03-10 01:28:14] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:398)
[2022-03-10 01:28:14] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 01:37:05] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:37:05] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_6.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:37:05] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:37:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:36885/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:37:06] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:36885 (connectionpool.py:232)
[2022-03-10 01:37:07] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:36885 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:37:07] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:07] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:36885/session/91aae8c03a15e3ff56ba186476c5a665/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:37:07] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:36885 "POST /session/91aae8c03a15e3ff56ba186476c5a665/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:07] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:37:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:37:07] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:37:07] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:37:07] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:37:07] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:37:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_6.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:37:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:37:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47735/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:37:08] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:47735 (connectionpool.py:232)
[2022-03-10 01:37:08] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47735 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:37:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47735/session/55c516efb89dcb599220e6a2ae83a9fa/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:37:08] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47735 "POST /session/55c516efb89dcb599220e6a2ae83a9fa/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:08] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:37:08] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:37:08] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:37:08] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:37:08] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:37:08] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:37:08] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_6.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:37:08] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:37:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45375/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:37:09] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:45375 (connectionpool.py:232)
[2022-03-10 01:37:09] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45375 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:37:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45375/session/9c9456814168a7caaee9806fb3c6036e/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:37:09] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45375 "POST /session/9c9456814168a7caaee9806fb3c6036e/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:09] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:37:09] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:37:09] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:37:09] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:37:09] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:37:09] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:37:09] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_6.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:37:09] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:37:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:41867/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:37:10] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:41867 (connectionpool.py:232)
[2022-03-10 01:37:10] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:41867 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:37:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:41867/session/3f6db4c19f470f881711ef875446d806/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:37:10] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:41867 "POST /session/3f6db4c19f470f881711ef875446d806/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:10] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:37:10] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:37:10] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:37:10] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:37:10] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:37:10] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:37:10] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_6.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:37:10] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:37:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:37:11] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:42033 (connectionpool.py:232)
[2022-03-10 01:37:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:37:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:37:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:11] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:37:11] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:37:11] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:37:11] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:37:11] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:37:11] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:37:11] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_6.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:37:11] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:37:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38757/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:37:12] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:38757 (connectionpool.py:232)
[2022-03-10 01:37:12] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38757 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:37:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38757/session/77e5642a14253f900ef3ee5e000832cd/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:37:12] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38757 "POST /session/77e5642a14253f900ef3ee5e000832cd/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:12] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:37:12] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:37:12] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:37:12] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:37:12] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:37:12] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:37:12] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_6.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:37:12] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:37:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:52833/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:37:13] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:52833 (connectionpool.py:232)
[2022-03-10 01:37:13] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:52833 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:37:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:52833/session/127ccd069506472e83d033c01590f041/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:37:13] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:52833 "POST /session/127ccd069506472e83d033c01590f041/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:13] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:37:13] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:37:13] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:37:13] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:37:13] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:37:13] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:37:13] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_6.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:37:13] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:37:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50675/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:37:14] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:50675 (connectionpool.py:232)
[2022-03-10 01:37:14] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50675 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:37:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50675/session/1b90ffb39113ad9058ade9e3ae53db0f/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:37:14] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50675 "POST /session/1b90ffb39113ad9058ade9e3ae53db0f/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:14] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:37:14] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:37:14] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:37:14] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:37:14] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:37:14] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:37:14] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_6.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:37:15] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:37:16] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57317/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:37:16] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:57317 (connectionpool.py:232)
[2022-03-10 01:37:16] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57317 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:37:16] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:16] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57317/session/f2374ef50fcfdb26c596db4dc1b9bced/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:37:16] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57317 "POST /session/f2374ef50fcfdb26c596db4dc1b9bced/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:16] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:37:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:37:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:37:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:37:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:37:16] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:37:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_6.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:37:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:37:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38291/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:37:17] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:38291 (connectionpool.py:232)
[2022-03-10 01:37:17] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38291 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:37:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38291/session/77f73e01d3d750e03288fe25f66e952d/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:37:17] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38291 "POST /session/77f73e01d3d750e03288fe25f66e952d/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:17] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:37:17] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:37:17] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:37:17] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:37:17] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:37:17] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:37:17] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_6.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:37:17] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:37:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:37:18] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:45465 (connectionpool.py:232)
[2022-03-10 01:37:18] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:37:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:37:18] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:18] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:37:18] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:37:18] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:37:18] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:37:18] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:37:18] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> from <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (redirect.py:42)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://baike.baidu.com/error.html?status=404&uri=/item/earth%20fortification> from <GET https://baike.baidu.com/item/earth%20fortification> (redirect.py:42)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> from <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (redirect.py:42)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> from <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (redirect.py:42)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (referer: None) (engine.py:250)
[2022-03-10 01:37:18] [ WARNING] [py.warnings ] - /usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py:149: UserWarning: The "BaidubaikeSpider.parse" method is a generator and includes a "return" statement with a value different than None. This could lead to unexpected behaviour. Please see https://docs.python.org/3/reference/simple_stmts.html#the-return-statement for details about the semantics of the "return" statement within generators
  warn_on_generator_with_return_value(spider, callback)
 (warnings.py:110)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (referer: None) (engine.py:250)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (referer: None) (engine.py:250)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA/19178695> from <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (redirect.py:42)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6> (referer: None) (engine.py:250)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (referer: None) (engine.py:250)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/error.html?status=404&uri=/item/earth%20fortification> (referer: None) (engine.py:250)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (referer: None) (engine.py:250)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (referer: None) (engine.py:250)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (referer: None) (engine.py:250)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA/19178695> (referer: None) (engine.py:250)
[2022-03-10 01:37:18] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:37:18] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 959,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 2986,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 9.376655,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 37, 18, 749206),
 'httpcompression/response_bytes': 4555,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 78,
 'log_count/INFO': 73,
 'log_count/WARNING': 1,
 'memusage/max': 67211264,
 'memusage/startup': 67194880,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 3, 10, 1, 37, 9, 372551)} (statscollectors.py:47)
[2022-03-10 01:37:18] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:37:18] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (referer: None) (engine.py:250)
[2022-03-10 01:37:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/url {"url": "https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA"} (remote_connection.py:388)
[2022-03-10 01:37:20] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:20] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:20] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:20] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:20] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:22] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:22] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:22] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:24] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:24] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:24] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:26] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:28] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:28] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:28] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:28] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:28] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:28] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:28] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/elements {"using": "xpath", "value": "//img[contains(@alt, '\u82b1\u83b2\u673a\u573a')]"} (remote_connection.py:388)
[2022-03-10 01:37:28] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/elements HTTP/1.1" 200 248 (connectionpool.py:465)
[2022-03-10 01:37:28] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:28] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "28a7e307-89c3-48dc-ac31-60f0786ea766", "element-6066-11e4-a52e-4f735466cecf": "28a7e307-89c3-48dc-ac31-60f0786ea766"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:37:28] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/execute/sync HTTP/1.1" 200 151 (connectionpool.py:465)
[2022-03-10 01:37:28] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:30] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "4dedbd78-ef24-44a9-ac6b-261a1c934f2b", "element-6066-11e4-a52e-4f735466cecf": "4dedbd78-ef24-44a9-ac6b-261a1c934f2b"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:37:30] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/execute/sync HTTP/1.1" 200 157 (connectionpool.py:465)
[2022-03-10 01:37:30] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:32] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42033/session/2db282e281f4426d754be872dbda4488/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "348d9a3a-7bfd-4b6b-9dad-7595cf53555b", "element-6066-11e4-a52e-4f735466cecf": "348d9a3a-7bfd-4b6b-9dad-7595cf53555b"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:37:32] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42033 "POST /session/2db282e281f4426d754be872dbda4488/execute/sync HTTP/1.1" 200 146 (connectionpool.py:465)
[2022-03-10 01:37:32] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57317/session/f2374ef50fcfdb26c596db4dc1b9bced/url {"url": "https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6"} (remote_connection.py:388)
[2022-03-10 01:37:36] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57317 "POST /session/f2374ef50fcfdb26c596db4dc1b9bced/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:36] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:36] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57317/session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:36] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57317 "POST /session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:36] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:38] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57317/session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:38] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57317 "POST /session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:38] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:40] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57317/session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:40] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57317 "POST /session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:40] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57317/session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:42] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57317 "POST /session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57317/session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57317 "POST /session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57317/session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57317 "POST /session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57317/session/f2374ef50fcfdb26c596db4dc1b9bced/elements {"using": "xpath", "value": "//img[contains(@alt, '\u88c5\u7532\u8fd0\u8f93\u8f66')]"} (remote_connection.py:388)
[2022-03-10 01:37:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57317 "POST /session/f2374ef50fcfdb26c596db4dc1b9bced/elements HTTP/1.1" 200 90 (connectionpool.py:465)
[2022-03-10 01:37:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:57317/session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "df6076c5-c9bf-4bd5-a998-1b5d46bfdd94", "element-6066-11e4-a52e-4f735466cecf": "df6076c5-c9bf-4bd5-a998-1b5d46bfdd94"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:37:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:57317 "POST /session/f2374ef50fcfdb26c596db4dc1b9bced/execute/sync HTTP/1.1" 200 150 (connectionpool.py:465)
[2022-03-10 01:37:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/url {"url": "https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6"} (remote_connection.py:388)
[2022-03-10 01:37:48] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:48] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:50] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:52] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:52] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:52] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:54] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:56] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:37:56] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:37:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/elements {"using": "xpath", "value": "//img[contains(@alt, '\u88c5\u7532\u4fa6\u5bdf\u8f66')]"} (remote_connection.py:388)
[2022-03-10 01:37:56] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/elements HTTP/1.1" 200 564 (connectionpool.py:465)
[2022-03-10 01:37:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "6b606473-f2ac-4e63-9794-b2060e4523c7", "element-6066-11e4-a52e-4f735466cecf": "6b606473-f2ac-4e63-9794-b2060e4523c7"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:37:56] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 147 (connectionpool.py:465)
[2022-03-10 01:37:56] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:37:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "d1b3cd4b-2847-4e1e-943e-e0c732acf831", "element-6066-11e4-a52e-4f735466cecf": "d1b3cd4b-2847-4e1e-943e-e0c732acf831"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:37:58] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 147 (connectionpool.py:465)
[2022-03-10 01:37:58] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "5ae297a5-7817-41c2-8736-9784adcd6dc4", "element-6066-11e4-a52e-4f735466cecf": "5ae297a5-7817-41c2-8736-9784adcd6dc4"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:38:00] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 147 (connectionpool.py:465)
[2022-03-10 01:38:00] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "d8db293a-8925-4860-9ca9-8b9d89b6147f", "element-6066-11e4-a52e-4f735466cecf": "d8db293a-8925-4860-9ca9-8b9d89b6147f"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:38:02] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 147 (connectionpool.py:465)
[2022-03-10 01:38:02] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:04] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "b22a25c7-70bf-405b-86dc-65a7595e002c", "element-6066-11e4-a52e-4f735466cecf": "b22a25c7-70bf-405b-86dc-65a7595e002c"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:38:04] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 147 (connectionpool.py:465)
[2022-03-10 01:38:04] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "f4ab8b30-09e9-48bd-ac10-c7c41e60970c", "element-6066-11e4-a52e-4f735466cecf": "f4ab8b30-09e9-48bd-ac10-c7c41e60970c"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:38:06] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 153 (connectionpool.py:465)
[2022-03-10 01:38:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:45465/session/d182ee3fa66942ee608863b75819b85c/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "aafc5725-e447-4ccf-afbc-84e98aaf7204", "element-6066-11e4-a52e-4f735466cecf": "aafc5725-e447-4ccf-afbc-84e98aaf7204"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:38:08] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:45465 "POST /session/d182ee3fa66942ee608863b75819b85c/execute/sync HTTP/1.1" 200 146 (connectionpool.py:465)
[2022-03-10 01:38:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47735/session/55c516efb89dcb599220e6a2ae83a9fa/url {"url": "https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA"} (remote_connection.py:388)
[2022-03-10 01:38:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47735 "POST /session/55c516efb89dcb599220e6a2ae83a9fa/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47735/session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47735 "POST /session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47735/session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:13] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47735 "POST /session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:15] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47735/session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:15] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47735 "POST /session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:15] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47735/session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:17] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47735 "POST /session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47735/session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:19] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47735 "POST /session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47735/session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:19] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47735 "POST /session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47735/session/55c516efb89dcb599220e6a2ae83a9fa/elements {"using": "xpath", "value": "//img[contains(@alt, '\u9a6c\u516c\u673a\u573a')]"} (remote_connection.py:388)
[2022-03-10 01:38:19] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47735 "POST /session/55c516efb89dcb599220e6a2ae83a9fa/elements HTTP/1.1" 200 90 (connectionpool.py:465)
[2022-03-10 01:38:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:47735/session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "8d914d49-35f2-461c-889d-5aba051bfda0", "element-6066-11e4-a52e-4f735466cecf": "8d914d49-35f2-461c-889d-5aba051bfda0"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:38:19] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:47735 "POST /session/55c516efb89dcb599220e6a2ae83a9fa/execute/sync HTTP/1.1" 200 150 (connectionpool.py:465)
[2022-03-10 01:38:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:21] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38291/session/77f73e01d3d750e03288fe25f66e952d/url {"url": "https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6"} (remote_connection.py:388)
[2022-03-10 01:38:23] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38291 "POST /session/77f73e01d3d750e03288fe25f66e952d/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38291/session/77f73e01d3d750e03288fe25f66e952d/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:23] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38291 "POST /session/77f73e01d3d750e03288fe25f66e952d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38291/session/77f73e01d3d750e03288fe25f66e952d/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:25] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38291 "POST /session/77f73e01d3d750e03288fe25f66e952d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38291/session/77f73e01d3d750e03288fe25f66e952d/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:27] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38291 "POST /session/77f73e01d3d750e03288fe25f66e952d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:29] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38291/session/77f73e01d3d750e03288fe25f66e952d/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:29] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38291 "POST /session/77f73e01d3d750e03288fe25f66e952d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:29] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38291/session/77f73e01d3d750e03288fe25f66e952d/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:31] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38291 "POST /session/77f73e01d3d750e03288fe25f66e952d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38291/session/77f73e01d3d750e03288fe25f66e952d/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:31] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38291 "POST /session/77f73e01d3d750e03288fe25f66e952d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38291/session/77f73e01d3d750e03288fe25f66e952d/elements {"using": "xpath", "value": "//img[contains(@alt, '\u88c5\u7532\u6551\u62a4\u8f66')]"} (remote_connection.py:388)
[2022-03-10 01:38:31] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38291 "POST /session/77f73e01d3d750e03288fe25f66e952d/elements HTTP/1.1" 200 90 (connectionpool.py:465)
[2022-03-10 01:38:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38291/session/77f73e01d3d750e03288fe25f66e952d/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "4b5e41d0-2da1-41c7-8210-cf8a82d16bbb", "element-6066-11e4-a52e-4f735466cecf": "4b5e41d0-2da1-41c7-8210-cf8a82d16bbb"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:38:31] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38291 "POST /session/77f73e01d3d750e03288fe25f66e952d/execute/sync HTTP/1.1" 200 146 (connectionpool.py:465)
[2022-03-10 01:38:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:33] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38757/session/77e5642a14253f900ef3ee5e000832cd/url {"url": "https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA/19178695"} (remote_connection.py:388)
[2022-03-10 01:38:34] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38757 "POST /session/77e5642a14253f900ef3ee5e000832cd/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38757/session/77e5642a14253f900ef3ee5e000832cd/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:34] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38757 "POST /session/77e5642a14253f900ef3ee5e000832cd/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:34] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:36] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38757/session/77e5642a14253f900ef3ee5e000832cd/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:36] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38757 "POST /session/77e5642a14253f900ef3ee5e000832cd/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:36] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:38] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38757/session/77e5642a14253f900ef3ee5e000832cd/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:38] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38757 "POST /session/77e5642a14253f900ef3ee5e000832cd/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:38] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:40] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38757/session/77e5642a14253f900ef3ee5e000832cd/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:40] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38757 "POST /session/77e5642a14253f900ef3ee5e000832cd/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:40] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38757/session/77e5642a14253f900ef3ee5e000832cd/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:42] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38757 "POST /session/77e5642a14253f900ef3ee5e000832cd/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38757/session/77e5642a14253f900ef3ee5e000832cd/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:42] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38757 "POST /session/77e5642a14253f900ef3ee5e000832cd/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38757/session/77e5642a14253f900ef3ee5e000832cd/elements {"using": "xpath", "value": "//img[contains(@alt, '\u76f4\u5347\u673a')]"} (remote_connection.py:388)
[2022-03-10 01:38:42] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38757 "POST /session/77e5642a14253f900ef3ee5e000832cd/elements HTTP/1.1" 200 90 (connectionpool.py:465)
[2022-03-10 01:38:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:38757/session/77e5642a14253f900ef3ee5e000832cd/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "8cd9777d-d8c0-4f40-868a-12bf47745c14", "element-6066-11e4-a52e-4f735466cecf": "8cd9777d-d8c0-4f40-868a-12bf47745c14"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:38:42] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:38757 "POST /session/77e5642a14253f900ef3ee5e000832cd/execute/sync HTTP/1.1" 200 150 (connectionpool.py:465)
[2022-03-10 01:38:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50675/session/1b90ffb39113ad9058ade9e3ae53db0f/url {"url": "https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6"} (remote_connection.py:388)
[2022-03-10 01:38:46] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50675 "POST /session/1b90ffb39113ad9058ade9e3ae53db0f/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50675/session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:46] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50675 "POST /session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50675/session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:48] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50675 "POST /session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50675/session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:50] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50675 "POST /session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:52] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50675/session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:52] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50675 "POST /session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:52] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50675/session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:54] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50675 "POST /session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50675/session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:38:54] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50675 "POST /session/1b90ffb39113ad9058ade9e3ae53db0f/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:38:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:54] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50675/session/1b90ffb39113ad9058ade9e3ae53db0f/elements {"using": "xpath", "value": "//img[contains(@alt, '\u88c5\u7532\u626b\u96f7\u8f66')]"} (remote_connection.py:388)
[2022-03-10 01:38:55] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50675 "POST /session/1b90ffb39113ad9058ade9e3ae53db0f/elements HTTP/1.1" 200 12 (connectionpool.py:465)
[2022-03-10 01:38:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6>
{'attributes': {'img_url': {},
                '中文名': '装甲扫雷车',
                '作用': '用来清除地雷',
                '分类': '车轮或者是履带型态',
                '实质': '作战工具'},
 'content': '装甲扫雷车特指装有清除地雷装置的装甲车辆，以协助地面部队扩速通过地雷区。装甲扫雷车可以是专门设计用来清除地雷，或者是将清除工具附加在一般用途的装甲车辆上面，长时间担任地雷排除的任务的装甲车辆。无论是车轮或者是履带型态的扫雷车都可见于不同国家的部队当中。简介装甲扫雷车并非用于清除整个被发现的地雷区，而是将地雷区清理出一至数条的安全信道，提供地面部队人员和车辆安全通过。排除的地雷可能在过程中加以引爆，或者是移动到安全的地方之后另外加以处理。由于清理的过程当中，扫雷车可能碰触或者是引爆其他尚未发现的地雷或者是爆裂物，车辆本身对于底盘和车辆底部的保护需要特别加强，以免轻易的被地雷或者是爆裂物瘫痪而无法完成清除的任务。',
 'date': '',
 'keyword': '装甲扫雷车',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6'} (scraper.py:257)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:38:55] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 959,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 2995,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 101.647134,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 38, 55, 509744),
 'httpcompression/response_bytes': 4555,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 262,
 'log_count/INFO': 44,
 'log_count/WARNING': 1,
 'memusage/max': 67993600,
 'memusage/startup': 67993600,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 3, 10, 1, 37, 13, 862610)} (statscollectors.py:47)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:38:55] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 931,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 2824,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 105.0329,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 38, 55, 511100),
 'httpcompression/response_bytes': 4555,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 283,
 'log_count/INFO': 71,
 'log_count/WARNING': 1,
 'memusage/max': 67403776,
 'memusage/startup': 67403776,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 3, 10, 1, 37, 10, 478200)} (statscollectors.py:47)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:38:55] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 924,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 2971,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 108.373895,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 38, 55, 512794),
 'httpcompression/response_bytes': 4555,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 304,
 'log_count/INFO': 98,
 'log_count/WARNING': 1,
 'memusage/max': 66707456,
 'memusage/startup': 66707456,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 3, 10, 1, 37, 7, 138899)} (statscollectors.py:47)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:38:55] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:38:55] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:38:55] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:38:55] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min) (logstats.py:48)
[2022-03-10 01:38:55] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:38:55] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:38:55] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:38:55] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 412,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 36129,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 100.545514,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 38, 55, 541726),
 'httpcompression/response_bytes': 194515,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 255,
 'log_count/INFO': 52,
 'log_count/WARNING': 1,
 'memusage/max': 86867968,
 'memusage/startup': 68218880,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 37, 14, 996212)} (statscollectors.py:47)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/2934349b033b5bb56eefbaf336d3d539b600bc87?x-bce-process=image/resize,m_lfit,w_278,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/2934349b033b5bb56eefbaf336d3d539b600bc87?x-bce-process=image/resize,m_lfit,w_278,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing BmpImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing BufrStubImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing CurImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing DcxImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing DdsImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing EpsImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing FitsStubImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing FliImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing FpxImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing FtexImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing GbrImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing GifImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing GribStubImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing Hdf5StubImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing IcnsImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing IcoImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing ImImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing ImtImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing IptcImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing JpegImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing Jpeg2KImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing McIdasImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing MicImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing MpegImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing MpoImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing MspImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing PalmImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing PcdImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing PcxImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing PdfImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing PixarImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing PngImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing PpmImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing PsdImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing SgiImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing SpiderImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing SunImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing TgaImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing TiffImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing WebPImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing WmfImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing XbmImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing XpmImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [ PIL.Image ] - Importing XVThumbImagePlugin (Image.py:397)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_220,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_220,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/9e3df8dcd100baa1d818ddb64710b912c8fc2e82?x-bce-process=image/resize,m_lfit,w_400,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/9e3df8dcd100baa1d818ddb64710b912c8fc2e82?x-bce-process=image/resize,m_lfit,w_400,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/d4628535e5dde71190eff0d94da1d91b9d16fdfacbc7?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/d4628535e5dde71190eff0d94da1d91b9d16fdfacbc7?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/6f061d950a7b020881cd22c262d9f2d3572cc889?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/6f061d950a7b020881cd22c262d9f2d3572cc889?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/c8177f3e6709c93d07727cf99f3df8dcd100543f?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/c8177f3e6709c93d07727cf99f3df8dcd100543f?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/1b4c510fd9f9d72a6f12657dd42a2834349bbb5f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/1b4c510fd9f9d72a6f12657dd42a2834349bbb5f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/8601a18b87d6277f9e2ff24e20760830e924b899563c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/8601a18b87d6277f9e2ff24e20760830e924b899563c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/29381f30e924b8997cb60b366e061d950a7bf632?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/29381f30e924b8997cb60b366e061d950a7bf632?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/3c6d55fbb2fb43163aac9c552da4462309f7d36a?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/3c6d55fbb2fb43163aac9c552da4462309f7d36a?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/bf096b63f6246b60e2b1d7dfe1f81a4c500fa2da?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/bf096b63f6246b60e2b1d7dfe1f81a4c500fa2da?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/e7cd7b899e510fb3b92f6774d233c895d1430c1a?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/e7cd7b899e510fb3b92f6774d233c895d1430c1a?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6>
{'attributes': {'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/d4628535e5dde71190eff0d94da1d91b9d16fdfacbc7?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '装甲运输车',
                '主要分类': '履带式和轮式'},
 'content': '装甲运输车是指：具有较好机动性能的装甲战斗输送车辆，分履带式和轮式两种。该种车为装甲车族的基本型车，主要用于战时输送人员或坦克、步战车后跟进作战，有时也可运送作战物资等，一般可输送一个班的兵力，其武器装备为1-2挺机枪，通常具备水陆两用性能。',
 'date': '',
 'keyword': '装甲运输车',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6'} (scraper.py:257)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:38:55] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 895,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 61250,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 99.643827,
 'file_count': 1,
 'file_status_count/downloaded': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 38, 55, 777311),
 'httpcompression/response_bytes': 193954,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 319,
 'log_count/INFO': 47,
 'log_count/WARNING': 1,
 'memusage/max': 86867968,
 'memusage/startup': 68403200,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 37, 16, 133484)} (statscollectors.py:47)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/908fa0ec08fa513d26972468a62342fbb2fb4316737c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/908fa0ec08fa513d26972468a62342fbb2fb4316737c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6>
{'attributes': {'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/6f061d950a7b020881cd22c262d9f2d3572cc889?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '装甲救护车',
                '作用': '辆',
                '特点': '装甲车',
                '类型': ''},
 'content': '指在战场环境下实行人员救护的装甲车辆，一般只装备一至两挺机枪作为自卫武器，防护力亦很弱。用于抢救人员，并将重伤员运送至后方。[1]\xa0'
            '用于敌火力下救护和运送伤员的轻型装甲车辆。分为履带式装甲救护车和轮式装甲救护车和轮式装甲救护车两种。车上通常配有医疗急救设备、器材和药品等。[2]\xa0',
 'date': '',
 'keyword': '装甲救护车',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6'} (scraper.py:257)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:38:55] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 896,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 58554,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 98.526236,
 'file_count': 1,
 'file_status_count/downloaded': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 38, 55, 799585),
 'httpcompression/response_bytes': 198889,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 315,
 'log_count/INFO': 42,
 'log_count/WARNING': 1,
 'memusage/max': 86867968,
 'memusage/startup': 68587520,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 37, 17, 273349)} (statscollectors.py:47)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA/19178695>
{'attributes': {'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/8601a18b87d6277f9e2ff24e20760830e924b899563c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '直升机',
                '厂商': '互联网',
                '游戏平台': 'Android',
                '游戏类别': '飞行游戏',
                '语言类型': '英语',
                '资费提示': '完全免费',
                '软件格式': 'apk'},
 'content': '直升机是一款Android游戏。游戏中玩家要躲避障碍物；该游戏是直升机在一个山洞里飞行，但不要撞上墙壁，该有是一个很容易上瘾，简单的游戏，它的功能，操作方便和简单的用户界面。《直升机》，与《侠盗猎车》GameA经典直升机游戏，能够跻身前10名最流行的游戏。该游戏是直升机在一个山洞里飞行，但不要撞上墙壁，避免传入obstacles.The的时间越长，试点直升机，better.Don‘T忘记领取奖金框drop '
            'ing下来，它可以帮助你的直升机生存崩溃。回到当PC开始出现，成为跻身世界流行的那些昔日，尽管当时的那些游戏很简单，也许有点沉闷相比，这些游戏，但他们充满在我们的自由时间的空白，并永远留在我们的记忆中。那些经典的游戏，通过不眠之夜，艰难的时刻伴随着我们，见证了我们的成功和failure.Let“开始重播那些老games.This之旅，是一个很容易上瘾，简单的游戏，它的功能，操作方便和简单的用户界面。[1]\xa0',
 'date': '',
 'keyword': '直升机',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA/19178695'} (scraper.py:257)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:38:55] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1409,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 175084,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 103.075054,
 'file_count': 1,
 'file_status_count/downloaded': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 38, 55, 822530),
 'httpcompression/response_bytes': 205214,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 344,
 'log_count/INFO': 77,
 'log_count/WARNING': 1,
 'memusage/max': 86867968,
 'memusage/startup': 67809280,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 3, 10, 1, 37, 12, 747476)} (statscollectors.py:47)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6>
{'attributes': {'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/3c6d55fbb2fb43163aac9c552da4462309f7d36a?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto',
                            '图片2': 'https://bkimg.cdn.bcebos.com/pic/2934349b033b5bb56eefbaf336d3d539b600bc87?x-bce-process=image/resize,m_lfit,w_278,limit_1/format,f_auto',
                            '图片3': 'https://bkimg.cdn.bcebos.com/pic/9e3df8dcd100baa1d818ddb64710b912c8fc2e82?x-bce-process=image/resize,m_lfit,w_400,limit_1/format,f_auto',
                            '图片4': 'https://bkimg.cdn.bcebos.com/pic/29381f30e924b8997cb60b366e061d950a7bf632?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto',
                            '图片5': 'https://bkimg.cdn.bcebos.com/pic/c8177f3e6709c93d07727cf99f3df8dcd100543f?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto',
                            '图片6': 'https://bkimg.cdn.bcebos.com/pic/1b4c510fd9f9d72a6f12657dd42a2834349bbb5f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto',
                            '图片7': 'https://bkimg.cdn.bcebos.com/pic/bf096b63f6246b60e2b1d7dfe1f81a4c500fa2da?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '装甲侦察车',
                '作用': '装甲',
                '分类': '战斗车辆',
                '定义': '配备有侦察设备的'},
 'content': '装甲侦察车具有战场观察、目标搜索、识别、定位、处理和传输能力。有轮式装甲侦察车和履带式装甲侦察车两种，以轮式装甲侦察车为主。装甲侦察车现代装甲侦察车一般装有大倍率光学潜望镜、电视摄像机、热像仪、激光测距仪、雷达定位定向、信息处理和信息传输设备等。为便于远距离观察，车上的观察设备通常设有旋转和升降装置。大倍率光学潜望镜和电视摄像机主要用于能见度良好的夜间进行侦察，发现目标距离不小于20千米，识别装甲车辆距离为10～15千米，并具有电视自动跟踪能力。热像仪主要用于夜间侦察，夜间识别装甲车辆的距离不小于3千米。激光测距仪的最大测量距离不小于20千米，误差一般为5米。雷达可全天候实施侦察，具有多目标自动跟踪能力，对装甲车辆的探测距离不小于25千米，对单兵的最大探测距离不小于10千米。定位定向设备通常由全球卫星定位装置和惯性定位定向装置组成，用于实现装甲侦察车自动寻北、定位导航，寻北精度3密位，定位精度10～20米。信息处理设备由计算机等组成，可对侦察到的目标与图像进行采集、存储和叠加属性、数量、时间、坐标等，并在电子地图上进行自动标注。信息传输设备由微波电视传输设备和电台组成，具有数字通信和网络通信能力，可将侦察到的信息及时传递给其他作战单元。有的装甲侦察车上还装有红外报警器、地面激光目标指示器和核、化、生探测报警器等。履带式装甲侦察车的最大机动速度为90千米/时，轮式装甲侦察车可达125千米/时。车上装有20～30毫米机关炮和机枪，有的还装有76～105毫米火炮，也有的同时装有火炮和反坦克导弹发射装置。[1]\xa0'
            '20世纪30年代后期，美、德、英等国相继用装甲车改装成装甲侦察车，并用于实战。50～60年代，出现了专门研制的装甲侦察车，典型的有法国的EBR、英国的“白鼬”2/3型、苏联的BRDM-1/2型等。70年代以后，装甲侦察车广泛采用先进的光电设备，使装甲侦察车的侦察能力有很大提高。典型的有美国的M2A3“布雷德利”步兵战车、英国的“佩刀”、德国的“山猫”、俄罗斯的BRM和南非的“大山猫”装甲侦察车等。中国于80年代初开始研制装甲侦察车，90年代末装备部队。装甲侦察车的侦察设备将向探测距离远、分辨能力高、信息传输速度快、全天候性能好和抗干扰能力强的方向发展，进一步提高装甲侦察车的生存能力、隐身能力、感知能力和通信能力。[1]\xa0'
            '世界上各国军队，列装有多种型号的专用装甲侦察车，下面主要谈谈轮式装甲侦察车，外军比较有名的有：德国的山猫2型轮式侦察车、法国的VBC90轮式侦察车，俄罗斯的БРДМ-2型轮式侦察车，最新的还有以色列的侦察/监视装甲车--RAM-2000，德国威格曼公司和荷兰宇航车辆公司联合研制的非洲小狐轻型4×4底盘的轮式装甲侦察车等。前苏联陆军的每1摩托化步兵师装备28辆БРДМ-2型轮式侦察车，其中侦察营12辆，坦克团和3个不同装备的摩托化步兵团各4辆；坦克师也装备28辆，其中侦察营12辆，摩托化步兵团和3个坦克团各4辆。紧跟世界军事变革的中国军队，对轮式轻型机械化部队的建设也搞的热火朝天，各种轮式底盘的系列主战装备，纷纷配套列装我军机步师[旅]，已见的有轮式92A型步战车，轮式92B型人员输送车；100毫米轮式自行突击炮；轮式120毫米自行迫榴炮，轮式122毫米自行榴弹炮，轮式倚天防空导弹车；轮式指挥，通信，抢修，救护等辅助车辆，为独很少见到具有重要作用的轮式战场装甲侦察车。[2]\xa0'
            '装甲侦察车装甲侦察车已见的只有三种左右，一种是过去在露脸的一种侦察车，这种专用侦察车，像是80年代试研产品，从照片看中国这款新型轮式装甲侦察车，采用4X4轮式底盘，侦察车由均质钢装甲板焊接而成，侧面形状低矮，易于隐蔽。正面为尖锐的契形，具有良好的防弹性能。该车顶部配有钢围板的枪塔一座，内装12.7毫米口径高平两用重机枪一挺，车体前部，左右各有一个凸起的装防弹玻璃的观察窗，用于驾驶和侦察，其它技术性能不详，车的样子感觉怪怪的，用网友的话说像土鳖.后来没有消息，不知可否列装部队…….另一种是与中国军队对外军贸产品：90--B型122毫米火箭炮配套出口的轮式90B型炮兵侦察车，还有一种是电视上济南战区127机步师[铁军]演习中露脸的一种轮式车辆，怀疑是侦察车.当然各位军迷大虾如有新发现和照片请指教贴图。[3]\xa0'
            '第一种装甲侦察车，过于简单，除车裁武器外，也没见可伸缩的观侦设备，可能属于试制性质，在此不在多说.后二种采用了与92轮式步战车相同的，WMZ551B轮式6X6底盘，车体上装有一挺12.7毫米重机枪和可伸缩的观侦设备，但该车体长6.8米，宽2.86米，高2.87米，战斗全重为15.3吨，距地高0.41米，虽然采用与92车族通用的底盘，有利于战时后勤保障，但敝人认为，选用与92轮式步战车相同的，WMZ551B轮式6X6底盘，做为专用装甲侦察车底盘,车体过于高大，不利于战场隐蔽侦察。除了轮式底盘通用，便于后勤保障外，就车型来说，不是最佳的选型。狐式轻型轮式装甲侦察车狐式轻型轮式装甲侦察车[4]\xa0'
            '该车于1965年由当时的战车研究发展院(Fighting Vehicles Research and Development '
            'Establishment)即现在的彻特西皇家武器装备研究与发展院(Royal Armament Research and '
            'Development Establishmen,Chertsey)研制，次年与戴姆勒公司(Daimler '
            'Company)签订了生产15辆样车的合同。第一辆样车于1967年11月完成，最后一辆于1969年4月完成，1968年开始进行试验。1969年10月第一次公布研制成功了狐式侦察车。1970年英国陆军接受庐车服役。1972年由利兹皇家兵工厂（Royal '
            'Ordnance '
            'Leeds)生产，1973年3月完成第一辆生产型车。英国陆军的正规部队和预备部队均使用该车，阿尔维斯（Alvis)公司为该车提供焊接的铝合金炮塔。RAM轻型轮式装甲侦察车族该车采用全焊接的铝合金装甲车体和炮塔，可防中重型枪弹和弹片。驾驶员位于车体前部，前方吊装1个向右开的舱盖，其上有1个整体式广角潜望镜，该潜望镜可迅速换为被动式夜视潜望镜。炮塔位于车体中央，车长兼装填手在左侧，炮长位于右侧，各有1个单扇向后开启的舱盖。车长有1个装在旋转架上的1×和10×的双筒监视潜望镜，并有7个观察潜望镜。炮长有1个与主炮相连的1×、10×的双筒潜望镜式昼夜瞄准镜和2个观察潜望镜。主炮右侧安装兰克精密工业（Rank '
            'Precision '
            'Industries)公司SPAVL2A1被动式夜视仪，有两种倍率和视野，5.8×，8×视野的用于瞄准；1.6×，28×视野的用于监视，2种倍率不会发生干涉。像增强管由遮光帘保护，不受炮口闪光的危害，遮光帘是由火炮发射系统电动控制的。当选用高倍率时，带有亮度控制的照明弹道分划镜被自动引入光学系统。物镜带刮水器，瞄准镜由装甲盖防护。轮式专用装甲侦察车动力舱后置，发动机和传动装置为一整体，可从车后装拆。发动机采用双阻风门化油器，带有冷起动设备。传动装置是带液力偶合器的预选排档行星齿轮变速箱。冷却系统包括2个散热器，水平布置在发动机后部顶上，在散热器之间有1对离心风扇。发动机和传动装置的润滑油靠1个油水散热器冷却。该车采用独立悬挂，由上下叉形杆、螺旋弹簧和筒式液压减振器组成。上下叉形杆的连接部分兼作润滑油箱，减振器装在螺旋弹簧内。车轮的最大垂直行程为0.279m。该车在无任何准备的情况下可涉水深1m。车上的浮渡围帐2min内即可准备好，在水上靠车轮推进和转向。浮渡围帐的前部有1供观察用的透明板并装有流量为205L/min的排水泵。服役于英国陆军的狐式侦察车已去掉了浮渡围帐。该车装备30mm的拉登（RARDEN)炮，可发射多种炮弹，可单发也可6发连射，空弹壳自动弹出车外。主炮左侧有1挺7.62mm的并列机枪。炮塔前部两侧各有4个烟幕弹发射器。所有武器均电控，主炮和并列机枪可手动超越控制。无线电设备安装在炮塔后部，该车的工作环境温度为零下40°～零上50°并可以空运。该车的制式设备包括红外滤光灯、聚光灯、外部储油箱、13.6L的饮水箱和1个电气接线盒等。任选设备包括导航设备、动力回转装置、核和化学探测设备及ZB298监视雷达。[5]\xa0'
            '随着地面战争发生了巨大变化，装甲侦察车也不例外。装甲侦察车的传统功能一直是在主力部队之前侦察并收集有关敌军和前方地形的准确战术信息，将信息发送给指挥官。侦察分队也可以执行侧翼掩护、路线侦察及护航任务。4×4型侦察车曾是典型的老一代轻型侦察车，由于外形尺寸小而不易被发现，并且仅装备机枪，如英国的“白鼬”（Ferret）和前苏联的BRDM-2。这些车辆的观察设备仅限于昼用瞄具和红外夜视器材，信息通过无线电台传递到下一指挥链，无线电波可能会被中途截获；车辆几乎无法准确地测定自己的位置。后来红外夜视装置逐渐被二代图像增强系统所取代，最近又被热像仪取代。尽管后者通常相当昂贵，但目标探测和识别的距离比过去远许多。新一代侦察车通常配有先进的侦察系统，包括昼用摄像机、热像仪、人眼安全激光测距机、精确地面导航系统和先进的通信系统。通过这些设备可以把数据实时传递到下一指挥链或高一级指挥层。当许多国家仍在使用装备精良的装甲平台执行侦察任务时，一些国家已开始装备带有专用传感器组件的小型车辆。未来侦察系统正逐渐演变为传感器平台，该平台与前几代平台最显著的区别是：传感器、通信和导航设备远比平台本身昂贵。关于侦察车应是轮式还是履带式的争论已持续了许多年，尚没有迹象表明这场争论会停止，最终方案取决于作战要求和预期地形。已被终止的英美TRACER/FSCS就是现代侦察平台的一个范例。Sika和Lancer财团各研制了一辆先进的全履带式样车，两者都装有遥控型40毫米埋头弹（CTA）武器系统。3名乘员坐在车内使用平面显示器，上面显示来自多个传感器的各种信息。车辆的隐身特征使其不易被探测到，橡胶带式履带能降低噪音，如果需要还可采用混合电传动系统来进行静默行驶。在当今的高科技世界，装甲侦察车仅是与指挥、控制、通信和计算机（C4）网络连接在一起的整个侦察、监视和目标捕获（RSTA）组件的一个组成部分。RSTA组件中还包括：卫星等各种空中传感器平台、各种固定翼和旋翼飞机及无人机（UAV）。由于信息需要很长时间才能传给用户，老式无人机的使用受到限制。包括雷达在内的各种地面传感器可提供关于敌军转移的信息，或为火炮和火箭系统定位打击目标。白俄罗斯监视器服务公司（MONITOR '
            'SERVISE）研制的2T Stalker是最近推出的侦察车之一，该车已在中东演示过多次。2T '
            'Stalker属于全履带式车辆，装备1门30毫米机关炮和1挺7.62毫米并列机枪，车顶装有两个导弹发射架：一个包括两枚发射后不管型地对空导弹，另一个包括两枚9K114 '
            'Kokon '
            '反坦克导弹。该车配有一套复杂的昼/夜火控系统。加拿大武装部队选择现在通用动力地面系统分部加拿大分公司研制的“小狼”（Coyote）来替代联合防御公司的“山猫”（Lynx）全履带式指挥侦察车。“小狼”以8×8型轻型装甲车（LAV）底盘为基础，并且保留了通用动力地面系统分部加利福尼亚技术中心研制的25毫米LAV-25炮塔。加拿大共采购约203辆“小狼”，由3种车型组成：一种装有桅杆式传感器组件；一种装有两个三脚架传感器组件；一种主要用于接收数据，但不装备传感器组件。桅杆式传感器组件装在炮塔后部，在不需要时可收在装甲下。桅杆顶端的传感器吊舱包括：1台监视雷达、1架远程电视摄像机（据称昼夜识别/探测距离可达18千米）和1具人眼安全激光测距机。桅杆在全装甲和核生化防护下可升高至10米。捷克VOP '
            '026 '
            '厂自称在履带式和轮式装甲车升级与维护方面具有丰富的经验。该国的Snezka侦察车是一种较新的平台，该车以加长型BMP底盘为基础，两侧各有7个负重轮。顶置式剪刀型装备中包括一套由雷达、昼夜电视摄像机、热成像摄像机、激光测距机和风速测量系统组成的传感器组件。把传感器吊舱升至顶端需要90秒，降下则需1分钟。Snezka侦察车还装有一套霍尼韦尔 '
            'TALIN '
            '导航系统和多种通信设备。该车已在捷克服役多年，并与以BMP底盘为基础的轻型观察系统（LOS）一起使用，LOS将部署在Snezka侦察车前方。LOS使用1门30毫米机关炮和带有昼夜电视系统、人眼安全激光测距机和激光目标标识/指示器的可伸缩式桅杆式传感器吊舱。该车还配有惯性导航系统和多种通信设备。VOP '
            '026 '
            '厂还为广泛使用的俄罗斯4×4型BRDM-2装甲车开发了一套升级组件，其中包括用柴油机代替汽油机，并拆除了车底备用轮胎。法国陆军使用装备105毫米炮的6×6型AMX-10RC装甲车和潘哈德4×4型VBL侦察车与勒克莱尔坦克协同作战。6×6型车辆已接受了延长使用寿命的改进，改进内容包括：炮塔、悬挂装置和传动装置，并安装热成像摄像机和终端信息系统。法国陆军装备1200多辆VBL侦察车，该车的生产还将持续多年。至少有9家海外客户购买了VBL，用于执行侦察、反坦克和防空等多种任务。标准车型的轴距为2.45米，此外还有长轴距车型（轴距为2.7米）。除了各种武器站，VBL还可安装桅杆式传感器吊舱。法国陆军还有192辆潘哈德6×6型ERC '
            '90 '
            'Sagaie装甲车，广泛用在非洲，巴尔干和中东地区。这些车辆将进行多方面升级，包括用燃油效率更高的柴油机代替标致V-6汽油机。ACMAT公司在已被验证的ACMAT底盘的基础上开发了VLRB装甲联络侦察车。为适应不同作战需求，该车可以装备不同的传感器组件和武器系统。该车也用作ACMAT公司与法国地面武器工业集团和泰利斯光电公司共同研制的SYPORA侦察系统的基础。VLRB车顶上装有泰利斯装甲战车（AFV）系统稳定型武器和侦察底座（SWARM）、M2式12.7毫米机枪和传感器组件。德国陆军使用莱茵金属公司地面系统分部研制的“鼬鼠” '
            '1空降车已有多年，该车装有“陶”式反坦克导弹或20毫米机关炮。约30辆装有“陶”式反坦克导弹的“鼬鼠”1最近被改装为侦察车，为此拆除了“陶”式导弹系统，在凸起的车顶上安装了新的上部结构，后部是一个可伸缩式桅杆，顶端装有STN '
            'Atlas Elektronik '
            'AOZ自动瞄准系统。莱茵金属公司地面系统分部生产的8×8型“山猫”（Luchs）侦察车多年来一直是德国陆军的制式侦察车，该车重20t，有3名乘员，其双人炮塔上装有20毫米机关炮和7.62毫米机枪，配有1具一代热像仪。ARGE '
            'Fennek财团（由荷兰SP宇航与车辆系统公司和德国克劳斯－玛菲·威格曼公司组成）研制的新型“非洲小狐”（Fennek）侦察车将取代“山猫”。根据目前的计划，德国陆军将接收202辆“非洲小狐”侦察车，而荷兰将接受410辆；首批车辆即将交付荷兰皇家陆军。侦察车型装有STN '
            'Atlas '
            'Elektronik研制的桅杆式传感器组件，该组件包括昼用热成像光学设备和人眼安全激光测距机。该车还装有导航系统和多种通信系统。以色列飞机工业公司RAMTAD分部研制了4×4型RAM系列轻型装甲车，除了作为武器平台外，这些车辆还可用作侦察车。几年前意大利陆军决定用8×8型105毫米“圣陶罗”（Centauro）装甲车补充其坦克车队。这些车辆被广泛用在索马里和巴尔干地区。“圣陶罗”拥有“豹” '
            '1坦克一样的火力，但其速度更快，战略机动性更强。意大利陆军已接收400辆“圣陶罗”，西班牙则已接收首批22辆，并又定购了62辆。最近由依维柯防务公司车辆分部与奥托·梅拉拉公司组成的依维柯·奥托财团研制了一种装备120毫米火炮的“圣陶罗”车型 '
            '，以及一个完整的特种车车族，其中包括装甲人员输送车。依维柯公司负责底盘，奥托·梅拉拉公司负责炮塔和武器装备。为满足意大利陆军的需求，依维柯公司还研制了轻型多用途车（LMV），英国阿尔维斯维克斯公司也在销售这种车辆。该车可用于完成多种任务，并装有顶置式武器站和监视组件。今年7月中旬该车被选作英国陆军的未来指挥联络车，预计英国陆军要采购486辆。波兰陆军装备有俄制4×4型BRDM-2侦察车，并开发了一些延长这些车辆使用寿命的升级组件。96I型车辆的特点是采用新型依维柯柴油机，拆除车底备用轮胎，车体和炮塔两侧各有一扇门，保留14.5毫米和7.62毫米机枪。97型车辆采用了类似的改进方案，但对炮塔进行了改装，安装了1具顶置式9K111系列Fagot反坦克制导武器，并用12.7毫米NSTV武器代替了14.5毫米机枪。96I型和97型正在服役，而最新的98型仍处在样车阶段，该车与97型类似，但还装有STN '
            'Atlas Elektronik BAA 观察与瞄准系统',
 'date': '',
 'keyword': '装甲侦察车',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6'} (scraper.py:257)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:38:55] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 3794,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 196250,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 97.448658,
 'file_count': 7,
 'file_status_count/downloaded': 7,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 38, 55, 873783),
 'httpcompression/response_bytes': 260598,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 310,
 'log_count/INFO': 40,
 'log_count/WARNING': 1,
 'memusage/max': 86867968,
 'memusage/startup': 68767744,
 'response_received_count': 8,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 37, 18, 425125)} (statscollectors.py:47)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA>
{'attributes': {'IATA代码': 'HUN',
                'ICAO代码': 'RCYU',
                'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_220,limit_1/format,f_auto',
                            '图片2': 'https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto',
                            '图片3': 'https://bkimg.cdn.bcebos.com/pic/e7cd7b899e510fb3b92f6774d233c895d1430c1a?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '花莲机场',
                '外文名': 'Hualien Airport',
                '所属地区': '',
                '机场类型': '台湾省',
                '运营机构': '花莲县新城乡',
                '通航日期': '1962年5月16日'},
 'content': '花莲机场，位于台湾省花莲县新城乡，在花莲县花莲市北方，其正式操作单位为台湾交通部民用航空局花莲航空站，同时也是台湾“国防部”位于花莲的军用机场。航空运输协会所制定的IATA机场代码为HUN；在国际民航组织所制定的ICAO机场代码为RCYU。花莲机场(2张)花莲机场（Hualien '
            'Airport）是位于中国台湾省花莲县新城乡的一座军民合用的机场，由交通部民用航空局花莲航空站运营管理，为花莲县及其周边地区提供航空服务。花莲机场的前身是日治时期的“花莲港北飞行场”，兴建于1936年，属于军民共用的机场，由日本航空株式会社经营。第二次世界大战结束后，由中华民国政府接收。1962年5月16日，花莲航空站成立，花莲机场正式投入使用，海拔高度为16米（52英尺）。机场共有两条跑道，即长宽分别为2750米×45米的03/21跑道和344米×20米的03L/21R跑道。花莲机场先后于2002年和2005年经历具有标志性的改扩建工程。新客运航站楼于2004年3月19日正式对外开放，总投资23亿新台币（6900万美元）。此外，该机场还有一座独立的货运航站楼供货运使用。花莲机场主营台湾地区性的定期航线和通往中国大陆地区的短途航班，直飞高雄、台中、台北、济南和天津等地，它是马英九政府开放两岸包机直航的航线。华信航空和TranAsia航空是该机场的主要运营商。[1]\xa0'
            '2004年3月19日：新航厦正式营运。其建筑融合了台湾原住民传统住屋，与汉族合院式住宅的特色。2004年8月8日：花莲与韩国仁川直航包机首航2004年10月19日：花莲与澳门直航包机首航2005年11月13日：中华航空股份有限公司重回花莲天空执行日本包机任务2006年1月30日：花莲与菲律宾马尼拉直航包机首航2006年10月26日：花莲与日本石垣岛直航包机首航2007年7月1日：澳门航空首航花莲机场，创花莲境外包机先例2007年9月3日：鹿儿岛包机首航B1：汽车停车场、多用途展示空间1F：离站出口、国内线到站区、国际线到站区、入境证照检查柜台、到站旅客等候区、行李托盘、公共汽车站、出租车排班站、大客车等候区、机车停车场、大客车停车场2F：搭机入口、远东航空柜台、华信航空柜台、复兴航空柜台、行李托运、出境联合服务柜台、商店街、保险柜台、自动提款机、贵宾室、出境证照检查柜台、国内线等候大厅、国际线等候大厅、1~3号空桥登机门、4号非空桥登机门3F：行政办公室、会议室、展览展示区、赏机室备有 '
            '7个停机坪 1~3号停机坪有空桥连接 '
            '4号登机门备有电扶梯连络4~7号停机坪※视评估扩充5~7号登机门及空桥，扩建工程第一期第一阶段并无建设.货运站独立一栋货运站场供货运使用往返台中：华信航空股份有限公司 '
            'FK50/FK100往返高雄：华信航空股份有限公司 FK50/FK100往返台北：远东航空 '
            'MD83/B757(暂停营运)、复兴航空 '
            'ATR72/A320日本：宫崎、小松、仙台、福岛、新潟、关西、花卷、松山、冈山、能登、石垣岛、富山、函馆韩国：首尔、济州岛港澳：澳门东南亚：马尼拉、吉隆坡直航航线花莲机场是马政府开放两岸包机直航的航线，但是此航线开放直航经济效应不足（没有足够的旅客）、让大陆籍航空公司飞航又会大幅增加国防成本（因为邻近军机场）。',
 'date': '',
 'keyword': '花莲机场',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA'} (scraper.py:257)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:38:55] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1872,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 174374,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 104.274865,
 'file_count': 3,
 'file_status_count/downloaded': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 38, 55, 878424),
 'httpcompression/response_bytes': 208288,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 353,
 'log_count/INFO': 91,
 'log_count/WARNING': 1,
 'memusage/max': 86867968,
 'memusage/startup': 67604480,
 'response_received_count': 4,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 37, 11, 603559)} (statscollectors.py:47)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:38:55] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA>
{'attributes': {'IATA代码': 'Makung Airport',
                'ICAO代码': '机场',
                'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/908fa0ec08fa513d26972468a62342fbb2fb4316737c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '',
                '地区管理': '',
                '外文名': '马公',
                '年旅客容量': '湖西乡',
                '建筑高度': '澎湖县',
                '总面积': '省',
                '所属地区': 'MZG',
                '服务城市': '军民合用',
                '机场类型': '1977年3月',
                '跑道长度': '台湾',
                '通航日期': 'RCQC'},
 'content': '澎湖马公机场（英语译名：Penghu Makung '
            'Airport，IATA：MZG、ICAO：RCQC），正式名称为马公航空站，是一座位于台湾省澎湖县湖西乡的机场。[1]\xa0'
            '1957年起由民航空运公司以C-46型开始营运。1966年兴建航站大厦，成立马公候机室，隶属于高雄航空站。1977年8月1日成立马公航空站(丙种航空站)。1993年1月18日改设为乙种航空站。1991年5月11日接管七美、望安两离岛机场，成立七美、望安辅助站。[1]\xa0'
            '2014年7月23日，一架从高雄飞往澎湖马公机场的台湾复兴航空小型客机GE-222航班因迫降失败，坠毁于马公机场附近的澎湖湖西乡西溪村62号旁的空地。机上共58人，乘客54名(50名大人、4名儿童)，机组人员4名。台湾复兴航空公司24日6时30分许发布说明,确认23日晚在澎湖失事的GE222航班上48人罹难,10人受伤。[2]\xa0'
            '具体参照7·23台湾客机起火事故。澎湖地区近50年已发生十余起空难2013年7月23日晚，一架复兴航空高雄飞马公的客机在澎湖迫降失败，造成重大伤亡。消息传来,许多台湾人不禁问，为什么又是澎湖？据不完全统计，不算这次空难，自1967年以来的47年间，澎湖海域已发生11起空难，共造成289人死亡或失踪。1986年2月26日，台湾“华航”一架客机载着7名机组人员及6名乘客从台北飞往马公途中，在澎湖县白沙乡吉贝屿海域失事坠海，13人全部死亡。1998年，德安航空直升机在吉贝屿石油钻井平台降落时坠海,两名驾驶员死亡。同年，一架由嘉义基地起飞的台湾空军F—16战斗机，在训练时飞经澎湖花屿海域上空后失踪，至今尚未找到飞机残骸及机上两名飞行员。2002年5月25日，“华航”飞香港客机在澎湖目斗屿北方海域上空解体坠海，机上225人全部罹难，堪称台湾航空史上最大空难。这场空难发生不久后，2003年9月27日，台湾一架空军战机在澎湖马公海域进行例行训练时失事坠毁，所幸两名飞行员成功跳伞逃生，被当时正在附近作业的两艘大陆渔船的渔民救起。2008年10月21日晚，台湾空军一架IDF战机从台中清泉岗机场起飞，半小时后在澎湖外海失去联络，机上2名飞行员遇难。澎湖列岛由64个岛屿组成，位于台湾海峡的中间，地处两大洋流交汇处,加上有海沟，海象十分凶险。海域上空接二连三发生各种飞机失事事件,原因众说纷纭。有说法是莫名的磁场作祟,在一些台湾人心中,澎湖成了台湾的“百慕大”;也有说法是因为澎湖位于国际航线上,失事几率也随之提高。无论如何，又一场空难噩耗传来，,举世同悲。澎湖，这个游客心目中的台湾“小希腊”，这个和阿根廷球服一样喜欢用蓝白色调装裹自己的小清新之地，,这个歌手张雨生和《外婆的澎湖湾》原唱者潘安邦的故乡，这个有浪漫双心石沪和好吃仙人掌冰的梦幻之岛,再次成为悲痛、哀戚笼罩的地方。[1]\xa0',
 'date': '',
 'keyword': '马公机场',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA'} (scraper.py:257)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:38:55] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 902,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 202782,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 107.643832,
 'file_count': 1,
 'file_status_count/downloaded': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 38, 55, 899870),
 'httpcompression/response_bytes': 205133,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 375,
 'log_count/INFO': 118,
 'log_count/WARNING': 1,
 'memusage/max': 86867968,
 'memusage/startup': 67006464,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 37, 8, 256038)} (statscollectors.py:47)
[2022-03-10 01:38:55] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:38:55] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.001951 (DataCleaning.py:41)
[2022-03-10 01:38:55] [    INFO] [  __main__ ] - 上传文件：/code/./result/baidu/baidu_马公机场_马公机场_20220310013855896398.json (MultisiteSchedule.py:276)
[2022-03-10 01:38:55] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:291)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 277, in upload_crawl_file
    connect.upload_file(file, "/text_crawl_file/")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 01:38:55] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:395)
[2022-03-10 01:38:55] [    INFO] [  __main__ ] - 上传文件：result/Images/马公机场_0.jpg (MultisiteSchedule.py:245)
[2022-03-10 01:38:55] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:261)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 246, in upload_crawl_img_new
    connect.upload_file(file_path, "/imageSearch")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 01:38:55] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:398)
[2022-03-10 01:38:55] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 01:40:37] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:40:37] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_7.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:40:37] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:40:38] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:53435/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:40:38] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:53435 (connectionpool.py:232)
[2022-03-10 01:40:38] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:53435 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:40:38] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:38] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:53435/session/795d65be5f957a0e20c6de9b33503b87/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:40:38] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:53435 "POST /session/795d65be5f957a0e20c6de9b33503b87/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:38] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:38] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:40:38] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:40:38] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:40:38] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:40:38] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:40:38] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:40:38] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_7.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:40:38] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:40:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35213/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:40:39] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:35213 (connectionpool.py:232)
[2022-03-10 01:40:39] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35213 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:40:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35213/session/ce2ee736587e752cc034029509349fe2/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:40:39] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35213 "POST /session/ce2ee736587e752cc034029509349fe2/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:39] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:40:39] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:40:39] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:40:39] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:40:39] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:40:39] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:40:39] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_7.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:40:39] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:40:40] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:49085/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:40:40] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:49085 (connectionpool.py:232)
[2022-03-10 01:40:40] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:49085 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:40:40] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:40] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:49085/session/9fc1b5b5fe151f2cb52420bb7bd3ba5b/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:40:40] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:49085 "POST /session/9fc1b5b5fe151f2cb52420bb7bd3ba5b/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:40] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:40] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:40:40] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:40:40] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:40:40] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:40:40] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:40:40] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:40:40] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_7.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:40:40] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:40:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35017/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:40:41] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:35017 (connectionpool.py:232)
[2022-03-10 01:40:41] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35017 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:40:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35017/session/ad74e6d7471a3ae09c6c53b42ab6b402/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:40:41] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35017 "POST /session/ad74e6d7471a3ae09c6c53b42ab6b402/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:41] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:40:41] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:40:41] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:40:41] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:40:41] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:40:41] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:40:41] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_7.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:40:41] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:40:42] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:40:42] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:50859 (connectionpool.py:232)
[2022-03-10 01:40:43] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:40:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:40:43] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:43] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:40:43] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:40:43] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:40:43] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:40:43] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:40:43] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:40:43] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_7.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:40:43] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:40:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42615/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:40:44] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:42615 (connectionpool.py:232)
[2022-03-10 01:40:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42615 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:40:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42615/session/43e81e0ef48bc04c3618dc1b8ef249a1/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:40:44] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42615 "POST /session/43e81e0ef48bc04c3618dc1b8ef249a1/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:44] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:44] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:40:44] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:40:44] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:40:44] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:40:44] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:40:44] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:40:44] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_7.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:40:44] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:40:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54837/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:40:45] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:54837 (connectionpool.py:232)
[2022-03-10 01:40:45] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54837 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:40:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:54837/session/434c1cd22d344d5ea5fb92849f83e718/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:40:45] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:54837 "POST /session/434c1cd22d344d5ea5fb92849f83e718/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:45] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:40:45] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:40:45] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:40:45] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:40:45] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:40:45] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:40:45] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_7.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:40:45] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:40:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50339/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:40:46] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:50339 (connectionpool.py:232)
[2022-03-10 01:40:46] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50339 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:40:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50339/session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:40:46] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50339 "POST /session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:46] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:46] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:40:46] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:40:46] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:40:46] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:40:46] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:40:46] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:40:46] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_7.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:40:46] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:40:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34125/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:40:47] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:34125 (connectionpool.py:232)
[2022-03-10 01:40:47] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34125 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:40:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34125/session/6f85171af1636337196ac7cfb101313b/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:40:47] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34125 "POST /session/6f85171af1636337196ac7cfb101313b/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:40:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:40:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:40:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:40:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:40:47] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:40:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_7.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:40:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:40:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46427/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:40:48] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:46427 (connectionpool.py:232)
[2022-03-10 01:40:48] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46427 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:40:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46427/session/2f801e7a23b7d29056286f933939d7db/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:40:48] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46427 "POST /session/2f801e7a23b7d29056286f933939d7db/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:48] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:48] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:40:48] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:40:48] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:40:48] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:40:48] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:40:48] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:40:48] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_7.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:40:48] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:40:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"prefs": {"profile.default_content_setting_values": {"notifications": 2, "images": 2}}, "extensions": [], "args": ["--no-sandbox", "--disable-dev-shm-usage", "--headless"]}}} (remote_connection.py:388)
[2022-03-10 01:40:49] [   DEBUG] [urllib3.connectionpool ] - Starting new HTTP connection (1): 127.0.0.1:48605 (connectionpool.py:232)
[2022-03-10 01:40:49] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session HTTP/1.1" 200 753 (connectionpool.py:465)
[2022-03-10 01:40:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/timeouts {"implicit": 1000} (remote_connection.py:388)
[2022-03-10 01:40:49] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/timeouts HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:49] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:40:49] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:40:49] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.BaiduPipeline'] (middleware.py:48)
[2022-03-10 01:40:49] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:40:49] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:40:49] [    INFO] [     baidu ] - Spider opened: baidu (middlewares.py:142)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> from <GET https://baike.baidu.com/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (redirect.py:42)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> from <GET https://baike.baidu.com/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (redirect.py:42)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> from <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (redirect.py:42)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://baike.baidu.com/error.html?status=404&uri=/item/earth%20fortification> from <GET https://baike.baidu.com/item/earth%20fortification> (redirect.py:42)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA> (referer: None) (engine.py:250)
[2022-03-10 01:40:50] [ WARNING] [py.warnings ] - /usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py:149: UserWarning: The "BaidubaikeSpider.parse" method is a generator and includes a "return" statement with a value different than None. This could lead to unexpected behaviour. Please see https://docs.python.org/3/reference/simple_stmts.html#the-return-statement for details about the semantics of the "return" statement within generators
  warn_on_generator_with_return_value(spider, callback)
 (warnings.py:110)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99> (referer: None) (engine.py:250)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6> (referer: None) (engine.py:250)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA> (referer: None) (engine.py:250)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6> (referer: None) (engine.py:250)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/error.html?status=404&uri=/item/%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA> (referer: None) (engine.py:250)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/error.html?status=404&uri=/item/earth%20fortification> (referer: None) (engine.py:250)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6> (referer: None) (engine.py:250)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6> (referer: None) (engine.py:250)
[2022-03-10 01:40:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6> (referer: None) (engine.py:250)
[2022-03-10 01:40:50] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35213/session/ce2ee736587e752cc034029509349fe2/url {"url": "https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA"} (remote_connection.py:388)
[2022-03-10 01:40:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35213 "POST /session/ce2ee736587e752cc034029509349fe2/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35213/session/ce2ee736587e752cc034029509349fe2/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:40:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35213 "POST /session/ce2ee736587e752cc034029509349fe2/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35213/session/ce2ee736587e752cc034029509349fe2/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:40:53] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35213 "POST /session/ce2ee736587e752cc034029509349fe2/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35213/session/ce2ee736587e752cc034029509349fe2/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:40:55] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35213 "POST /session/ce2ee736587e752cc034029509349fe2/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35213/session/ce2ee736587e752cc034029509349fe2/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:40:57] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35213 "POST /session/ce2ee736587e752cc034029509349fe2/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35213/session/ce2ee736587e752cc034029509349fe2/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:40:59] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35213 "POST /session/ce2ee736587e752cc034029509349fe2/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35213/session/ce2ee736587e752cc034029509349fe2/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:40:59] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35213 "POST /session/ce2ee736587e752cc034029509349fe2/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:40:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35213/session/ce2ee736587e752cc034029509349fe2/elements {"using": "xpath", "value": "//img[contains(@alt, '\u9a6c\u516c\u673a\u573a')]"} (remote_connection.py:388)
[2022-03-10 01:40:59] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35213 "POST /session/ce2ee736587e752cc034029509349fe2/elements HTTP/1.1" 200 90 (connectionpool.py:465)
[2022-03-10 01:40:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:40:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:35213/session/ce2ee736587e752cc034029509349fe2/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "34e39d19-b00b-4d65-a110-53f082bb9561", "element-6066-11e4-a52e-4f735466cecf": "34e39d19-b00b-4d65-a110-53f082bb9561"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:40:59] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:35213 "POST /session/ce2ee736587e752cc034029509349fe2/execute/sync HTTP/1.1" 200 150 (connectionpool.py:465)
[2022-03-10 01:40:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:01] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA/19178695> from <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA> (redirect.py:42)
[2022-03-10 01:41:01] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46427/session/2f801e7a23b7d29056286f933939d7db/url {"url": "https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6"} (remote_connection.py:388)
[2022-03-10 01:41:03] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46427 "POST /session/2f801e7a23b7d29056286f933939d7db/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46427/session/2f801e7a23b7d29056286f933939d7db/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:03] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46427 "POST /session/2f801e7a23b7d29056286f933939d7db/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:05] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46427/session/2f801e7a23b7d29056286f933939d7db/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:05] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46427 "POST /session/2f801e7a23b7d29056286f933939d7db/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:05] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:07] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46427/session/2f801e7a23b7d29056286f933939d7db/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:07] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46427 "POST /session/2f801e7a23b7d29056286f933939d7db/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:07] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46427/session/2f801e7a23b7d29056286f933939d7db/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:09] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46427 "POST /session/2f801e7a23b7d29056286f933939d7db/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:09] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46427/session/2f801e7a23b7d29056286f933939d7db/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46427 "POST /session/2f801e7a23b7d29056286f933939d7db/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46427/session/2f801e7a23b7d29056286f933939d7db/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46427 "POST /session/2f801e7a23b7d29056286f933939d7db/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46427/session/2f801e7a23b7d29056286f933939d7db/elements {"using": "xpath", "value": "//img[contains(@alt, '\u88c5\u7532\u6551\u62a4\u8f66')]"} (remote_connection.py:388)
[2022-03-10 01:41:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46427 "POST /session/2f801e7a23b7d29056286f933939d7db/elements HTTP/1.1" 200 90 (connectionpool.py:465)
[2022-03-10 01:41:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:46427/session/2f801e7a23b7d29056286f933939d7db/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "38815054-6a44-4817-a6f3-0df893717f48", "element-6066-11e4-a52e-4f735466cecf": "38815054-6a44-4817-a6f3-0df893717f48"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:41:11] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:46427 "POST /session/2f801e7a23b7d29056286f933939d7db/execute/sync HTTP/1.1" 200 146 (connectionpool.py:465)
[2022-03-10 01:41:11] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:13] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/url {"url": "https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA"} (remote_connection.py:388)
[2022-03-10 01:41:15] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:15] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:15] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:15] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:15] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:17] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:17] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:19] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:19] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:21] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:21] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:21] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:23] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:23] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/elements {"using": "xpath", "value": "//img[contains(@alt, '\u82b1\u83b2\u673a\u573a')]"} (remote_connection.py:388)
[2022-03-10 01:41:23] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/elements HTTP/1.1" 200 248 (connectionpool.py:465)
[2022-03-10 01:41:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "da8c71d3-ec20-464c-b305-e32792dd30b7", "element-6066-11e4-a52e-4f735466cecf": "da8c71d3-ec20-464c-b305-e32792dd30b7"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:41:23] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/execute/sync HTTP/1.1" 200 151 (connectionpool.py:465)
[2022-03-10 01:41:23] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "14a9830c-bcc7-4df3-8c0f-367a7429d7fd", "element-6066-11e4-a52e-4f735466cecf": "14a9830c-bcc7-4df3-8c0f-367a7429d7fd"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:41:25] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/execute/sync HTTP/1.1" 200 157 (connectionpool.py:465)
[2022-03-10 01:41:25] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50859/session/1ee774154a33eea28cb5dff13c6671c5/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "a160e60f-c15f-4edd-94d6-3a4eb95291f0", "element-6066-11e4-a52e-4f735466cecf": "a160e60f-c15f-4edd-94d6-3a4eb95291f0"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:41:27] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50859 "POST /session/1ee774154a33eea28cb5dff13c6671c5/execute/sync HTTP/1.1" 200 146 (connectionpool.py:465)
[2022-03-10 01:41:27] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:29] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/url {"url": "https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6"} (remote_connection.py:388)
[2022-03-10 01:41:31] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:31] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:31] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:33] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:33] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:33] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:35] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:35] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:35] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:37] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:37] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:37] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:39] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:39] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/elements {"using": "xpath", "value": "//img[contains(@alt, '\u88c5\u7532\u4fa6\u5bdf\u8f66')]"} (remote_connection.py:388)
[2022-03-10 01:41:39] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/elements HTTP/1.1" 200 564 (connectionpool.py:465)
[2022-03-10 01:41:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "1c9684d2-11bb-41f1-a22f-bf8e445aa00f", "element-6066-11e4-a52e-4f735466cecf": "1c9684d2-11bb-41f1-a22f-bf8e445aa00f"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:41:39] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 147 (connectionpool.py:465)
[2022-03-10 01:41:39] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "6a669202-ab44-45db-be87-7b8131f39666", "element-6066-11e4-a52e-4f735466cecf": "6a669202-ab44-45db-be87-7b8131f39666"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:41:41] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 147 (connectionpool.py:465)
[2022-03-10 01:41:41] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "3f20d47c-1a2e-4aa4-a3be-c1db129a62d9", "element-6066-11e4-a52e-4f735466cecf": "3f20d47c-1a2e-4aa4-a3be-c1db129a62d9"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:41:43] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 147 (connectionpool.py:465)
[2022-03-10 01:41:43] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "7bf73168-95ea-4d39-8b1b-474f7ef9a942", "element-6066-11e4-a52e-4f735466cecf": "7bf73168-95ea-4d39-8b1b-474f7ef9a942"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:41:45] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 147 (connectionpool.py:465)
[2022-03-10 01:41:45] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "cd57f0fd-7fde-4ae8-ad5c-6511c6452066", "element-6066-11e4-a52e-4f735466cecf": "cd57f0fd-7fde-4ae8-ad5c-6511c6452066"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:41:47] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 147 (connectionpool.py:465)
[2022-03-10 01:41:47] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "80e09e1f-d25c-4599-8a44-576010e07548", "element-6066-11e4-a52e-4f735466cecf": "80e09e1f-d25c-4599-8a44-576010e07548"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:41:49] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 153 (connectionpool.py:465)
[2022-03-10 01:41:49] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:48605/session/befd941964ed2115e3caf9a6fed1164d/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "e074d736-5f9e-4c51-a675-a070e735fab2", "element-6066-11e4-a52e-4f735466cecf": "e074d736-5f9e-4c51-a675-a070e735fab2"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:41:51] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:48605 "POST /session/befd941964ed2115e3caf9a6fed1164d/execute/sync HTTP/1.1" 200 146 (connectionpool.py:465)
[2022-03-10 01:41:51] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:53] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50339/session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/url {"url": "https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6"} (remote_connection.py:388)
[2022-03-10 01:41:55] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50339 "POST /session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50339/session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:55] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50339 "POST /session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:55] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50339/session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:57] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50339 "POST /session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:57] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:41:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50339/session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:41:59] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50339 "POST /session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:41:59] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:01] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50339/session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:01] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50339 "POST /session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:01] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50339/session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:03] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50339 "POST /session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50339/session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:03] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50339 "POST /session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:03] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:50339/session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/elements {"using": "xpath", "value": "//img[contains(@alt, '\u88c5\u7532\u626b\u96f7\u8f66')]"} (remote_connection.py:388)
[2022-03-10 01:42:04] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:50339 "POST /session/cbc7e6fcfe20ae00cbf2af66cbd7ae1a/elements HTTP/1.1" 200 12 (connectionpool.py:465)
[2022-03-10 01:42:04] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:04] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6>
{'attributes': {'img_url': {},
                '中文名': '装甲扫雷车',
                '作用': '用来清除地雷',
                '分类': '车轮或者是履带型态',
                '实质': '作战工具'},
 'content': '装甲扫雷车特指装有清除地雷装置的装甲车辆，以协助地面部队扩速通过地雷区。装甲扫雷车可以是专门设计用来清除地雷，或者是将清除工具附加在一般用途的装甲车辆上面，长时间担任地雷排除的任务的装甲车辆。无论是车轮或者是履带型态的扫雷车都可见于不同国家的部队当中。简介装甲扫雷车并非用于清除整个被发现的地雷区，而是将地雷区清理出一至数条的安全信道，提供地面部队人员和车辆安全通过。排除的地雷可能在过程中加以引爆，或者是移动到安全的地方之后另外加以处理。由于清理的过程当中，扫雷车可能碰触或者是引爆其他尚未发现的地雷或者是爆裂物，车辆本身对于底盘和车辆底部的保护需要特别加强，以免轻易的被地雷或者是爆裂物瘫痪而无法完成清除的任务。',
 'date': '',
 'keyword': '装甲扫雷车',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6'} (scraper.py:257)
[2022-03-10 01:42:04] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34125/session/6f85171af1636337196ac7cfb101313b/url {"url": "https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6"} (remote_connection.py:388)
[2022-03-10 01:42:06] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34125 "POST /session/6f85171af1636337196ac7cfb101313b/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34125/session/6f85171af1636337196ac7cfb101313b/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:06] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34125 "POST /session/6f85171af1636337196ac7cfb101313b/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:06] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34125/session/6f85171af1636337196ac7cfb101313b/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:08] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34125 "POST /session/6f85171af1636337196ac7cfb101313b/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:08] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34125/session/6f85171af1636337196ac7cfb101313b/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:10] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34125 "POST /session/6f85171af1636337196ac7cfb101313b/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:10] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34125/session/6f85171af1636337196ac7cfb101313b/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:12] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34125 "POST /session/6f85171af1636337196ac7cfb101313b/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:12] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34125/session/6f85171af1636337196ac7cfb101313b/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:14] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34125 "POST /session/6f85171af1636337196ac7cfb101313b/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34125/session/6f85171af1636337196ac7cfb101313b/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:14] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34125 "POST /session/6f85171af1636337196ac7cfb101313b/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34125/session/6f85171af1636337196ac7cfb101313b/elements {"using": "xpath", "value": "//img[contains(@alt, '\u88c5\u7532\u8fd0\u8f93\u8f66')]"} (remote_connection.py:388)
[2022-03-10 01:42:14] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34125 "POST /session/6f85171af1636337196ac7cfb101313b/elements HTTP/1.1" 200 90 (connectionpool.py:465)
[2022-03-10 01:42:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:34125/session/6f85171af1636337196ac7cfb101313b/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "1a4f4cdd-d237-4fee-9037-f2c4a6bab5df", "element-6066-11e4-a52e-4f735466cecf": "1a4f4cdd-d237-4fee-9037-f2c4a6bab5df"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:42:14] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:34125 "POST /session/6f85171af1636337196ac7cfb101313b/execute/sync HTTP/1.1" 200 150 (connectionpool.py:465)
[2022-03-10 01:42:14] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:16] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:42:16] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 962,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 2995,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 90.775807,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 42, 16, 110072),
 'httpcompression/response_bytes': 4555,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 234,
 'log_count/INFO': 41,
 'log_count/WARNING': 1,
 'memusage/max': 68063232,
 'memusage/startup': 68063232,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 3, 10, 1, 40, 45, 334265)} (statscollectors.py:47)
[2022-03-10 01:42:16] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:42:16] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:42:16] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 906,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 2815,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 95.339725,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 42, 16, 112744),
 'httpcompression/response_bytes': 4555,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 262,
 'log_count/INFO': 76,
 'log_count/WARNING': 1,
 'memusage/max': 67248128,
 'memusage/startup': 67248128,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 3, 10, 1, 40, 40, 773019)} (statscollectors.py:47)
[2022-03-10 01:42:16] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:42:16] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:42:16] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 915,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 2824,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 94.205538,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 42, 16, 114225),
 'httpcompression/response_bytes': 4555,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 255,
 'log_count/INFO': 71,
 'log_count/WARNING': 1,
 'memusage/max': 67452928,
 'memusage/startup': 67452928,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 3, 10, 1, 40, 41, 908687)} (statscollectors.py:47)
[2022-03-10 01:42:16] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:42:16] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:42:16] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 872,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 2800,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 97.612869,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 42, 16, 115590),
 'httpcompression/response_bytes': 4555,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 276,
 'log_count/INFO': 98,
 'log_count/WARNING': 1,
 'memusage/max': 66764800,
 'memusage/startup': 66764800,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 3, 10, 1, 40, 38, 502721)} (statscollectors.py:47)
[2022-03-10 01:42:16] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:42:16] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA/19178695> (referer: None) (engine.py:250)
[2022-03-10 01:42:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:42:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:42:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:42:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min) (logstats.py:48)
[2022-03-10 01:42:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:42:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:42:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:42:16] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:42:16] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 412,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 30647,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 89.683459,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 42, 16, 149001),
 'httpcompression/response_bytes': 194515,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 228,
 'log_count/INFO': 52,
 'log_count/WARNING': 1,
 'memusage/max': 88002560,
 'memusage/startup': 68251648,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 40, 46, 465542)} (statscollectors.py:47)
[2022-03-10 01:42:16] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:42:16] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/2934349b033b5bb56eefbaf336d3d539b600bc87?x-bce-process=image/resize,m_lfit,w_278,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:42:16] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/2934349b033b5bb56eefbaf336d3d539b600bc87?x-bce-process=image/resize,m_lfit,w_278,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing BmpImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing BufrStubImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing CurImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing DcxImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing DdsImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing EpsImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing FitsStubImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing FliImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing FpxImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing FtexImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing GbrImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing GifImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing GribStubImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing Hdf5StubImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing IcnsImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing IcoImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing ImImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing ImtImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing IptcImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing JpegImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing Jpeg2KImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing McIdasImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing MicImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing MpegImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing MpoImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing MspImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing PalmImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing PcdImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing PcxImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing PdfImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing PixarImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing PngImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing PpmImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing PsdImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing SgiImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing SpiderImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing SunImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing TgaImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing TiffImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing WebPImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing WmfImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing XbmImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing XpmImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [ PIL.Image ] - Importing XVThumbImagePlugin (Image.py:397)
[2022-03-10 01:42:16] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/3c6d55fbb2fb43163aac9c552da4462309f7d36a?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:42:16] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/3c6d55fbb2fb43163aac9c552da4462309f7d36a?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:42:16] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/e7cd7b899e510fb3b92f6774d233c895d1430c1a?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:42:16] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/e7cd7b899e510fb3b92f6774d233c895d1430c1a?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:42:16] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_220,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:42:16] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_220,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:42:16] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42615/session/43e81e0ef48bc04c3618dc1b8ef249a1/url {"url": "https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA/19178695"} (remote_connection.py:388)
[2022-03-10 01:42:18] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42615 "POST /session/43e81e0ef48bc04c3618dc1b8ef249a1/url HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42615/session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:18] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42615 "POST /session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:18] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:20] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42615/session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:20] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42615 "POST /session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:20] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:22] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42615/session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:22] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42615 "POST /session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:22] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:24] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42615/session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:24] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42615 "POST /session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:24] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42615/session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync {"script": "window.scrollBy(0,1500)", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:26] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42615 "POST /session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42615/session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync {"script": "return document.body.scrollHeight;", "args": []} (remote_connection.py:388)
[2022-03-10 01:42:26] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42615 "POST /session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync HTTP/1.1" 200 14 (connectionpool.py:465)
[2022-03-10 01:42:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42615/session/43e81e0ef48bc04c3618dc1b8ef249a1/elements {"using": "xpath", "value": "//img[contains(@alt, '\u76f4\u5347\u673a')]"} (remote_connection.py:388)
[2022-03-10 01:42:26] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42615 "POST /session/43e81e0ef48bc04c3618dc1b8ef249a1/elements HTTP/1.1" 200 90 (connectionpool.py:465)
[2022-03-10 01:42:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - POST http://127.0.0.1:42615/session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync {"script": "return (function(){return function(){var d=this;function f(a){return\"string\"==typeof a};function h(a,b){this.code=a;this.a=l[a]||m;this.message=b||\"\";a=this.a.replace(/((?:^|\\s+)[a-z])/g,function(a){return a.toUpperCase().replace(/^[\\s\\xa0]+/g,\"\")});b=a.length-5;if(0>b||a.indexOf(\"Error\",b)!=b)a+=\"Error\";this.name=a;a=Error(this.message);a.name=this.name;this.stack=a.stack||\"\"}\n(function(){var a=Error;function b(){}b.prototype=a.prototype;h.b=a.prototype;h.prototype=new b;h.prototype.constructor=h;h.a=function(b,c,g){for(var e=Array(arguments.length-2),k=2;k<arguments.length;k++)e[k-2]=arguments[k];return a.prototype[c].apply(b,e)}})();var m=\"unknown error\",l={15:\"element not selectable\",11:\"element not visible\"};l[31]=m;l[30]=m;l[24]=\"invalid cookie domain\";l[29]=\"invalid element coordinates\";l[12]=\"invalid element state\";l[32]=\"invalid selector\";l[51]=\"invalid selector\";\nl[52]=\"invalid selector\";l[17]=\"javascript error\";l[405]=\"unsupported operation\";l[34]=\"move target out of bounds\";l[27]=\"no such alert\";l[7]=\"no such element\";l[8]=\"no such frame\";l[23]=\"no such window\";l[28]=\"script timeout\";l[33]=\"session not created\";l[10]=\"stale element reference\";l[21]=\"timeout\";l[25]=\"unable to set cookie\";l[26]=\"unexpected alert open\";l[13]=m;l[9]=\"unknown command\";h.prototype.toString=function(){return this.name+\": \"+this.message};var n;a:{var p=d.navigator;if(p){var q=p.userAgent;if(q){n=q;break a}}n=\"\"}function r(a){return-1!=n.indexOf(a)};function t(a,b){for(var e=a.length,c=f(a)?a.split(\"\"):a,g=0;g<e;g++)g in c&&b.call(void 0,c[g],g,a)};function v(){return r(\"iPhone\")&&!r(\"iPod\")&&!r(\"iPad\")};function w(){return(r(\"Chrome\")||r(\"CriOS\"))&&!r(\"Edge\")};var x=r(\"Opera\"),y=r(\"Trident\")||r(\"MSIE\"),z=r(\"Edge\"),A=r(\"Gecko\")&&!(-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\"))&&!(r(\"Trident\")||r(\"MSIE\"))&&!r(\"Edge\"),aa=-1!=n.toLowerCase().indexOf(\"webkit\")&&!r(\"Edge\");function B(){var a=d.document;return a?a.documentMode:void 0}var C;\na:{var D=\"\",E=function(){var a=n;if(A)return/rv\\:([^\\);]+)(\\)|;)/.exec(a);if(z)return/Edge\\/([\\d\\.]+)/.exec(a);if(y)return/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a);if(aa)return/WebKit\\/(\\S+)/.exec(a);if(x)return/(?:Version)[ \\/]?(\\S+)/.exec(a)}();E&&(D=E?E[1]:\"\");if(y){var F=B();if(null!=F&&F>parseFloat(D)){C=String(F);break a}}C=D}var G;var H=d.document;G=H&&y?B()||(\"CSS1Compat\"==H.compatMode?parseInt(C,10):5):void 0;var ba=r(\"Firefox\"),ca=v()||r(\"iPod\"),da=r(\"iPad\"),I=r(\"Android\")&&!(w()||r(\"Firefox\")||r(\"Opera\")||r(\"Silk\")),ea=w(),J=r(\"Safari\")&&!(w()||r(\"Coast\")||r(\"Opera\")||r(\"Edge\")||r(\"Silk\")||r(\"Android\"))&&!(v()||r(\"iPad\")||r(\"iPod\"));function K(a){return(a=a.exec(n))?a[1]:\"\"}(function(){if(ba)return K(/Firefox\\/([0-9.]+)/);if(y||z||x)return C;if(ea)return v()||r(\"iPad\")||r(\"iPod\")?K(/CriOS\\/([0-9.]+)/):K(/Chrome\\/([0-9.]+)/);if(J&&!(v()||r(\"iPad\")||r(\"iPod\")))return K(/Version\\/([0-9.]+)/);if(ca||da){var a=/Version\\/(\\S+).*Mobile\\/(\\S+)/.exec(n);if(a)return a[1]+\".\"+a[2]}else if(I)return(a=K(/Android\\s+([0-9.]+)/))?a:K(/Version\\/([0-9.]+)/);return\"\"})();var L,M=function(){if(!A)return!1;var a=d.Components;if(!a)return!1;try{if(!a.classes)return!1}catch(g){return!1}var b=a.classes,a=a.interfaces,e=b[\"@mozilla.org/xpcom/version-comparator;1\"].getService(a.nsIVersionComparator),c=b[\"@mozilla.org/xre/app-info;1\"].getService(a.nsIXULAppInfo).version;L=function(a){e.compare(c,\"\"+a)};return!0}(),N=y&&!(8<=Number(G)),fa=y&&!(9<=Number(G));I&&M&&L(2.3);I&&M&&L(4);J&&M&&L(6);var ga={SCRIPT:1,STYLE:1,HEAD:1,IFRAME:1,OBJECT:1},O={IMG:\" \",BR:\"\\n\"};function P(a,b,e){if(!(a.nodeName in ga))if(3==a.nodeType)e?b.push(String(a.nodeValue).replace(/(\\r\\n|\\r|\\n)/g,\"\")):b.push(a.nodeValue);else if(a.nodeName in O)b.push(O[a.nodeName]);else for(a=a.firstChild;a;)P(a,b,e),a=a.nextSibling};function Q(a,b){b=b.toLowerCase();return\"style\"==b?ha(a.style.cssText):N&&\"value\"==b&&R(a,\"INPUT\")?a.value:fa&&!0===a[b]?String(a.getAttribute(b)):(a=a.getAttributeNode(b))&&a.specified?a.value:null}var ia=/[;]+(?=(?:(?:[^\"]*\"){2})*[^\"]*$)(?=(?:(?:[^']*'){2})*[^']*$)(?=(?:[^()]*\\([^()]*\\))*[^()]*$)/;\nfunction ha(a){var b=[];t(a.split(ia),function(a){var c=a.indexOf(\":\");0<c&&(a=[a.slice(0,c),a.slice(c+1)],2==a.length&&b.push(a[0].toLowerCase(),\":\",a[1],\";\"))});b=b.join(\"\");return b=\";\"==b.charAt(b.length-1)?b:b+\";\"}function S(a,b){N&&\"value\"==b&&R(a,\"OPTION\")&&null===Q(a,\"value\")?(b=[],P(a,b,!1),a=b.join(\"\")):a=a[b];return a}function R(a,b){b&&\"string\"!==typeof b&&(b=b.toString());return!!a&&1==a.nodeType&&(!b||a.tagName.toUpperCase()==b)}\nfunction T(a){return R(a,\"OPTION\")?!0:R(a,\"INPUT\")?(a=a.type.toLowerCase(),\"checkbox\"==a||\"radio\"==a):!1};var ja={\"class\":\"className\",readonly:\"readOnly\"},U=\"allowfullscreen allowpaymentrequest allowusermedia async autofocus autoplay checked compact complete controls declare default defaultchecked defaultselected defer disabled ended formnovalidate hidden indeterminate iscontenteditable ismap itemscope loop multiple muted nohref nomodule noresize noshade novalidate nowrap open paused playsinline pubdate readonly required reversed scoped seamless seeking selected truespeed typemustmatch willvalidate\".split(\" \");function V(a,b){var e=null,c=b.toLowerCase();if(\"style\"==c)return(e=a.style)&&!f(e)&&(e=e.cssText),e;if((\"selected\"==c||\"checked\"==c)&&T(a)){if(!T(a))throw new h(15,\"Element is not selectable\");b=\"selected\";e=a.type&&a.type.toLowerCase();if(\"checkbox\"==e||\"radio\"==e)b=\"checked\";return S(a,b)?\"true\":null}var g=R(a,\"A\");if(R(a,\"IMG\")&&\"src\"==c||g&&\"href\"==c)return(e=Q(a,c))&&(e=S(a,c)),e;if(\"spellcheck\"==c){e=Q(a,c);if(null!==e){if(\"false\"==e.toLowerCase())return\"false\";if(\"true\"==e.toLowerCase())return\"true\"}return S(a,\nc)+\"\"}g=ja[b]||b;a:if(f(U))c=f(c)&&1==c.length?U.indexOf(c,0):-1;else{for(var u=0;u<U.length;u++)if(u in U&&U[u]===c){c=u;break a}c=-1}if(0<=c)return(e=null!==Q(a,b)||S(a,g))?\"true\":null;try{var k=S(a,g)}catch(ka){}(c=null==k)||(c=typeof k,c=\"object\"==c&&null!=k||\"function\"==c);c?e=Q(a,b):e=k;return null!=e?e.toString():null}var W=[\"_\"],X=d;W[0]in X||!X.execScript||X.execScript(\"var \"+W[0]);\nfor(var Y;W.length&&(Y=W.shift());){var Z;if(Z=!W.length)Z=void 0!==V;Z?X[Y]=V:X[Y]&&X[Y]!==Object.prototype[Y]?X=X[Y]:X=X[Y]={}};; return this._.apply(null,arguments);}.apply({navigator:typeof window!='undefined'?window.navigator:null,document:typeof window!='undefined'?window.document:null}, arguments);}\n).apply(null, arguments);", "args": [{"ELEMENT": "635a4e7c-b8a5-4a0a-8dc7-a46dc18c615a", "element-6066-11e4-a52e-4f735466cecf": "635a4e7c-b8a5-4a0a-8dc7-a46dc18c615a"}, "src"]} (remote_connection.py:388)
[2022-03-10 01:42:26] [   DEBUG] [urllib3.connectionpool ] - http://127.0.0.1:42615 "POST /session/43e81e0ef48bc04c3618dc1b8ef249a1/execute/sync HTTP/1.1" 200 150 (connectionpool.py:465)
[2022-03-10 01:42:26] [   DEBUG] [selenium.webdriver.remote.remote_connection ] - Finished Request (remote_connection.py:440)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/1b4c510fd9f9d72a6f12657dd42a2834349bbb5f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/1b4c510fd9f9d72a6f12657dd42a2834349bbb5f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/bf096b63f6246b60e2b1d7dfe1f81a4c500fa2da?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/bf096b63f6246b60e2b1d7dfe1f81a4c500fa2da?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/908fa0ec08fa513d26972468a62342fbb2fb4316737c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/908fa0ec08fa513d26972468a62342fbb2fb4316737c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/29381f30e924b8997cb60b366e061d950a7bf632?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/29381f30e924b8997cb60b366e061d950a7bf632?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/c8177f3e6709c93d07727cf99f3df8dcd100543f?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/c8177f3e6709c93d07727cf99f3df8dcd100543f?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/9e3df8dcd100baa1d818ddb64710b912c8fc2e82?x-bce-process=image/resize,m_lfit,w_400,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/9e3df8dcd100baa1d818ddb64710b912c8fc2e82?x-bce-process=image/resize,m_lfit,w_400,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto> (referer: None) (engine.py:250)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto> referred in <None> (files.py:456)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/d4628535e5dde71190eff0d94da1d91b9d16fdfacbc7?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/d4628535e5dde71190eff0d94da1d91b9d16fdfacbc7?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/6f061d950a7b020881cd22c262d9f2d3572cc889?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/6f061d950a7b020881cd22c262d9f2d3572cc889?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA>
{'attributes': {'IATA代码': 'Makung Airport',
                'ICAO代码': '机场',
                'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/908fa0ec08fa513d26972468a62342fbb2fb4316737c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '',
                '地区管理': '',
                '外文名': '马公',
                '年旅客容量': '湖西乡',
                '建筑高度': '澎湖县',
                '总面积': '省',
                '所属地区': 'MZG',
                '服务城市': '军民合用',
                '机场类型': '1977年3月',
                '跑道长度': '台湾',
                '通航日期': 'RCQC'},
 'content': '澎湖马公机场（英语译名：Penghu Makung '
            'Airport，IATA：MZG、ICAO：RCQC），正式名称为马公航空站，是一座位于台湾省澎湖县湖西乡的机场。[1]\xa0'
            '1957年起由民航空运公司以C-46型开始营运。1966年兴建航站大厦，成立马公候机室，隶属于高雄航空站。1977年8月1日成立马公航空站(丙种航空站)。1993年1月18日改设为乙种航空站。1991年5月11日接管七美、望安两离岛机场，成立七美、望安辅助站。[1]\xa0'
            '2014年7月23日，一架从高雄飞往澎湖马公机场的台湾复兴航空小型客机GE-222航班因迫降失败，坠毁于马公机场附近的澎湖湖西乡西溪村62号旁的空地。机上共58人，乘客54名(50名大人、4名儿童)，机组人员4名。台湾复兴航空公司24日6时30分许发布说明,确认23日晚在澎湖失事的GE222航班上48人罹难,10人受伤。[2]\xa0'
            '具体参照7·23台湾客机起火事故。澎湖地区近50年已发生十余起空难2013年7月23日晚，一架复兴航空高雄飞马公的客机在澎湖迫降失败，造成重大伤亡。消息传来,许多台湾人不禁问，为什么又是澎湖？据不完全统计，不算这次空难，自1967年以来的47年间，澎湖海域已发生11起空难，共造成289人死亡或失踪。1986年2月26日，台湾“华航”一架客机载着7名机组人员及6名乘客从台北飞往马公途中，在澎湖县白沙乡吉贝屿海域失事坠海，13人全部死亡。1998年，德安航空直升机在吉贝屿石油钻井平台降落时坠海,两名驾驶员死亡。同年，一架由嘉义基地起飞的台湾空军F—16战斗机，在训练时飞经澎湖花屿海域上空后失踪，至今尚未找到飞机残骸及机上两名飞行员。2002年5月25日，“华航”飞香港客机在澎湖目斗屿北方海域上空解体坠海，机上225人全部罹难，堪称台湾航空史上最大空难。这场空难发生不久后，2003年9月27日，台湾一架空军战机在澎湖马公海域进行例行训练时失事坠毁，所幸两名飞行员成功跳伞逃生，被当时正在附近作业的两艘大陆渔船的渔民救起。2008年10月21日晚，台湾空军一架IDF战机从台中清泉岗机场起飞，半小时后在澎湖外海失去联络，机上2名飞行员遇难。澎湖列岛由64个岛屿组成，位于台湾海峡的中间，地处两大洋流交汇处,加上有海沟，海象十分凶险。海域上空接二连三发生各种飞机失事事件,原因众说纷纭。有说法是莫名的磁场作祟,在一些台湾人心中,澎湖成了台湾的“百慕大”;也有说法是因为澎湖位于国际航线上,失事几率也随之提高。无论如何，又一场空难噩耗传来，,举世同悲。澎湖，这个游客心目中的台湾“小希腊”，这个和阿根廷球服一样喜欢用蓝白色调装裹自己的小清新之地，,这个歌手张雨生和《外婆的澎湖湾》原唱者潘安邦的故乡，这个有浪漫双心石沪和好吃仙人掌冰的梦幻之岛,再次成为悲痛、哀戚笼罩的地方。[1]\xa0',
 'date': '',
 'keyword': '马公机场',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA'} (scraper.py:257)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:42:28] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 887,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 196981,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 109.121238,
 'file_count': 1,
 'file_status_count/downloaded': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 42, 28, 762797),
 'httpcompression/response_bytes': 205133,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 368,
 'log_count/INFO': 103,
 'log_count/WARNING': 1,
 'memusage/max': 88002560,
 'memusage/startup': 67051520,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 40, 39, 641559)} (statscollectors.py:47)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6>
{'attributes': {'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/3c6d55fbb2fb43163aac9c552da4462309f7d36a?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto',
                            '图片2': 'https://bkimg.cdn.bcebos.com/pic/2934349b033b5bb56eefbaf336d3d539b600bc87?x-bce-process=image/resize,m_lfit,w_278,limit_1/format,f_auto',
                            '图片3': 'https://bkimg.cdn.bcebos.com/pic/9e3df8dcd100baa1d818ddb64710b912c8fc2e82?x-bce-process=image/resize,m_lfit,w_400,limit_1/format,f_auto',
                            '图片4': 'https://bkimg.cdn.bcebos.com/pic/29381f30e924b8997cb60b366e061d950a7bf632?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto',
                            '图片5': 'https://bkimg.cdn.bcebos.com/pic/c8177f3e6709c93d07727cf99f3df8dcd100543f?x-bce-process=image/resize,m_lfit,w_440,limit_1/format,f_auto',
                            '图片6': 'https://bkimg.cdn.bcebos.com/pic/1b4c510fd9f9d72a6f12657dd42a2834349bbb5f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto',
                            '图片7': 'https://bkimg.cdn.bcebos.com/pic/bf096b63f6246b60e2b1d7dfe1f81a4c500fa2da?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '装甲侦察车',
                '作用': '装甲',
                '分类': '战斗车辆',
                '定义': '配备有侦察设备的'},
 'content': '装甲侦察车具有战场观察、目标搜索、识别、定位、处理和传输能力。有轮式装甲侦察车和履带式装甲侦察车两种，以轮式装甲侦察车为主。装甲侦察车现代装甲侦察车一般装有大倍率光学潜望镜、电视摄像机、热像仪、激光测距仪、雷达定位定向、信息处理和信息传输设备等。为便于远距离观察，车上的观察设备通常设有旋转和升降装置。大倍率光学潜望镜和电视摄像机主要用于能见度良好的夜间进行侦察，发现目标距离不小于20千米，识别装甲车辆距离为10～15千米，并具有电视自动跟踪能力。热像仪主要用于夜间侦察，夜间识别装甲车辆的距离不小于3千米。激光测距仪的最大测量距离不小于20千米，误差一般为5米。雷达可全天候实施侦察，具有多目标自动跟踪能力，对装甲车辆的探测距离不小于25千米，对单兵的最大探测距离不小于10千米。定位定向设备通常由全球卫星定位装置和惯性定位定向装置组成，用于实现装甲侦察车自动寻北、定位导航，寻北精度3密位，定位精度10～20米。信息处理设备由计算机等组成，可对侦察到的目标与图像进行采集、存储和叠加属性、数量、时间、坐标等，并在电子地图上进行自动标注。信息传输设备由微波电视传输设备和电台组成，具有数字通信和网络通信能力，可将侦察到的信息及时传递给其他作战单元。有的装甲侦察车上还装有红外报警器、地面激光目标指示器和核、化、生探测报警器等。履带式装甲侦察车的最大机动速度为90千米/时，轮式装甲侦察车可达125千米/时。车上装有20～30毫米机关炮和机枪，有的还装有76～105毫米火炮，也有的同时装有火炮和反坦克导弹发射装置。[1]\xa0'
            '20世纪30年代后期，美、德、英等国相继用装甲车改装成装甲侦察车，并用于实战。50～60年代，出现了专门研制的装甲侦察车，典型的有法国的EBR、英国的“白鼬”2/3型、苏联的BRDM-1/2型等。70年代以后，装甲侦察车广泛采用先进的光电设备，使装甲侦察车的侦察能力有很大提高。典型的有美国的M2A3“布雷德利”步兵战车、英国的“佩刀”、德国的“山猫”、俄罗斯的BRM和南非的“大山猫”装甲侦察车等。中国于80年代初开始研制装甲侦察车，90年代末装备部队。装甲侦察车的侦察设备将向探测距离远、分辨能力高、信息传输速度快、全天候性能好和抗干扰能力强的方向发展，进一步提高装甲侦察车的生存能力、隐身能力、感知能力和通信能力。[1]\xa0'
            '世界上各国军队，列装有多种型号的专用装甲侦察车，下面主要谈谈轮式装甲侦察车，外军比较有名的有：德国的山猫2型轮式侦察车、法国的VBC90轮式侦察车，俄罗斯的БРДМ-2型轮式侦察车，最新的还有以色列的侦察/监视装甲车--RAM-2000，德国威格曼公司和荷兰宇航车辆公司联合研制的非洲小狐轻型4×4底盘的轮式装甲侦察车等。前苏联陆军的每1摩托化步兵师装备28辆БРДМ-2型轮式侦察车，其中侦察营12辆，坦克团和3个不同装备的摩托化步兵团各4辆；坦克师也装备28辆，其中侦察营12辆，摩托化步兵团和3个坦克团各4辆。紧跟世界军事变革的中国军队，对轮式轻型机械化部队的建设也搞的热火朝天，各种轮式底盘的系列主战装备，纷纷配套列装我军机步师[旅]，已见的有轮式92A型步战车，轮式92B型人员输送车；100毫米轮式自行突击炮；轮式120毫米自行迫榴炮，轮式122毫米自行榴弹炮，轮式倚天防空导弹车；轮式指挥，通信，抢修，救护等辅助车辆，为独很少见到具有重要作用的轮式战场装甲侦察车。[2]\xa0'
            '装甲侦察车装甲侦察车已见的只有三种左右，一种是过去在露脸的一种侦察车，这种专用侦察车，像是80年代试研产品，从照片看中国这款新型轮式装甲侦察车，采用4X4轮式底盘，侦察车由均质钢装甲板焊接而成，侧面形状低矮，易于隐蔽。正面为尖锐的契形，具有良好的防弹性能。该车顶部配有钢围板的枪塔一座，内装12.7毫米口径高平两用重机枪一挺，车体前部，左右各有一个凸起的装防弹玻璃的观察窗，用于驾驶和侦察，其它技术性能不详，车的样子感觉怪怪的，用网友的话说像土鳖.后来没有消息，不知可否列装部队…….另一种是与中国军队对外军贸产品：90--B型122毫米火箭炮配套出口的轮式90B型炮兵侦察车，还有一种是电视上济南战区127机步师[铁军]演习中露脸的一种轮式车辆，怀疑是侦察车.当然各位军迷大虾如有新发现和照片请指教贴图。[3]\xa0'
            '第一种装甲侦察车，过于简单，除车裁武器外，也没见可伸缩的观侦设备，可能属于试制性质，在此不在多说.后二种采用了与92轮式步战车相同的，WMZ551B轮式6X6底盘，车体上装有一挺12.7毫米重机枪和可伸缩的观侦设备，但该车体长6.8米，宽2.86米，高2.87米，战斗全重为15.3吨，距地高0.41米，虽然采用与92车族通用的底盘，有利于战时后勤保障，但敝人认为，选用与92轮式步战车相同的，WMZ551B轮式6X6底盘，做为专用装甲侦察车底盘,车体过于高大，不利于战场隐蔽侦察。除了轮式底盘通用，便于后勤保障外，就车型来说，不是最佳的选型。狐式轻型轮式装甲侦察车狐式轻型轮式装甲侦察车[4]\xa0'
            '该车于1965年由当时的战车研究发展院(Fighting Vehicles Research and Development '
            'Establishment)即现在的彻特西皇家武器装备研究与发展院(Royal Armament Research and '
            'Development Establishmen,Chertsey)研制，次年与戴姆勒公司(Daimler '
            'Company)签订了生产15辆样车的合同。第一辆样车于1967年11月完成，最后一辆于1969年4月完成，1968年开始进行试验。1969年10月第一次公布研制成功了狐式侦察车。1970年英国陆军接受庐车服役。1972年由利兹皇家兵工厂（Royal '
            'Ordnance '
            'Leeds)生产，1973年3月完成第一辆生产型车。英国陆军的正规部队和预备部队均使用该车，阿尔维斯（Alvis)公司为该车提供焊接的铝合金炮塔。RAM轻型轮式装甲侦察车族该车采用全焊接的铝合金装甲车体和炮塔，可防中重型枪弹和弹片。驾驶员位于车体前部，前方吊装1个向右开的舱盖，其上有1个整体式广角潜望镜，该潜望镜可迅速换为被动式夜视潜望镜。炮塔位于车体中央，车长兼装填手在左侧，炮长位于右侧，各有1个单扇向后开启的舱盖。车长有1个装在旋转架上的1×和10×的双筒监视潜望镜，并有7个观察潜望镜。炮长有1个与主炮相连的1×、10×的双筒潜望镜式昼夜瞄准镜和2个观察潜望镜。主炮右侧安装兰克精密工业（Rank '
            'Precision '
            'Industries)公司SPAVL2A1被动式夜视仪，有两种倍率和视野，5.8×，8×视野的用于瞄准；1.6×，28×视野的用于监视，2种倍率不会发生干涉。像增强管由遮光帘保护，不受炮口闪光的危害，遮光帘是由火炮发射系统电动控制的。当选用高倍率时，带有亮度控制的照明弹道分划镜被自动引入光学系统。物镜带刮水器，瞄准镜由装甲盖防护。轮式专用装甲侦察车动力舱后置，发动机和传动装置为一整体，可从车后装拆。发动机采用双阻风门化油器，带有冷起动设备。传动装置是带液力偶合器的预选排档行星齿轮变速箱。冷却系统包括2个散热器，水平布置在发动机后部顶上，在散热器之间有1对离心风扇。发动机和传动装置的润滑油靠1个油水散热器冷却。该车采用独立悬挂，由上下叉形杆、螺旋弹簧和筒式液压减振器组成。上下叉形杆的连接部分兼作润滑油箱，减振器装在螺旋弹簧内。车轮的最大垂直行程为0.279m。该车在无任何准备的情况下可涉水深1m。车上的浮渡围帐2min内即可准备好，在水上靠车轮推进和转向。浮渡围帐的前部有1供观察用的透明板并装有流量为205L/min的排水泵。服役于英国陆军的狐式侦察车已去掉了浮渡围帐。该车装备30mm的拉登（RARDEN)炮，可发射多种炮弹，可单发也可6发连射，空弹壳自动弹出车外。主炮左侧有1挺7.62mm的并列机枪。炮塔前部两侧各有4个烟幕弹发射器。所有武器均电控，主炮和并列机枪可手动超越控制。无线电设备安装在炮塔后部，该车的工作环境温度为零下40°～零上50°并可以空运。该车的制式设备包括红外滤光灯、聚光灯、外部储油箱、13.6L的饮水箱和1个电气接线盒等。任选设备包括导航设备、动力回转装置、核和化学探测设备及ZB298监视雷达。[5]\xa0'
            '随着地面战争发生了巨大变化，装甲侦察车也不例外。装甲侦察车的传统功能一直是在主力部队之前侦察并收集有关敌军和前方地形的准确战术信息，将信息发送给指挥官。侦察分队也可以执行侧翼掩护、路线侦察及护航任务。4×4型侦察车曾是典型的老一代轻型侦察车，由于外形尺寸小而不易被发现，并且仅装备机枪，如英国的“白鼬”（Ferret）和前苏联的BRDM-2。这些车辆的观察设备仅限于昼用瞄具和红外夜视器材，信息通过无线电台传递到下一指挥链，无线电波可能会被中途截获；车辆几乎无法准确地测定自己的位置。后来红外夜视装置逐渐被二代图像增强系统所取代，最近又被热像仪取代。尽管后者通常相当昂贵，但目标探测和识别的距离比过去远许多。新一代侦察车通常配有先进的侦察系统，包括昼用摄像机、热像仪、人眼安全激光测距机、精确地面导航系统和先进的通信系统。通过这些设备可以把数据实时传递到下一指挥链或高一级指挥层。当许多国家仍在使用装备精良的装甲平台执行侦察任务时，一些国家已开始装备带有专用传感器组件的小型车辆。未来侦察系统正逐渐演变为传感器平台，该平台与前几代平台最显著的区别是：传感器、通信和导航设备远比平台本身昂贵。关于侦察车应是轮式还是履带式的争论已持续了许多年，尚没有迹象表明这场争论会停止，最终方案取决于作战要求和预期地形。已被终止的英美TRACER/FSCS就是现代侦察平台的一个范例。Sika和Lancer财团各研制了一辆先进的全履带式样车，两者都装有遥控型40毫米埋头弹（CTA）武器系统。3名乘员坐在车内使用平面显示器，上面显示来自多个传感器的各种信息。车辆的隐身特征使其不易被探测到，橡胶带式履带能降低噪音，如果需要还可采用混合电传动系统来进行静默行驶。在当今的高科技世界，装甲侦察车仅是与指挥、控制、通信和计算机（C4）网络连接在一起的整个侦察、监视和目标捕获（RSTA）组件的一个组成部分。RSTA组件中还包括：卫星等各种空中传感器平台、各种固定翼和旋翼飞机及无人机（UAV）。由于信息需要很长时间才能传给用户，老式无人机的使用受到限制。包括雷达在内的各种地面传感器可提供关于敌军转移的信息，或为火炮和火箭系统定位打击目标。白俄罗斯监视器服务公司（MONITOR '
            'SERVISE）研制的2T Stalker是最近推出的侦察车之一，该车已在中东演示过多次。2T '
            'Stalker属于全履带式车辆，装备1门30毫米机关炮和1挺7.62毫米并列机枪，车顶装有两个导弹发射架：一个包括两枚发射后不管型地对空导弹，另一个包括两枚9K114 '
            'Kokon '
            '反坦克导弹。该车配有一套复杂的昼/夜火控系统。加拿大武装部队选择现在通用动力地面系统分部加拿大分公司研制的“小狼”（Coyote）来替代联合防御公司的“山猫”（Lynx）全履带式指挥侦察车。“小狼”以8×8型轻型装甲车（LAV）底盘为基础，并且保留了通用动力地面系统分部加利福尼亚技术中心研制的25毫米LAV-25炮塔。加拿大共采购约203辆“小狼”，由3种车型组成：一种装有桅杆式传感器组件；一种装有两个三脚架传感器组件；一种主要用于接收数据，但不装备传感器组件。桅杆式传感器组件装在炮塔后部，在不需要时可收在装甲下。桅杆顶端的传感器吊舱包括：1台监视雷达、1架远程电视摄像机（据称昼夜识别/探测距离可达18千米）和1具人眼安全激光测距机。桅杆在全装甲和核生化防护下可升高至10米。捷克VOP '
            '026 '
            '厂自称在履带式和轮式装甲车升级与维护方面具有丰富的经验。该国的Snezka侦察车是一种较新的平台，该车以加长型BMP底盘为基础，两侧各有7个负重轮。顶置式剪刀型装备中包括一套由雷达、昼夜电视摄像机、热成像摄像机、激光测距机和风速测量系统组成的传感器组件。把传感器吊舱升至顶端需要90秒，降下则需1分钟。Snezka侦察车还装有一套霍尼韦尔 '
            'TALIN '
            '导航系统和多种通信设备。该车已在捷克服役多年，并与以BMP底盘为基础的轻型观察系统（LOS）一起使用，LOS将部署在Snezka侦察车前方。LOS使用1门30毫米机关炮和带有昼夜电视系统、人眼安全激光测距机和激光目标标识/指示器的可伸缩式桅杆式传感器吊舱。该车还配有惯性导航系统和多种通信设备。VOP '
            '026 '
            '厂还为广泛使用的俄罗斯4×4型BRDM-2装甲车开发了一套升级组件，其中包括用柴油机代替汽油机，并拆除了车底备用轮胎。法国陆军使用装备105毫米炮的6×6型AMX-10RC装甲车和潘哈德4×4型VBL侦察车与勒克莱尔坦克协同作战。6×6型车辆已接受了延长使用寿命的改进，改进内容包括：炮塔、悬挂装置和传动装置，并安装热成像摄像机和终端信息系统。法国陆军装备1200多辆VBL侦察车，该车的生产还将持续多年。至少有9家海外客户购买了VBL，用于执行侦察、反坦克和防空等多种任务。标准车型的轴距为2.45米，此外还有长轴距车型（轴距为2.7米）。除了各种武器站，VBL还可安装桅杆式传感器吊舱。法国陆军还有192辆潘哈德6×6型ERC '
            '90 '
            'Sagaie装甲车，广泛用在非洲，巴尔干和中东地区。这些车辆将进行多方面升级，包括用燃油效率更高的柴油机代替标致V-6汽油机。ACMAT公司在已被验证的ACMAT底盘的基础上开发了VLRB装甲联络侦察车。为适应不同作战需求，该车可以装备不同的传感器组件和武器系统。该车也用作ACMAT公司与法国地面武器工业集团和泰利斯光电公司共同研制的SYPORA侦察系统的基础。VLRB车顶上装有泰利斯装甲战车（AFV）系统稳定型武器和侦察底座（SWARM）、M2式12.7毫米机枪和传感器组件。德国陆军使用莱茵金属公司地面系统分部研制的“鼬鼠” '
            '1空降车已有多年，该车装有“陶”式反坦克导弹或20毫米机关炮。约30辆装有“陶”式反坦克导弹的“鼬鼠”1最近被改装为侦察车，为此拆除了“陶”式导弹系统，在凸起的车顶上安装了新的上部结构，后部是一个可伸缩式桅杆，顶端装有STN '
            'Atlas Elektronik '
            'AOZ自动瞄准系统。莱茵金属公司地面系统分部生产的8×8型“山猫”（Luchs）侦察车多年来一直是德国陆军的制式侦察车，该车重20t，有3名乘员，其双人炮塔上装有20毫米机关炮和7.62毫米机枪，配有1具一代热像仪。ARGE '
            'Fennek财团（由荷兰SP宇航与车辆系统公司和德国克劳斯－玛菲·威格曼公司组成）研制的新型“非洲小狐”（Fennek）侦察车将取代“山猫”。根据目前的计划，德国陆军将接收202辆“非洲小狐”侦察车，而荷兰将接受410辆；首批车辆即将交付荷兰皇家陆军。侦察车型装有STN '
            'Atlas '
            'Elektronik研制的桅杆式传感器组件，该组件包括昼用热成像光学设备和人眼安全激光测距机。该车还装有导航系统和多种通信系统。以色列飞机工业公司RAMTAD分部研制了4×4型RAM系列轻型装甲车，除了作为武器平台外，这些车辆还可用作侦察车。几年前意大利陆军决定用8×8型105毫米“圣陶罗”（Centauro）装甲车补充其坦克车队。这些车辆被广泛用在索马里和巴尔干地区。“圣陶罗”拥有“豹” '
            '1坦克一样的火力，但其速度更快，战略机动性更强。意大利陆军已接收400辆“圣陶罗”，西班牙则已接收首批22辆，并又定购了62辆。最近由依维柯防务公司车辆分部与奥托·梅拉拉公司组成的依维柯·奥托财团研制了一种装备120毫米火炮的“圣陶罗”车型 '
            '，以及一个完整的特种车车族，其中包括装甲人员输送车。依维柯公司负责底盘，奥托·梅拉拉公司负责炮塔和武器装备。为满足意大利陆军的需求，依维柯公司还研制了轻型多用途车（LMV），英国阿尔维斯维克斯公司也在销售这种车辆。该车可用于完成多种任务，并装有顶置式武器站和监视组件。今年7月中旬该车被选作英国陆军的未来指挥联络车，预计英国陆军要采购486辆。波兰陆军装备有俄制4×4型BRDM-2侦察车，并开发了一些延长这些车辆使用寿命的升级组件。96I型车辆的特点是采用新型依维柯柴油机，拆除车底备用轮胎，车体和炮塔两侧各有一扇门，保留14.5毫米和7.62毫米机枪。97型车辆采用了类似的改进方案，但对炮塔进行了改装，安装了1具顶置式9K111系列Fagot反坦克制导武器，并用12.7毫米NSTV武器代替了14.5毫米机枪。96I型和97型正在服役，而最新的98型仍处在样车阶段，该车与97型类似，但还装有STN '
            'Atlas Elektronik BAA 观察与瞄准系统',
 'date': '',
 'keyword': '装甲侦察车',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6'} (scraper.py:257)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:42:28] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 3757,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 196257,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 98.900346,
 'file_count': 7,
 'file_status_count/downloaded': 7,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 42, 28, 781230),
 'httpcompression/response_bytes': 260598,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 306,
 'log_count/INFO': 34,
 'log_count/WARNING': 1,
 'memusage/max': 88002560,
 'memusage/startup': 68825088,
 'response_received_count': 8,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 40, 49, 880884)} (statscollectors.py:47)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA>
{'attributes': {'IATA代码': 'HUN',
                'ICAO代码': 'RCYU',
                'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_220,limit_1/format,f_auto',
                            '图片2': 'https://bkimg.cdn.bcebos.com/pic/7acb0a46f21fbe096b63e2f073321b338744eaf8078f?x-bce-process=image/resize,m_lfit,w_235,h_235,limit_1/format,f_auto',
                            '图片3': 'https://bkimg.cdn.bcebos.com/pic/e7cd7b899e510fb3b92f6774d233c895d1430c1a?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '花莲机场',
                '外文名': 'Hualien Airport',
                '所属地区': '',
                '机场类型': '台湾省',
                '运营机构': '花莲县新城乡',
                '通航日期': '1962年5月16日'},
 'content': '花莲机场，位于台湾省花莲县新城乡，在花莲县花莲市北方，其正式操作单位为台湾交通部民用航空局花莲航空站，同时也是台湾“国防部”位于花莲的军用机场。航空运输协会所制定的IATA机场代码为HUN；在国际民航组织所制定的ICAO机场代码为RCYU。花莲机场(2张)花莲机场（Hualien '
            'Airport）是位于中国台湾省花莲县新城乡的一座军民合用的机场，由交通部民用航空局花莲航空站运营管理，为花莲县及其周边地区提供航空服务。花莲机场的前身是日治时期的“花莲港北飞行场”，兴建于1936年，属于军民共用的机场，由日本航空株式会社经营。第二次世界大战结束后，由中华民国政府接收。1962年5月16日，花莲航空站成立，花莲机场正式投入使用，海拔高度为16米（52英尺）。机场共有两条跑道，即长宽分别为2750米×45米的03/21跑道和344米×20米的03L/21R跑道。花莲机场先后于2002年和2005年经历具有标志性的改扩建工程。新客运航站楼于2004年3月19日正式对外开放，总投资23亿新台币（6900万美元）。此外，该机场还有一座独立的货运航站楼供货运使用。花莲机场主营台湾地区性的定期航线和通往中国大陆地区的短途航班，直飞高雄、台中、台北、济南和天津等地，它是马英九政府开放两岸包机直航的航线。华信航空和TranAsia航空是该机场的主要运营商。[1]\xa0'
            '2004年3月19日：新航厦正式营运。其建筑融合了台湾原住民传统住屋，与汉族合院式住宅的特色。2004年8月8日：花莲与韩国仁川直航包机首航2004年10月19日：花莲与澳门直航包机首航2005年11月13日：中华航空股份有限公司重回花莲天空执行日本包机任务2006年1月30日：花莲与菲律宾马尼拉直航包机首航2006年10月26日：花莲与日本石垣岛直航包机首航2007年7月1日：澳门航空首航花莲机场，创花莲境外包机先例2007年9月3日：鹿儿岛包机首航B1：汽车停车场、多用途展示空间1F：离站出口、国内线到站区、国际线到站区、入境证照检查柜台、到站旅客等候区、行李托盘、公共汽车站、出租车排班站、大客车等候区、机车停车场、大客车停车场2F：搭机入口、远东航空柜台、华信航空柜台、复兴航空柜台、行李托运、出境联合服务柜台、商店街、保险柜台、自动提款机、贵宾室、出境证照检查柜台、国内线等候大厅、国际线等候大厅、1~3号空桥登机门、4号非空桥登机门3F：行政办公室、会议室、展览展示区、赏机室备有 '
            '7个停机坪 1~3号停机坪有空桥连接 '
            '4号登机门备有电扶梯连络4~7号停机坪※视评估扩充5~7号登机门及空桥，扩建工程第一期第一阶段并无建设.货运站独立一栋货运站场供货运使用往返台中：华信航空股份有限公司 '
            'FK50/FK100往返高雄：华信航空股份有限公司 FK50/FK100往返台北：远东航空 '
            'MD83/B757(暂停营运)、复兴航空 '
            'ATR72/A320日本：宫崎、小松、仙台、福岛、新潟、关西、花卷、松山、冈山、能登、石垣岛、富山、函馆韩国：首尔、济州岛港澳：澳门东南亚：马尼拉、吉隆坡直航航线花莲机场是马政府开放两岸包机直航的航线，但是此航线开放直航经济效应不足（没有足够的旅客）、让大陆籍航空公司飞航又会大幅增加国防成本（因为邻近军机场）。',
 'date': '',
 'keyword': '花莲机场',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA'} (scraper.py:257)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:42:28] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1855,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 174206,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 105.734829,
 'file_count': 3,
 'file_status_count/downloaded': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 42, 28, 787019),
 'httpcompression/response_bytes': 208288,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 349,
 'log_count/INFO': 85,
 'log_count/WARNING': 1,
 'memusage/max': 88002560,
 'memusage/startup': 67653632,
 'response_received_count': 4,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 40, 43, 52190)} (statscollectors.py:47)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6>
{'attributes': {'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/d4628535e5dde71190eff0d94da1d91b9d16fdfacbc7?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '装甲运输车',
                '主要分类': '履带式和轮式'},
 'content': '装甲运输车是指：具有较好机动性能的装甲战斗输送车辆，分履带式和轮式两种。该种车为装甲车族的基本型车，主要用于战时输送人员或坦克、步战车后跟进作战，有时也可运送作战物资等，一般可输送一个班的兵力，其武器装备为1-2挺机枪，通常具备水陆两用性能。',
 'date': '',
 'keyword': '装甲运输车',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6'} (scraper.py:257)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6>
{'attributes': {'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/6f061d950a7b020881cd22c262d9f2d3572cc889?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '装甲救护车',
                '作用': '辆',
                '特点': '装甲车',
                '类型': ''},
 'content': '指在战场环境下实行人员救护的装甲车辆，一般只装备一至两挺机枪作为自卫武器，防护力亦很弱。用于抢救人员，并将重伤员运送至后方。[1]\xa0'
            '用于敌火力下救护和运送伤员的轻型装甲车辆。分为履带式装甲救护车和轮式装甲救护车和轮式装甲救护车两种。车上通常配有医疗急救设备、器材和药品等。[2]\xa0',
 'date': '',
 'keyword': '装甲救护车',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6'} (scraper.py:257)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:42:28] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 900,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 61250,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 101.194115,
 'file_count': 1,
 'file_status_count/downloaded': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 42, 28, 799914),
 'httpcompression/response_bytes': 193954,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 323,
 'log_count/INFO': 56,
 'log_count/WARNING': 1,
 'memusage/max': 88002560,
 'memusage/startup': 68456448,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 40, 47, 605799)} (statscollectors.py:47)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:42:28] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 905,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52690,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 100.063785,
 'file_count': 1,
 'file_status_count/downloaded': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 42, 28, 809532),
 'httpcompression/response_bytes': 198889,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 316,
 'log_count/INFO': 51,
 'log_count/WARNING': 1,
 'memusage/max': 88002560,
 'memusage/startup': 68640768,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 10, 1, 40, 48, 745747)} (statscollectors.py:47)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://bkimg.cdn.bcebos.com/pic/8601a18b87d6277f9e2ff24e20760830e924b899563c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> (referer: None) (engine.py:250)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.pipelines.files ] - File (downloaded): Downloaded file from <GET https://bkimg.cdn.bcebos.com/pic/8601a18b87d6277f9e2ff24e20760830e924b899563c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg> referred in <None> (files.py:456)
[2022-03-10 01:42:28] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA/19178695>
{'attributes': {'img_url': {'图片1': 'https://bkimg.cdn.bcebos.com/pic/8601a18b87d6277f9e2ff24e20760830e924b899563c?x-bce-process=image/resize,m_lfit,w_536,limit_1/format,f_jpg'},
                '中文名': '直升机',
                '厂商': '互联网',
                '游戏平台': 'Android',
                '游戏类别': '飞行游戏',
                '语言类型': '英语',
                '资费提示': '完全免费',
                '软件格式': 'apk'},
 'content': '直升机是一款Android游戏。游戏中玩家要躲避障碍物；该游戏是直升机在一个山洞里飞行，但不要撞上墙壁，该有是一个很容易上瘾，简单的游戏，它的功能，操作方便和简单的用户界面。《直升机》，与《侠盗猎车》GameA经典直升机游戏，能够跻身前10名最流行的游戏。该游戏是直升机在一个山洞里飞行，但不要撞上墙壁，避免传入obstacles.The的时间越长，试点直升机，better.Don‘T忘记领取奖金框drop '
            'ing下来，它可以帮助你的直升机生存崩溃。回到当PC开始出现，成为跻身世界流行的那些昔日，尽管当时的那些游戏很简单，也许有点沉闷相比，这些游戏，但他们充满在我们的自由时间的空白，并永远留在我们的记忆中。那些经典的游戏，通过不眠之夜，艰难的时刻伴随着我们，见证了我们的成功和failure.Let“开始重播那些老games.This之旅，是一个很容易上瘾，简单的游戏，它的功能，操作方便和简单的用户界面。[1]\xa0',
 'date': '',
 'keyword': '直升机',
 'source': 'baidu',
 'title': 'None',
 'url': 'https://baike.baidu.com/item/%E7%9B%B4%E5%8D%87%E6%9C%BA/19178695'} (scraper.py:257)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:42:28] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1339,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 174743,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 104.741579,
 'file_count': 1,
 'file_status_count/downloaded': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 42, 28, 933198),
 'httpcompression/response_bytes': 205214,
 'httpcompression/response_count': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 347,
 'log_count/INFO': 86,
 'log_count/WARNING': 1,
 'memusage/max': 88002560,
 'memusage/startup': 67846144,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 3, 10, 1, 40, 44, 191619)} (statscollectors.py:47)
[2022-03-10 01:42:28] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:42:28] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.002266 (DataCleaning.py:41)
[2022-03-10 01:42:28] [    INFO] [  __main__ ] - 上传文件：/code/./result/baidu/baidu_马公机场_马公机场_20220310014228755279.json (MultisiteSchedule.py:276)
[2022-03-10 01:42:28] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:291)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 277, in upload_crawl_file
    connect.upload_file(file, "/text_crawl_file/")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 01:42:28] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:395)
[2022-03-10 01:42:28] [    INFO] [  __main__ ] - 上传文件：result/Images/马公机场_1.jpg (MultisiteSchedule.py:245)
[2022-03-10 01:42:28] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:261)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 246, in upload_crawl_img_new
    connect.upload_file(file_path, "/imageSearch")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 01:42:28] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:398)
[2022-03-10 01:42:28] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 01:43:23] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:43:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_8.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:43:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:43:24] [    INFO] [      wiki ] - Spider opened: wiki (middlewares.py:142)
[2022-03-10 01:43:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_8.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:43:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:43:24] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:43:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_8.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:43:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:43:24] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:43:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_8.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:43:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:43:24] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:43:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_8.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:43:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:43:24] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:43:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_8.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:43:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:43:24] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:43:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_8.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:43:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:43:24] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:43:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_8.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:43:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:43:24] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:43:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_8.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:43:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:43:24] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:43:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_8.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:43:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:43:24] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:43:24] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_8.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:43:24] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:43:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:43:24] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:43:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:43:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:43:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:43:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:43:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:43:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:43:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:43:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:43:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:43:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:43:45] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:06] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:44:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:44:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:44:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:44:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:44:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:44:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:44:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:44:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:44:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:44:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:44:24] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:44:27] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:44:27] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:44:27] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:44:27] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:44:27] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:44:27] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:44:27] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:44:27] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:44:27] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:44:27] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:44:27] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:44:27] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:44:27] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:44:27] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:44:27] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:44:27] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:44:27] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:44:27] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:44:27] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:44:27] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:44:27] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:44:27] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:44:27] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1488,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.393346,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 44, 27, 647130),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 20,
 'memusage/max': 71733248,
 'memusage/startup': 68001792,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 43, 24, 253784)} (statscollectors.py:47)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:44:27] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1399,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.565734,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 44, 27, 710721),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 103,
 'memusage/max': 71733248,
 'memusage/startup': 66064384,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 43, 24, 144987)} (statscollectors.py:47)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:44:27] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1424,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.51594,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 44, 27, 713921),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 66,
 'memusage/max': 71733248,
 'memusage/startup': 67190784,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 43, 24, 197981)} (statscollectors.py:47)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:44:27] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1485,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.497789,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 44, 27, 726963),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 45,
 'memusage/max': 71733248,
 'memusage/startup': 67731456,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 43, 24, 229174)} (statscollectors.py:47)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:44:27] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1485,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.512248,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 44, 27, 730077),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 56,
 'memusage/max': 71733248,
 'memusage/startup': 67461120,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 43, 24, 217829)} (statscollectors.py:47)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:44:27] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1475,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.493647,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 44, 27, 736450),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 43,
 'memusage/max': 71733248,
 'memusage/startup': 67731456,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 43, 24, 242803)} (statscollectors.py:47)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:44:27] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1471,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.53303,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 44, 27, 742616),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 70,
 'memusage/max': 71733248,
 'memusage/startup': 67190784,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 43, 24, 209586)} (statscollectors.py:47)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:44:27] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1457,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.56028,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 44, 27, 748351),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 89,
 'memusage/max': 71733248,
 'memusage/startup': 66924544,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 43, 24, 188071)} (statscollectors.py:47)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:44:27] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1445,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.597202,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 44, 27, 751398),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 116,
 'memusage/max': 71733248,
 'memusage/startup': 66400256,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 43, 24, 154196)} (statscollectors.py:47)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:44:27] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1485,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.582252,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 44, 27, 758754),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 103,
 'memusage/max': 71733248,
 'memusage/startup': 66670592,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 43, 24, 176502)} (statscollectors.py:47)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:44:27] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1444,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.599759,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 44, 27, 764342),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 114,
 'memusage/max': 71733248,
 'memusage/startup': 66670592,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 43, 24, 164583)} (statscollectors.py:47)
[2022-03-10 01:44:27] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:44:27] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.017370 (DataCleaning.py:41)
[2022-03-10 01:44:27] [    INFO] [  __main__ ] - 上传文件：/code/./result/baidu/baidu_马公机场_马公机场_20220310014228755279.json (MultisiteSchedule.py:276)
[2022-03-10 01:44:27] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:291)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 277, in upload_crawl_file
    connect.upload_file(file, "/text_crawl_file/")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 01:44:27] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:395)
[2022-03-10 01:44:27] [    INFO] [  __main__ ] - 上传文件：result/Images/花莲机场_3.jpg (MultisiteSchedule.py:245)
[2022-03-10 01:44:27] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:261)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 246, in upload_crawl_img_new
    connect.upload_file(file_path, "/imageSearch")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 01:44:27] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:398)
[2022-03-10 01:44:27] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 01:46:16] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:46:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_9.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:46:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:46:16] [    INFO] [      wiki ] - Spider opened: wiki (middlewares.py:142)
[2022-03-10 01:46:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_9.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:46:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:46:16] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:46:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_9.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:46:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:46:16] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:46:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_9.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:46:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:46:16] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:46:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_9.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:46:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:46:16] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:46:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_9.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:46:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:46:16] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:46:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_9.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:46:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:46:16] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:46:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_9.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:46:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:46:16] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:46:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_9.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:46:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:46:16] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:46:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_9.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:46:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:46:16] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:46:16] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_9.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:46:16] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:46:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:46:16] [    INFO] [   wiki_zh ] - Spider opened: wiki_zh (middlewares.py:142)
[2022-03-10 01:46:37] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:37] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:37] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:37] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:37] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:37] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:37] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:37] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:37] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:37] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:37] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:46:58] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:47:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:47:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:47:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:47:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:47:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:47:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:47:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:47:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:47:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:47:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:47:16] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:47:19] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:47:19] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:47:19] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:47:19] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:47:19] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:47:19] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:47:19] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:47:19] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:47:19] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:47:19] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:47:19] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:47:19] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:47:19] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:47:19] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:47:19] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:47:19] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:47:19] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:47:19] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:47:19] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1437,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.563129,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 47, 19, 823352),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 18,
 'log_count/INFO': 92,
 'memusage/max': 69709824,
 'memusage/startup': 66662400,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 46, 16, 260223)} (statscollectors.py:47)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:47:19] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1507,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.475977,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 47, 19, 825408),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 18,
 'log_count/INFO': 23,
 'memusage/max': 69709824,
 'memusage/startup': 68161536,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 46, 16, 349431)} (statscollectors.py:47)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:47:19] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1424,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.530318,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 47, 19, 831872),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 18,
 'log_count/INFO': 66,
 'memusage/max': 69709824,
 'memusage/startup': 67325952,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 46, 16, 301554)} (statscollectors.py:47)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:47:19] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1499,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.555354,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 47, 19, 833759),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 18,
 'log_count/INFO': 85,
 'memusage/max': 69709824,
 'memusage/startup': 66932736,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 46, 16, 278405)} (statscollectors.py:47)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:47:19] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1484,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.530245,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 47, 19, 869355),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 18,
 'log_count/INFO': 40,
 'memusage/max': 69709824,
 'memusage/startup': 67891200,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 46, 16, 339110)} (statscollectors.py:47)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:47:19] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1458,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.580961,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 47, 19, 870817),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 18,
 'log_count/INFO': 83,
 'memusage/max': 69709824,
 'memusage/startup': 67026944,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 46, 16, 289856)} (statscollectors.py:47)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:47:19] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1494,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.563152,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 47, 19, 872281),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 18,
 'log_count/INFO': 70,
 'memusage/max': 69709824,
 'memusage/startup': 67325952,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 46, 16, 309129)} (statscollectors.py:47)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:47:19] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:47:19] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:47:19] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:47:19] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:47:19] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1478,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.646515,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 47, 19, 975489),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 57,
 'memusage/max': 69709824,
 'memusage/startup': 67624960,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 46, 16, 328974)} (statscollectors.py:47)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:47:19] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1408,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.72954,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 47, 19, 981569),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 124,
 'memusage/max': 69709824,
 'memusage/startup': 66396160,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 46, 16, 252029)} (statscollectors.py:47)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:47:19] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1485,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.670807,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 47, 19, 991247),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 71,
 'memusage/max': 69709824,
 'memusage/startup': 67624960,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 46, 16, 320440)} (statscollectors.py:47)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:47:19] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1443,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.723959,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 47, 19, 994807),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 22,
 'log_count/INFO': 114,
 'memusage/max': 69709824,
 'memusage/startup': 66662400,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 46, 16, 270848)} (statscollectors.py:47)
[2022-03-10 01:47:19] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:47:20] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.001930 (DataCleaning.py:41)
[2022-03-10 01:47:20] [    INFO] [  __main__ ] - 上传文件：/code/./result/baidu/baidu_马公机场_马公机场_20220310014228755279.json (MultisiteSchedule.py:276)
[2022-03-10 01:47:20] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:291)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 277, in upload_crawl_file
    connect.upload_file(file, "/text_crawl_file/")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 01:47:20] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:395)
[2022-03-10 01:47:20] [    INFO] [  __main__ ] - 上传文件：result/Images/直升机_1.jpg (MultisiteSchedule.py:245)
[2022-03-10 01:47:20] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:261)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 246, in upload_crawl_img_new
    connect.upload_file(file_path, "/imageSearch")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 01:47:20] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:398)
[2022-03-10 01:47:20] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 01:51:11] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:51:22] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:51:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_10.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'TextProcessorScrapy.middlewares.RandomUserAgentMiddleware',
 'TextProcessorScrapy.middlewares.TextCrawlDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:51:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:51:22] [    INFO] [      wiki ] - Spider opened: wiki (middlewares.py:142)
[2022-03-10 01:51:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_10.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:51:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_10.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:51:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_10.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:51:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_10.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:51:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_10.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:51:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_10.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:51:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_10.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:51:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_10.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:51:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_10.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:51:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_10.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:51:22] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:51:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:51:23] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 01:51:23] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 01:51:23] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 01:51:23] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (redirect.py:42)
[2022-03-10 01:51:23] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 01:51:23] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 01:51:23] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 01:51:23] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 01:51:23] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 01:51:23] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 01:51:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:51:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:51:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:51:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:51:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:51:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:51:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:51:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BE%93%E9%80%81%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BE%93%E9%80%81%E8%BD%A6>
{'keyword': '装甲防护车', 'source': 'wiki', 'title': '装甲输送车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BE%93%E9%80%81%E8%BD%A6', 'date': ' ', 'content': '装甲输送车（英文：Armoured personnel carrier，缩写：APC）又称装甲运兵车，指在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。在必要时，也可以使用车上的武器攻击敌人。\xa0加拿大：\xa0中华民国 ：\xa0中华人民共和国：\xa0芬兰：\xa0法国：\xa0德国：\xa0以色列：\xa0日本：\xa0俄罗斯：\xa0新加坡：\xa0瑞士：\xa0美国：\xa0乌克兰：\xa0土耳其：装甲输送车出现的时间与战车约略同期，第一次世界大战末期，英国推出专门用来运输步兵的马克IX型坦克。由于坦克本身的成本较当时使用的卡车高出许多，有些国家是以加装装甲的汽车权充兼作运输的用途。1930年代许多国家开始发展机械化部队，由于全履带车的造价与维护成本依旧居高不下，为了配合战车的运动速度与越野能力，半履带车加上防护装甲之后成为最常见的型态。二次世界大战期间，美国的M3半履带车与德国SdKfz 251半履带车是最著名的代表。这些车辆拥有防御小口径武器与弹药破片的侧面装甲，但是欠缺顶部的保护。车体上以携带机枪最为常见。而战争中期以后盟军开始将M4中型坦克改装成装甲输送车使用。到冷战时期，由于核战阴影的威胁、履带动力装置成本下降加上铝合金的使用，装甲输送车开始具备封闭式车身，为了与步兵共同作战而演化出步兵战斗车这类重武装车种。', 'attributes': {'装甲输送车': {}}} (scraper.py:257)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6>
{'keyword': '装甲侦察车', 'source': 'wiki', 'title': '装甲车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6', 'date': ' ', 'content': '装甲车辆是具有装甲防护的各种车辆的统称。坦克和自走炮也是广义的重型装甲车辆，但是在习惯上通常因作战用途另外独立分类，而装甲车辆多半是指防护力与火力较坦克弱的车种，而自行炮在原则上不一定要有装甲。装甲车的特性为具有高度的越野机动性能，有一定的防护和火力，分为履带式和轮式两种。一般军用装甲车会装备一至三门中小口径火炮及数挺机枪，一些还装有反坦克导弹，结构以装甲车体、武器系统、动力装置等组成。为了增强防护和方便成员下车战斗。大多数军用装甲车辆可以在水上行驶，可以执行运输、侦察、指挥、救护、伴随、支援坦克及步兵作战等多种任务，还有执行专门任务的装甲车辆，如装甲回收车、装甲指挥车、装甲扫雷车、装甲架桥车等。在警用领域多用于镇压暴乱等问题。步兵战车和装甲输送车作用相近，都是运送步兵机动作战用的装甲车辆，两者不同的地方是步兵战车的防护力较好，火力较大，能够让步兵乘车作战，本身也能够伴随下车作战的步兵，提供火力支援速度较好，装甲输送车则更接近于有装甲的运输车辆。装甲输送车为在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。装甲侦察车指装有侦察设备的装甲车辆，速度较快但装甲比其它装甲车辆要薄，多用于战场侦察，一般可分为轮式和履带式两种。较著名的装甲侦察车，有德国的狐式轻型装甲侦察车、山猫装甲侦察车，法国的雷诺VBC90轮式侦察车（英语：VBC-90）等等。装甲指挥车是具有装甲保护的移动指挥站，提供指挥官与支援的参谋和其他人员协调部队的相关事宜。装甲指挥车是早期以卡车或者是拖车为基础的移动指挥所衍生出来的架构，用意在于提供指挥单位快速移动，持续掌握情势与下达命令命且提供一些保护。大部分的装甲指挥车是从装甲输送车改装而成，扩大内部的空间以容纳额外的人员，通讯器材与其他设备。在到达预定指挥地点之后，部分装甲指挥车还有另外设置的顶蓬可以伸出车外，进一步的扩大人员使用的空间。装甲通信车是指装有通信设备的装甲车辆，常见的设计有两种型态，一种是将通信装备与装甲指挥车合并在一起，因此并非单纯的通信车辆。另外一种是做为地面通信的活动中转站，以延伸无线电通信的有效距离，或者是克服地形对通信的遮蔽效应，强化地面单位之间的联络与资讯交换。目前各国陆军很少装备单纯的装甲通信车，不过有不少国家配备由一般运输车辆改装的通信车辆来支援地面部队的通信需求。装甲救护车，指在战场环境下实行人员救护的装甲车辆，一般只装备一至两挺机枪作为自卫武器，防护力亦很弱。主要用于抢救人员，并将重伤员运送至后方。装甲扫雷车特指装有清除地雷装置的装甲车辆，以协助地面部队扩速通过地雷区。装甲扫雷车可以是专门设计用来清除地雷，或者是将清除工具附加在一般用途的坦 克底盘上，无论是车轮或是履带型态的扫雷车都可见于不同国家的部队当中。装甲扫雷车并非用于清除整个被发现的地雷区，而是将地雷区清理出一至数条的安全通道，提供地面部队人员和车辆安全通过。排除的地雷可能在过程中加以引爆，或者是移动到安全的地方之后另外加以处理。由于清理的过程当中，扫雷车可能碰触或者是引爆其他尚未发现的地雷或者是爆裂物，车辆本身对于底盘和车辆底部的保护需要特别加强，以免被地雷或者是爆裂物瘫痪而无法完成清除的任务。装甲架桥车指装有车桥及其架设、撤收装置的装甲车辆，主要用于快速架设桥梁，令部队迅速通过河流，普遍装备于工兵部队。装甲架桥车可由一般坦克或自走炮底盘改装而成，部分会保留机枪作防卫用途。步兵坦 克和装甲输送车 - 当示威活动和抗争会转变成失控的暴乱或群众暴力时，警方有时会出动警用装甲车控制场面。一般具有水炮功能，而车窗经特别制造，不易打碎。各地警方大多都有装甲车，以防范暴乱发生。保安公司常用，用来运载现金或其他贵重物品，又称“解款车”或“运钞车”。另外政要及富豪也会使用经过改装、具有防弹甚至抗炸能力的汽车。', 'attributes': {'装甲车': {}}} (scraper.py:257)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6>
{'keyword': '装甲救护车', 'source': 'wiki', 'title': '装甲车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6', 'date': ' ', 'content': '装甲车辆是具有装甲防护的各种车辆的统称。坦克和自走炮也是广义的重型装甲车辆，但是在习惯上通常因作战用途另外独立分类，而装甲车辆多半是指防护力与火力较坦克弱的车种，而自行炮在原则上不一定要有装甲。装甲车的特性为具有高度的越野机动性能，有一定的防护和火力，分为履带式和轮式两种。一般军用装甲车会装备一至三门中小口径火炮及数挺机枪，一些还装有反坦克导弹，结构以装甲车体、武器系统、动力装置等组成。为了增强防护和方便成员下车战斗。大多数军用装甲车辆可以在水上行驶，可以执行运输、侦察、指挥、救护、伴随、支援坦克及步兵作战等多种任务，还有执行专门任务的装甲车辆，如装甲回收车、装甲指挥车、装甲扫雷车、装甲架桥车等。在警用领域多用于镇压暴乱等问题。步兵战车和装甲输送车作用相近，都是运送步兵机动作战用的装甲车辆，两者不同的地方是步兵战车的防护力较好，火力较大，能够让步兵乘车作战，本身也能够伴随下车作战的步兵，提供火力支援速度较好，装甲输送车则更接近于有装甲的运输车辆。装甲输送车为在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。装甲侦察车指装有侦察设备的装甲车辆，速度较快但装甲比其它装甲车辆要薄，多用于战场侦察，一般可分为轮式和履带式两种。较著名的装甲侦察车，有德国的狐式轻型装甲侦察车、山猫装甲侦察车，法国的雷诺VBC90轮式侦察车（英语：VBC-90）等等。装甲指挥车是具有装甲保护的移动指挥站，提供指挥官与支援的参谋和其他人员协调部队的相关事宜。装甲指挥车是早期以卡车或者是拖车为基础的移动指挥所衍生出来的架构，用意在于提供指挥单位快速移动，持续掌握情势与下达命令命且提供一些保护。大部分的装甲指挥车是从装甲输送车改装而成，扩大内部的空间以容纳额外的人员，通讯器材与其他设备。在到达预定指挥地点之后，部分装甲指挥车还有另外设置的顶蓬可以伸出车外，进一步的扩大人员使用的空间。装甲通信车是指装有通信设备的装甲车辆，常见的设计有两种型态，一种是将通信装备与装甲指挥车合并在一起，因此并非单纯的通信车辆。另外一种是做为地面通信的活动中转站，以延伸无线电通信的有效距离，或者是克服地形对通信的遮蔽效应，强化地面单位之间的联络与资讯交换。目前各国陆军很少装备单纯的装甲通信车，不过有不少国家配备由一般运输车辆改装的通信车辆来支援地面部队的通信需求。装甲救护车，指在战场环境下实行人员救护的装甲车辆，一般只装备一至两挺机枪作为自卫武器，防护力亦很弱。主要用于抢救人员，并将重伤员运送至后方。装甲扫雷车特指装有清除地雷装置的装甲车辆，以协助地面部队扩速通过地雷区。装甲扫雷车可以是专门设计用来清除地雷，或者是将清除工具附加在一般用途的坦 克底盘上，无论是车轮或是履带型态的扫雷车都可见于不同国家的部队当中。装甲扫雷车并非用于清除整个被发现的地雷区，而是将地雷区清理出一至数条的安全通道，提供地面部队人员和车辆安全通过。排除的地雷可能在过程中加以引爆，或者是移动到安全的地方之后另外加以处理。由于清理的过程当中，扫雷车可能碰触或者是引爆其他尚未发现的地雷或者是爆裂物，车辆本身对于底盘和车辆底部的保护需要特别加强，以免被地雷或者是爆裂物瘫痪而无法完成清除的任务。装甲架桥车指装有车桥及其架设、撤收装置的装甲车辆，主要用于快速架设桥梁，令部队迅速通过河流，普遍装备于工兵部队。装甲架桥车可由一般坦克或自走炮底盘改装而成，部分会保留机枪作防卫用途。步兵坦 克和装甲输送车 - 当示威活动和抗争会转变成失控的暴乱或群众暴力时，警方有时会出动警用装甲车控制场面。一般具有水炮功能，而车窗经特别制造，不易打碎。各地警方大多都有装甲车，以防范暴乱发生。保安公司常用，用来运载现金或其他贵重物品，又称“解款车”或“运钞车”。另外政要及富豪也会使用经过改装、具有防弹甚至抗炸能力的汽车。', 'attributes': {'装甲车': {}}} (scraper.py:257)
[2022-03-10 01:51:25] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:51:25] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1604,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 39470,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 3.007423,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 51, 25, 615230),
 'httpcompression/response_bytes': 141127,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 27,
 'log_count/INFO': 36,
 'memusage/max': 67399680,
 'memusage/startup': 67399680,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 51, 22, 607807)} (statscollectors.py:47)
[2022-03-10 01:51:25] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6>
{'keyword': '装甲扫雷车', 'source': 'wiki', 'title': '装甲车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6', 'date': ' ', 'content': '装甲车辆是具有装甲防护的各种车辆的统称。坦克和自走炮也是广义的重型装甲车辆，但是在习惯上通常因作战用途另外独立分类，而装甲车辆多半是指防护力与火力较坦克弱的车种，而自行炮在原则上不一定要有装甲。装甲车的特性为具有高度的越野机动性能，有一定的防护和火力，分为履带式和轮式两种。一般军用装甲车会装备一至三门中小口径火炮及数挺机枪，一些还装有反坦克导弹，结构以装甲车体、武器系统、动力装置等组成。为了增强防护和方便成员下车战斗。大多数军用装甲车辆可以在水上行驶，可以执行运输、侦察、指挥、救护、伴随、支援坦克及步兵作战等多种任务，还有执行专门任务的装甲车辆，如装甲回收车、装甲指挥车、装甲扫雷车、装甲架桥车等。在警用领域多用于镇压暴乱等问题。步兵战车和装甲输送车作用相近，都是运送步兵机动作战用的装甲车辆，两者不同的地方是步兵战车的防护力较好，火力较大，能够让步兵乘车作战，本身也能够伴随下车作战的步兵，提供火力支援速度较好，装甲输送车则更接近于有装甲的运输车辆。装甲输送车为在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。装甲侦察车指装有侦察设备的装甲车辆，速度较快但装甲比其它装甲车辆要薄，多用于战场侦察，一般可分为轮式和履带式两种。较著名的装甲侦察车，有德国的狐式轻型装甲侦察车、山猫装甲侦察车，法国的雷诺VBC90轮式侦察车（英语：VBC-90）等等。装甲指挥车是具有装甲保护的移动指挥站，提供指挥官与支援的参谋和其他人员协调部队的相关事宜。装甲指挥车是早期以卡车或者是拖车为基础的移动指挥所衍生出来的架构，用意在于提供指挥单位快速移动，持续掌握情势与下达命令命且提供一些保护。大部分的装甲指挥车是从装甲输送车改装而成，扩大内部的空间以容纳额外的人员，通讯器材与其他设备。在到达预定指挥地点之后，部分装甲指挥车还有另外设置的顶蓬可以伸出车外，进一步的扩大人员使用的空间。装甲通信车是指装有通信设备的装甲车辆，常见的设计有两种型态，一种是将通信装备与装甲指挥车合并在一起，因此并非单纯的通信车辆。另外一种是做为地面通信的活动中转站，以延伸无线电通信的有效距离，或者是克服地形对通信的遮蔽效应，强化地面单位之间的联络与资讯交换。目前各国陆军很少装备单纯的装甲通信车，不过有不少国家配备由一般运输车辆改装的通信车辆来支援地面部队的通信需求。装甲救护车，指在战场环境下实行人员救护的装甲车辆，一般只装备一至两挺机枪作为自卫武器，防护力亦很弱。主要用于抢救人员，并将重伤员运送至后方。装甲扫雷车特指装有清除地雷装置的装甲车辆，以协助地面部队扩速通过地雷区。装甲扫雷车可以是专门设计用来清除地雷，或者是将清除工具附加在一般用途的坦 克底盘上，无论是车轮或是履带型态的扫雷车都可见于不同国家的部队当中。装甲扫雷车并非用于清除整个被发现的地雷区，而是将地雷区清理出一至数条的安全通道，提供地面部队人员和车辆安全通过。排除的地雷可能在过程中加以引爆，或者是移动到安全的地方之后另外加以处理。由于清理的过程当中，扫雷车可能碰触或者是引爆其他尚未发现的地雷或者是爆裂物，车辆本身对于底盘和车辆底部的保护需要特别加强，以免被地雷或者是爆裂物瘫痪而无法完成清除的任务。装甲架桥车指装有车桥及其架设、撤收装置的装甲车辆，主要用于快速架设桥梁，令部队迅速通过河流，普遍装备于工兵部队。装甲架桥车可由一般坦克或自走炮底盘改装而成，部分会保留机枪作防卫用途。步兵坦 克和装甲输送车 - 当示威活动和抗争会转变成失控的暴乱或群众暴力时，警方有时会出动警用装甲车控制场面。一般具有水炮功能，而车窗经特别制造，不易打碎。各地警方大多都有装甲车，以防范暴乱发生。保安公司常用，用来运载现金或其他贵重物品，又称“解款车”或“运钞车”。另外政要及富豪也会使用经过改装、具有防弹甚至抗炸能力的汽车。', 'attributes': {'装甲车': {}}} (scraper.py:257)
[2022-03-10 01:51:25] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:51:25] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1586,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 41639,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 3.12236,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 51, 25, 765781),
 'httpcompression/response_bytes': 155252,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 28,
 'log_count/INFO': 11,
 'memusage/max': 67973120,
 'memusage/startup': 67973120,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 51, 22, 643421)} (statscollectors.py:47)
[2022-03-10 01:51:25] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:51:25] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:51:25] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1586,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 41229,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 3.144852,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 51, 25, 779401),
 'httpcompression/response_bytes': 151063,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 28,
 'log_count/INFO': 21,
 'memusage/max': 67973120,
 'memusage/startup': 67973120,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 51, 22, 634549)} (statscollectors.py:47)
[2022-03-10 01:51:25] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:51:25] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:51:25] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1586,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 41546,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 3.168394,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 51, 25, 784093),
 'httpcompression/response_bytes': 151557,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 28,
 'log_count/INFO': 38,
 'memusage/max': 67706880,
 'memusage/startup': 67706880,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 51, 22, 615699)} (statscollectors.py:47)
[2022-03-10 01:51:25] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 01:51:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 01:51:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4>
{'keyword': '澎湖机场', 'source': 'wiki', 'title': '澎湖机场', 'url': 'https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4', 'date': ' ', 'content': "澎湖机场（闽南语白话字：.mw-parser-output .IPA{font-family:'Charis SIL','Doulos SIL','Linux Libertine','Segoe UI','Lucida Sans Unicode','Code2000','Gentium','Gentium Alternative','TITUS Cyberbit Basic','Arial Unicode MS','IPAPANNEW','Chrysanthi Unicode','GentiumAlt','Bitstream Vera','Bitstream Cyberbit','Hiragino Kaku Gothic Pro','Lucida Grande',sans-serif;text-decoration:none!important}.mw-parser-output .IPA a:link,.mw-parser-output .IPA a:visited{text-decoration:none!important}Phîⁿ-ô͘/Phêⁿ-ô͘ Ki-tiû；IATA代码：MZG；ICAO代码：RCQC），是一座位于台湾澎湖县湖西乡隘门村的军民合用机场，为该县主要联外机场，旧名“马公机场”。民用部分由交通部民用航空局马公航空站[注 1]管理及营运；军用部分为空军马公基地。由立荣航空、华信航空、德安航空营运台北松山、台中、台南、嘉义、高雄、金门及七美共7条航线，主要以ATR72-600、A321-200、DHC6-400等机型执飞。2019冠状病毒病疫情爆发，国际线需求下降，但离岛航线需求大增，华信航空部分航班由台湾虎航A320-200营运。", 'attributes': {'澎湖机场': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/ROCAF_F-5A_in_Makung_AB_1974.jpg/250px-ROCAF_F-5A_in_Makung_AB_1974.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Magong_Airport.jpg/150px-Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png/80px-%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png', 'https://upload.wikimedia.org/wikipedia/commons/7/7d/Aerial_view_of_Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Taiwan_location_map.svg/250px-Taiwan_location_map.svg.png'], '机场类型': '军民合用', '营运者': '军用： 中华民国空军民用： 交通部民用航空局', '服务城市': '澎湖县', '地理位置': '中华民国（台湾）澎湖县湖西乡隘门村126-5号', '启用日期': '军用：1937年民用：1977年8月1日(1977-08-01)', '海拔高度': '103英尺（31米）', '坐标': '23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833坐标：23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833', '网址': 'www.mkport.gov.tw', '方向': ';;;方向;;长度;;表面;;;米;;英尺;;;02/20;;3,000;;9,843;;混凝土;;', '客运量': '客运量2,320,249 人次货运量6,060.863 公吨起降架次35,682 次', '繁体字': ' 澎湖機場 ', '简化字': ' 澎湖机场 ', '标音': "标音官话-汉语拼音 Péng hú Háng kōng zhàn -威妥玛拼音 Pʻêng2 hu2 hang2 k'ung chan4 -耶鲁拼音 Péng hú háng kūng jàn -注音符号ㄆㄥˊ ㄏㄨˊ ㄏㄤˊ ㄎㄨㄥ ㄓㄢˋ闽语-闽南语白话字 Phîⁿ-ô͘/Phêⁿ-ô͘  hái-khang-chām -台罗拼音 Phînn-ôo/Phênn-ôo hâng-khong-tsām 客家话-客家话拼音 Pang2 fu2 hong2 kung1 zam4 -客语白话字 Phàng-fù hòng-khûng chham ", '汉语': '澎湖航空站'}}} (scraper.py:257)
[2022-03-10 01:51:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4>
{'keyword': '马公机场', 'source': 'wiki', 'title': '澎湖机场', 'url': 'https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4', 'date': ' ', 'content': "澎湖机场（闽南语白话字：.mw-parser-output .IPA{font-family:'Charis SIL','Doulos SIL','Linux Libertine','Segoe UI','Lucida Sans Unicode','Code2000','Gentium','Gentium Alternative','TITUS Cyberbit Basic','Arial Unicode MS','IPAPANNEW','Chrysanthi Unicode','GentiumAlt','Bitstream Vera','Bitstream Cyberbit','Hiragino Kaku Gothic Pro','Lucida Grande',sans-serif;text-decoration:none!important}.mw-parser-output .IPA a:link,.mw-parser-output .IPA a:visited{text-decoration:none!important}Phîⁿ-ô͘/Phêⁿ-ô͘ Ki-tiû；IATA代码：MZG；ICAO代码：RCQC），是一座位于台湾澎湖县湖西乡隘门村的军民合用机场，为该县主要联外机场，旧名“马公机场”。民用部分由交通部民用航空局马公航空站[注 1]管理及营运；军用部分为空军马公基地。由立荣航空、华信航空、德安航空营运台北松山、台中、台南、嘉义、高雄、金门及七美共7条航线，主要以ATR72-600、A321-200、DHC6-400等机型执飞。2019冠状病毒病疫情爆发，国际线需求下降，但离岛航线需求大增，华信航空部分航班由台湾虎航A320-200营运。", 'attributes': {'澎湖机场': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/ROCAF_F-5A_in_Makung_AB_1974.jpg/250px-ROCAF_F-5A_in_Makung_AB_1974.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Magong_Airport.jpg/150px-Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png/80px-%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png', 'https://upload.wikimedia.org/wikipedia/commons/7/7d/Aerial_view_of_Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Taiwan_location_map.svg/250px-Taiwan_location_map.svg.png'], '机场类型': '军民合用', '营运者': '军用： 中华民国空军民用： 交通部民用航空局', '服务城市': '澎湖县', '地理位置': '中华民国（台湾）澎湖县湖西乡隘门村126-5号', '启用日期': '军用：1937年民用：1977年8月1日(1977-08-01)', '海拔高度': '103英尺（31米）', '坐标': '23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833坐标：23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833', '网址': 'www.mkport.gov.tw', '方向': ';;;方向;;长度;;表面;;;米;;英尺;;;02/20;;3,000;;9,843;;混凝土;;', '客运量': '客运量2,320,249 人次货运量6,060.863 公吨起降架次35,682 次', '繁体字': ' 澎湖機場 ', '简化字': ' 澎湖机场 ', '标音': "标音官话-汉语拼音 Péng hú Háng kōng zhàn -威妥玛拼音 Pʻêng2 hu2 hang2 k'ung chan4 -耶鲁拼音 Péng hú háng kūng jàn -注音符号ㄆㄥˊ ㄏㄨˊ ㄏㄤˊ ㄎㄨㄥ ㄓㄢˋ闽语-闽南语白话字 Phîⁿ-ô͘/Phêⁿ-ô͘  hái-khang-chām -台罗拼音 Phînn-ôo/Phênn-ôo hâng-khong-tsām 客家话-客家话拼音 Pang2 fu2 hong2 kung1 zam4 -客语白话字 Phàng-fù hòng-khûng chham ", '汉语': '澎湖航空站'}}} (scraper.py:257)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:51:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1568,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 49176,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 3.727992,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 51, 26, 295000),
 'httpcompression/response_bytes': 199809,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 32,
 'log_count/INFO': 76,
 'memusage/max': 66859008,
 'memusage/startup': 66859008,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 51, 22, 567008)} (statscollectors.py:47)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:51:26] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E7%9B%B4%E5%8D%87%E6%A9%9F> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 01:51:26] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:51:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1568,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 48923,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 3.766078,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 51, 26, 325494),
 'httpcompression/response_bytes': 199399,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 34,
 'log_count/INFO': 86,
 'memusage/max': 66588672,
 'memusage/startup': 66588672,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 51, 22, 559416)} (statscollectors.py:47)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:51:26] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/SdKfz_252%E5%8D%8A%E5%B1%A5%E5%B8%A6%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 01:51:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E7%9B%B4%E5%8D%87%E6%A9%9F>
{'keyword': '直升机', 'source': 'wiki', 'title': '直升机', 'url': 'https://zh.wikipedia.org/wiki/%E7%9B%B4%E5%8D%87%E6%A9%9F', 'date': ' ', 'content': '直升机是一种由水平旋转的动力旋翼提供向上升力和飞行推进力的飞行器，是旋翼航空器的主要种类。直升机具有大多数固定翼飞机所不具备的垂直起降、悬停和随意向前、向后或侧向飞行的能力，这些特点使得直升机在很多狭窄、崎岖、缺乏跑道的复杂环境下有许多优势。与固定翼飞机相比，直升机的缺点是速度低、耗油量较高、航程较短、载重较少。直升机旋翼产生升力的原理与固定翼飞机的机翼相似，通过翼剖面与空气发生相对运动使得旋翼产生上弱下强的气压差，进而产生升力并通过旋翼的主轴传递给机身，使其可以克服重力实现飞行。和固定翼飞机的机翼一样，直升机旋桨能够产生的升力大小取决于气流速度和其桨叶水平投影面积的总和；但直升机不像固定翼飞机那样必须依赖整个机体的向前运动才能让机翼产生气流，而是依靠翼片的旋转产生与空气的相对运动。但旋翼在提供升力的同时也会产生反扭矩（与旋翼的转动方向相反、角动量相等的反作用扭矩）并传递到机身上，这使得最为常见的单旋翼直升机在浮空时会向着旋桨相反的方向自旋。为了平衡反扭矩，直升机需要在机尾位置产生一个与旋翼方向相同、角动量相等的水平旋转推力抵消反力矩，最常见的做法是在机尾末端安装一个垂直的小型螺旋桨（即尾桨）提供推力。而双旋翼和多旋翼直升机多采用让反向旋转的旋翼之间的扭矩相互抵消的方法来清除反扭矩，并可以利用各个旋翼的转速差别来改变飞行状态。在附图的运作说明中可以见得，由上俯视一个顺时针旋转的主翼，它的尾桨会是向黄色箭头所指方向推力的。直升机和自转旋翼机的外观相似，但是飞行原理和性能并不同。自转旋翼机的发动机只驱动尾部的螺旋桨提供前进推力，主旋桨并没有动力源，必须依赖向前运动时的相对反向气流才能被动旋转产生升力。自转旋翼机虽然构造比较简单和低价也可以做到短程起降，但完全没有垂直起降、悬停、随意侧飞和倒飞的能力，不如直升机的性能广泛，是介乎于固定翼飞机和直升机中间的一种对跑道要求较低的飞行器。用途较狭而专业化的航空机构通常拥有直升机，但鲜有采用旋翼机。人类梦想的飞行方式是原地腾空而起，既能自由飞翔又能悬停于空中，并且随意实现定点着陆。例如阿拉伯人的飞毯，希腊神的战车，都是垂直起落飞行器。其中最有价值、最具代表性的是中国古代玩具竹蜻蜓和意大利人达·芬奇关于垂直起降航空器的画作。李约瑟误以为中国晋朝葛洪所著的《抱朴子》有纪录类似竹蜻蜓最早的动力机械[1]，但实际上文章说的是服丹修练成仙成功时，人可以飞行[2]。《简明不列颠百科全书》第9卷写道：“直升机是人类最早的飞行设想之一，多年来人们一直相信最早提出这一想法的是达·芬奇，但现在都知道，中国人比中世纪的欧洲人更早做出了直升机玩具。”这种玩具于14世纪传到欧洲。“英国航空之父”乔治·凯利（1773年－1857年）曾制造过几个竹蜻蜓，用钟表发条作为动力来驱动旋转，飞行高度曾达27米。随着生产力的发展和人类文明的进步，直升机的发展史由幻想时期进入了探索时期。欧洲产业革命之后，机械工业迅速倔起，尤其是本世纪初汽车和轮船的发展，为飞行器准备了发动机和可供借鉴的螺旋桨。经过航空先驱者们勇敢而艰苦的创造和试验，1903年莱特兄弟（Wright brothers）制造的固定翼飞机飞行成功。在此期间，尽管在发展直升机方面，航空先驱们付出了相当的艰辛和努力，但由于直升机技术的复杂性和发动机性能不佳，它的成功飞行比飞机迟了30多年。20世纪初为直升机发展的探索期，多种试验性机型相继问世。试验机方案的多样性表明了探索阶段的技术不成熟性。经过多年实践，这些方案中只有纵列式和共轴双旋翼式保留了下来，至今仍在应用。双桨横列式方案未在直升机家族中延续，但在倾转旋翼飞机中得到了继承和发展。俄国人尤利耶夫另辟捷径，提出了利用尾桨来配平旋翼反扭矩的设计方案并于1912年制造出了试验机。这种单旋翼带尾桨式直升机成为至今最流行的形式。经过20世纪初的努力探索，为直升机发展积累了可贵的经验并取得显著进展，有多架试验机实现了短暂的垂直升空和短距飞行，但离实用还有很大距离。飞机工业的发展使航空发动机的性能迅速提高，为直升机的成功提供了重要条件。旋翼技术的第一次突破，归功于西班牙人Ciervao，他为了创造“不失速”的飞机以解决固定翼飞机的安全问题，采用自转旋翼代替机翼，发明了自转旋翼机。旋翼技术在自转旋翼机上的成功应用和发展，为直升机的诞生提供了另一个重要条件。1907年8月，法国人保罗·科尔尼研制出一架全尺寸载人直升机，并在同年11月13日试飞成功。这架直升机被称为“人类第一架直升机”。1938年，年轻的德国人汉纳赖奇驾驶一架双旋翼直升机在柏林体育场进行了一次完美的飞行表演。这架直升机被直升机界认为是世界上第一种试飞成功的直升机。1936年，德国福克公司在对早期直升机进行多方面改进之后，公开展示了自己制造的FW-61直升机，1年后该机创造了多项世界纪录。[3]1939年春，美国的伊戈尔·伊万诺维奇·西科尔斯基完成了VS-300直升机的全部设计工作，同年夏天制造出一架原型机。这种单旋翼带尾桨直升机构型成为现在最常见的直升机构型。20世纪40年代，美国沃特-西科斯基公司研制的一种2座轻型直升机R-4，它是世界上第一种投入批量生产的直升机，也是美国陆军航空兵、海军、海岸警卫队和英国空军、海军使用的第一种军用直升机。该机的公司编号为VS-316，VS-316A。美国陆军航空兵的编号为R-4，美国海军和海岸防卫队的编号为HNS-1，英国空军将其命名为“食蚜虻1”（Hoverfly 1），英国海军将其命名为“牛虻”（Gadfly）。到30年代末期，在法国、德国、美国和前苏联都有直升机试飞成功，并迅速改进达到了能够实用的程度。第二次世界大战的军事需要，加速了这一进程，促使直升机发展由探索期进入实用期，直升机开始投入生产线生产。到二战结束时，德国工厂已生产了30多架直升机，美国交付的R5、R6直升机已达400多架。[4]20世纪的后半期直升机进入航空实用期，特别是越战期间大量直升机部属到战场，战后直升机的应用领域不断扩展，数量迅速增加。每年八月第三个星期日被列为世界直升机日。单旋翼直升机（monocopter或unicopter）是直升机的主要类型，使用单一的主旋翼（main rotor）产生升力，但因为角动量守恒的原因，必须配有一个反扭矩机制去抵消主旋翼旋转造成的机体反向旋转。有尾桨例子：西科斯基UH-60涵道式尾桨例子：欧直EC-135无尾桨例子：麦道MD520N双旋翼直升机（bicopter）使用两个旋翼合作产生升力，可以用方向相反的旋转互相抵消反扭矩，因此不需要在尾部安装垂直旋桨。纵列式代表：波音CH-47D横列式代表：米里Mi-12倾转式代表：贝尔-波音V-22共轴式代表：卡莫夫Ka-27交错式代表：H-43卡曼公司双旋翼交叉式直升机K-600多旋翼直升机（multicopter）使用三个以上的旋翼来产生升力，是民用无人航空载具的主流类型。最常见的设计是四旋翼直升机（quadcopter），有四个大小相同、分布位置接近对称的旋翼来达到悬停、维持姿态及平飞。小型四旋翼飞行器大疆悟2无人机大疆御Air 2无人机六旋翼无人机直升机的起落架分为滑橇式和轮式两种，轮式又分可收放和不可收放式。滑橇式一般用于轻型直升机；轮式多用在中型、重型直升机。[5][6]直升机的操纵系统有别于固定翼航空器，通常由以下部分组成：单旋翼带尾桨直升机的操纵系统说明表直升机依照用途可分为民用与军用两种。作为民间工作，没有武装且仅有该用途所需的装备的直升机即为民用直升机。依其用途目前主要可分为下列几种：增加装甲和武器，同时加强性能以供军事用途的直升机便为军用直升机。依其用途目前主要可分为下列五种：', 'attributes': {'直升机': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Russian_Air_Force_Kamov_Ka-50.jpg/220px-Russian_Air_Force_Kamov_Ka-50.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Rotor_Antitorque_System.svg/220px-Rotor_Antitorque_System.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Helicopter_rescue_sancy_takeoff.jpg/220px-Helicopter_rescue_sancy_takeoff.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Mil_Mi-6%2C_54RED%2C_Russian_Air_Force.jpg/220px-Mil_Mi-6%2C_54RED%2C_Russian_Air_Force.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/F-WWPB_%288970712548%29.jpg/240px-F-WWPB_%288970712548%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Hatzerim_270613_Apache.jpg/220px-Hatzerim_270613_Apache.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/LAPD_Bell_206_Jetranger.jpg/300px-LAPD_Bell_206_Jetranger.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Antitorque.jpg/303px-Antitorque.jpg'], '航空器专题': ';;;航空器专题;;;单纯利用空气浮力（浮空器）;;;无动力;;动力;;;;气球;;;飞艇;;;空气浮力和空气动力混合;;;无动力;;动力;;;;混合系留气球;风筝式系留气球;;;混合飞艇;;;单纯利用空气动力;;;无动力;;动力;;;无动力固定翼;;动力固定翼;;;;滑翔机;悬挂式滑翔机;滑翔伞;风筝;;;飞机;动力滑翔伞;滚筒飞行器;地效飞行器;;;;;半固定翼和旋翼;;;;;;倾转旋翼机;环翼机;;;无动力旋翼;;动力旋翼;;;;旋翼风筝;;;自转旋翼机;旋翼式螺旋桨飞机;直升机;;;;;扑翼;;;;;;扑翼机;;;其他;;;无动力;;动力;;;;;;飞行实验器;飞行汽车;飞天车;;'}}} (scraper.py:257)
[2022-03-10 01:51:26] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E6%B5%B7%E8%BB%8D%E6%B5%B7%E6%B4%8B%E7%9B%A3%E5%81%B5%E6%8C%87%E6%8F%AE%E9%83%A8> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1) (engine.py:250)
[2022-03-10 01:51:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4>
{'keyword': '花莲机场', 'source': 'wiki', 'title': '花莲机场', 'url': 'https://zh.wikipedia.org/wiki/%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4', 'date': ' ', 'content': '花莲机场（阿美语：Pahikukiyan nu Kalinku，太鲁阁语：Rduwan Msangay Asu Skiya Skangki，IATA代码：HUN；ICAO代码：RCYU）是位于台湾花莲县新城乡的机场，场区位在花莲市中心北方，横亘整个新城乡最南部。该机场为一军民合用机场（英语：Civil enclave），也是东台湾第一座国际机场，主要由中华民国空军管理，分为山侧的空军佳山基地、以及海侧的空军花莲基地；民用部分位于海侧，称为花莲航空站，由交通部民用航空局经营。由于本场为军民合用，机场内有大量军事设施，故禁止于起降时对机场内摄影。花莲机场的前身是日治时期的“花莲港北飞行场”，兴建于1936年，属于军民共用的机场，由日本航空运输（日语：日本航空輸送）经营。第二次世界大战结束后，由中华民国政府接收。※视评估扩充5~7号登机门及空桥，扩建工程第一期第一阶段并无建设。国内航线由立荣航空及华信航空营运台北松山、台中及高雄共3条航线，主要以ATR72-600机型执飞。国际航线由韩国低成本航空公司易斯达航空营运韩国首尔仁川、釜山共2条包机航线，主要以B737-800机型执飞，目前因2019冠状病毒病关系停航。', 'attributes': {'花莲机场': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Hualien_Air_Force_Base_entrance_20120210.jpg/220px-Hualien_Air_Force_Base_entrance_20120210.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/%E5%8D%B3%E5%B0%87%E9%99%8D%E8%90%BD%E6%96%BC%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4%E7%9A%84%E8%8F%AF%E4%BF%A1%E8%88%AA%E7%A9%BA%28%E6%94%9D%E6%96%BC%E8%8A%B1%E8%93%AE%E5%B8%82%E5%9C%8B%E5%BC%B7%E9%87%8C%29.jpg/220px-%E5%8D%B3%E5%B0%87%E9%99%8D%E8%90%BD%E6%96%BC%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4%E7%9A%84%E8%8F%AF%E4%BF%A1%E8%88%AA%E7%A9%BA%28%E6%94%9D%E6%96%BC%E8%8A%B1%E8%93%AE%E5%B8%82%E5%9C%8B%E5%BC%B7%E9%87%8C%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Road_signs_in_Hualien_Airport.jpg/220px-Road_signs_in_Hualien_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%BA%94%E6%88%B0%E8%A1%93%E6%B7%B7%E5%90%88%E8%81%AF%E9%9A%8A.png/80px-%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%BA%94%E6%88%B0%E8%A1%93%E6%B7%B7%E5%90%88%E8%81%AF%E9%9A%8A.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/HuaLien_Airport.jpg/280px-HuaLien_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Taiwan_location_map.svg/250px-Taiwan_location_map.svg.png'], '机场类型': '军民合用', '所有者': '交通部民用航空局国防部空军司令部', '营运者': '军用： 中华民国空军民用： 交通部民用航空局', '服务城市': '花莲市', '地理位置': '中华民国（台湾）花莲县新城乡嘉里村机场一号', '启用日期': '1962年5月16日(1962-05-16)', '海拔高度': '51英尺（16米）', '坐标': '24°01′24″N 121°36′36″E\ufeff / \ufeff24.02333°N 121.61000°E\ufeff / 24.02333; 121.61000坐标：24°01′24″N 121°36′36″E\ufeff / \ufeff24.02333°N 121.61000°E\ufeff / 24.02333; 121.61000', '网址': 'www.hulairport.gov.tw', '方向': ';;;方向;;长度;;表面;;;米;;英尺;;;03/21;;2,751;;9,026;;混凝土;;', '客运量': '客运量214,279人次货运量402.2公吨起降架次4,799次', '国家（地区）': '中华民国（台湾）', '位置': '花莲县', '类型': '航空安检站', '出入境管理机关': '内政部移民署国境事务大队基隆港国境事务队', '海关': '财政部关务署基隆关', '繁体字': ' 花蓮機場 ', '简化字': ' 花莲机场 ', '标音': "标音官话-汉语拼音 Huā lián  Jī chǎng -威妥玛拼音 hua lien2 chi ch'ang3 -耶鲁拼音 Hwā lyán Jī chǎng -注音符号ㄏㄨㄚ ㄌㄧㄢˊ ㄐㄧ ㄔㄤˇ闽语-闽南语白话字 Hoa-liân Ki-tiûⁿ -台罗拼音 Hua-liân Ki-tiûnn 客家话-客家话拼音 Fa1 lian2  Gi1 cong2 -客语白话字 Fâ-lièn Kî-chhòng "}}} (scraper.py:257)
[2022-03-10 01:51:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/SdKfz_252%E5%8D%8A%E5%B1%A5%E5%B8%A6%E8%BD%A6>
{'keyword': '装甲运输车', 'source': 'wiki', 'title': 'SdKfz 252半履带车', 'url': 'https://zh.wikipedia.org/wiki/SdKfz_252%E5%8D%8A%E5%B1%A5%E5%B8%A6%E8%BD%A6', 'date': ' ', 'content': '第252号特种车辆（德语：Sonderkraftfahrzeug 252，简称：Sd.Kfz. 252），又称轻型装甲弹药运输车（leichter gepanzerter Munitionskraftwagen），是纳粹德国在二战期间使用的一款轻型半履带装甲运输车。Sd.Kfz. 252的设计基于Sd.Kfz. 250半履带车，并使用同款底盘。1940年6月至12月由德马格（英语：Demag）和韦格曼（英语：Krauss-Maffei Wegmann）负责生产。1941年1月至9月则由德意志造船厂负责生产，一共制造了413辆[1]。主要用途是为突击炮部队运输弹药，在东西线皆有使用。为了增加弹药运载能力，使用Sd.Ah. 32/1（Sonder-Anhänger 32/1） 拖车，可以额外运载36枚75毫米炮弹[2]。法国战役期间，第640和659突击炮连使用了Sd.Kfz. 252。在东线，使用者为第184、190和210突击炮营[3]。1941年之后停止生产，被Sd.Kfz. 250/6半履带车取代[4]。', 'attributes': {'SdKfz 252半履带车': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Bundesarchiv_Bild_101I-154-1968-16%2C_Russland%2C_Sch%C3%BCtzenpanzer_im_Gel%C3%A4nde.jpg/181px-Bundesarchiv_Bild_101I-154-1968-16%2C_Russland%2C_Sch%C3%BCtzenpanzer_im_Gel%C3%A4nde.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Balkenkreuz.svg/30px-Balkenkreuz.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/Sd.Kfz._252_01.png/300px-Sd.Kfz._252_01.png'], '类型': '轻型半履带装甲弹药运输车', '原产地': '纳粹德国', '服役期间': '1940年-？', '参与战争／冲突': '二战', '研发者': '德马格（英语：Demag）', '生产商': '德马格（英语：Demag）、韦格曼（英语：Krauss-Maffei Wegmann）、德意志造船厂', '生产日期': '1940年6月至12月（德马格、韦格曼)，1941年1月至9月（德意志造船厂）', '制造数量': '413', '重量': '5.73吨', '长度': '4.7米', '宽度': '1.95米', '高度': '1.8米', '操作人数': '2', '发动机': '迈巴赫HL42 TRKM 6缸水冷引擎', '作战范围': '320公里 公路175公里 越野', '速度': '65公里/小时'}}} (scraper.py:257)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:51:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1532,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 64369,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 4.263449,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 51, 26, 859917),
 'httpcompression/response_bytes': 250471,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 39,
 'log_count/INFO': 61,
 'memusage/max': 67362816,
 'memusage/startup': 67362816,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 51, 22, 596468)} (statscollectors.py:47)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:51:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E6%B5%B7%E8%BB%8D%E6%B5%B7%E6%B4%8B%E7%9B%A3%E5%81%B5%E6%8C%87%E6%8F%AE%E9%83%A8>
{'keyword': '西屿雷达站', 'source': 'wiki', 'title': '中华民国海军海洋监侦指挥部', 'url': 'https://zh.wikipedia.org/wiki/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E6%B5%B7%E8%BB%8D%E6%B5%B7%E6%B4%8B%E7%9B%A3%E5%81%B5%E6%8C%87%E6%8F%AE%E9%83%A8', 'date': ' ', 'content': '海军海洋监侦指挥部为中华民国海军岸置地对海雷达部队。', 'attributes': {'中华民国海军海洋监侦指挥部': {'存在时期': '1965年至今', '国家或地区': '中华民国', '效忠于': '中华民国', '军种': ' 中华民国海军', '种类': '雷达部队', '规模': '指挥部', '隶属于': '海军舰队指挥部', '装备': '机动雷达车、维星车、电战车、机动诱标车', '别称': '海侦部', 'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/ROCN_Rear_Admiral%27s_Flag.svg/25px-ROCN_Rear_Admiral%27s_Flag.svg.png']}}} (scraper.py:257)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:51:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1568,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 51650,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 4.391215,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 51, 26, 980560),
 'httpcompression/response_bytes': 226328,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 40,
 'log_count/INFO': 71,
 'memusage/max': 67096576,
 'memusage/startup': 67096576,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 51, 22, 589345)} (statscollectors.py:47)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:51:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1604,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 38653,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 4.356575,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 51, 26, 982270),
 'httpcompression/response_bytes': 140641,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 40,
 'log_count/INFO': 46,
 'memusage/max': 67706880,
 'memusage/startup': 67706880,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 51, 22, 625695)} (statscollectors.py:47)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:51:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1676,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 44119,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 4.412411,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 51, 26, 989681),
 'httpcompression/response_bytes': 179735,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 40,
 'log_count/INFO': 84,
 'memusage/max': 66859008,
 'memusage/startup': 66859008,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 51, 22, 577270)} (statscollectors.py:47)
[2022-03-10 01:51:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:51:43] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (failed 1 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:52:04] [   DEBUG] [scrapy.downloadermiddlewares.retry ] - Retrying <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (failed 2 times): Connection was refused by other side: 111: Connection refused. (retry.py:99)
[2022-03-10 01:52:22] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:52:25] [   ERROR] [scrapy.downloadermiddlewares.retry ] - Gave up retrying <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (failed 3 times): Connection was refused by other side: 111: Connection refused. (retry.py:122)
[2022-03-10 01:52:25] [   ERROR] [scrapy.core.scraper ] - Error downloading <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (scraper.py:219)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
[2022-03-10 01:52:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:52:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1420,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'elapsed_time_seconds': 63.525353,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 52, 26, 74009),
 'log_count/DEBUG': 42,
 'log_count/ERROR': 2,
 'log_count/INFO': 110,
 'memusage/max': 101003264,
 'memusage/startup': 66252800,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 51, 22, 548656)} (statscollectors.py:47)
[2022-03-10 01:52:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:52:26] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.010489 (DataCleaning.py:41)
[2022-03-10 01:52:26] [    INFO] [  __main__ ] - 上传文件：/code/./result/wiki/wiki_澎湖机场_澎湖机场_20220310015126077047.json (MultisiteSchedule.py:276)
[2022-03-10 01:52:26] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:291)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 277, in upload_crawl_file
    connect.upload_file(file, "/text_crawl_file/")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 01:52:26] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:395)
[2022-03-10 01:52:26] [    INFO] [  __main__ ] - upload crawl file success (MultisiteSchedule.py:398)
[2022-03-10 01:52:26] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 01:55:07] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:55:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_11.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_11.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_11.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 340
    if(type({}) = type(item['attributes']['img_url'])):
                ^
SyntaxError: invalid syntax
[2022-03-10 01:55:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_11.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 340
    if(type({}) = type(item['attributes']['img_url'])):
                ^
SyntaxError: invalid syntax
[2022-03-10 01:55:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_11.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_11.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 340
    if(type({}) = type(item['attributes']['img_url'])):
                ^
SyntaxError: invalid syntax
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 340
    if(type({}) = type(item['attributes']['img_url'])):
                ^
SyntaxError: invalid syntax
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 340
    if(type({}) = type(item['attributes']['img_url'])):
                ^
SyntaxError: invalid syntax
[2022-03-10 01:55:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_11.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 340
    if(type({}) = type(item['attributes']['img_url'])):
                ^
SyntaxError: invalid syntax
[2022-03-10 01:55:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_11.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_11.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 340
    if(type({}) = type(item['attributes']['img_url'])):
                ^
SyntaxError: invalid syntax
[2022-03-10 01:55:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_11.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 01:55:07] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 340
    if(type({}) = type(item['attributes']['img_url'])):
                ^
SyntaxError: invalid syntax
[2022-03-10 01:55:07] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_11.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:07] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:37] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 01:55:37] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 340
    if(type({}) = type(item['attributes']['img_url'])):
                ^
SyntaxError: invalid syntax
[2022-03-10 01:55:37] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.005326 (DataCleaning.py:41)
[2022-03-10 01:55:37] [    INFO] [  __main__ ] - 上传文件：/code/./result/wiki/wiki_澎湖机场_澎湖机场_20220310015126077047.json (MultisiteSchedule.py:276)
[2022-03-10 01:55:37] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:291)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 277, in upload_crawl_file
    connect.upload_file(file, "/text_crawl_file/")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 01:55:37] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:395)
[2022-03-10 01:55:37] [    INFO] [  __main__ ] - upload crawl file success (MultisiteSchedule.py:398)
[2022-03-10 01:55:37] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 01:55:46] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 01:55:46] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_12.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:55:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_12.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:55:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_12.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:55:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_12.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:55:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_12.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:55:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_12.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:55:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_12.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:55:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_12.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:55:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_12.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:55:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_12.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:55:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_12.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 01:55:47] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 01:55:47] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 01:55:47] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (redirect.py:42)
[2022-03-10 01:55:47] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 01:55:47] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 01:55:47] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 01:55:47] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 01:55:47] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 01:55:47] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 01:55:47] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 01:55:47] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 01:55:47] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 01:55:48] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:55:48] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:55:48] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:55:48] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:55:48] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Scorched_earth> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 01:55:48] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:55:48] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/SdKfz_252%E5%8D%8A%E5%B1%A5%E5%B8%A6%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 01:55:48] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E7%9B%B4%E5%8D%87%E6%A9%9F> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 01:55:48] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Scorched_earth>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Scorched earth', 'url': 'https://en.wikipedia.org/wiki/Scorched_earth', 'date': 202203092202, 'content': "CategoriesA scorched-earth policy is a military strategy that aims to destroy anything that might be useful to the enemy. Any assets that could be used by the enemy may be targeted, which usually includes obvious weapons, transport vehicles, communication sites, and industrial resources. However, anything useful to the advancing enemy may be targeted, including food stores and agricultural areas, water sources, and even the local people themselves, though the last has been banned under the 1977 Geneva Conventions.[a]The practice can be carried out by the military in enemy territory or in its own home territory while it is being invaded. It may overlap with, but is not the same as, punitive destruction of the enemy's resources, which is usually done as part of political strategy, rather than operational strategy.Notable historic examples of scorched-earth tactics include William Tecumseh Sherman's March to the Sea in the American Civil War, Kit Carson's subjugation of the American Navajo Indians, Lord Kitchener's advance against the Boers, and the setting on fire of 605 to 732 oil wells by retreating Iraqi military forces during the Gulf War. Also notable were the Russian army's strategies during the failed Swedish invasion of Russia, the failed Napoleonic invasion of Russia, the initial Soviet retreat commanded by Joseph Stalin during the German Army's invasion during the Second World War,[2] and Nazi Germany's retreat on the Eastern Front.The concept of scorched-earth defense is sometimes applied figuratively to the business world in which a firm facing a takeover attempts to make itself less valuable by selling off its assets.[3]The Scythians used scorched-earth methods against the Persian Achaemenid Empire, led by King Darius the Great, during his European Scythian campaign. The Scythians, who were nomadic herders, evaded the Persian invaders and retreated into the depths of the steppes after they had destroyed food supplies and poisoned wells.The Greek general Xenophon recorded in his Anabasis that the Armenians, as they withdrew, burned their crops and food supplies before the Ten Thousand could advance.[citation needed]The Greek mercenary general Memnon of Rhodes unsuccessfully suggested to the Persian satraps to use a scorched-earth policy against Alexander the Great, who was moving into Asia Minor.The system of punitive destruction of property and subjugation of people when accompanying a military campaign was known as vastatio. Two of the first uses of scorched earth recorded both happened in the Gallic Wars. The first was used when the Celtic Helvetii were forced to evacuate their homes in Southern Germany and Switzerland because of incursions of unfriendly Germanic tribes: to add incentive to the march, the Helvetii destroyed everything they could not bring.[4] After the Helvetii were defeated by combined Roman and Gallic forces, the Helvetii were forced to rebuild themselves on the plains they themselves had destroyed.The second case shows actual military value: during the Great Gallic War the Gauls under Vercingetorix planned to lure the Roman armies into Gaul and then trap and obliterate them. They thus ravaged the countryside of what are now the Benelux countries and France. That caused immense problems for the Romans, but the Roman military triumphs over the Gallic alliance showed that alone not to be enough to save Gaul from subjugation by Rome.During the Second Punic War in 218–202 BCE, the Carthaginians used the method selectively while storming through Italy.[5] After the end of the Third Punic War in 146 BCE, the Roman Senate also elected to use this method to permanently destroy the Carthaginian capital city, Carthage (near modern-day Tunis). The buildings were torn down, their stones scattered so not even rubble remained, and the fields were burned. However, the story that they salted the earth is apocryphal.[6]In the year CE 363, the Emperor Julian's invasion of Persia was turned back by a scorched-earth policy:The extensive region that lies between the River Tigris and the mountains of Media\xa0...was in a very improved state of cultivation. Julian might expect, that a conqueror, who possessed the two forcible instruments of persuasion, steel and gold, would easily procure a plentiful subsistence from the fears or avarice of the natives. But, on the approach of the Romans, the rich and smiling prospect was instantly blasted. Wherever they moved\xa0... the cattle was driven away; the grass and ripe corn were consumed with fire; and, as soon as the flames had subsided which interrupted the march of Julian, he beheld the melancholy face of a smoking and naked desert. This desperate but effectual method of defence can only be executed by the enthusiasm of a people who prefer their independence to their property; or by the rigor of an arbitrary government, which consults the public safety without submitting to their inclinations the liberty of choice.[7]The British monk Gildas wrote in his 6th-century treatise 'On the Ruin of Britain' on an earlier invasion: 'For the fire of vengeance\xa0...\u200aspread from sea to sea\xa0...\u200aand did not cease, until, destroying the neighbouring towns and lands, it reached the other side of the island'.[8]During the First Fitna (656–661), Muawiyah I sent Busr ibn Abi Artat to a campaign in the Hejaz and Yemen to ravage territory loyal to Muawiyah's opponent Ali ibn Abi Talib. According to Tabari, 30,000 civilians are estimated to have been killed during that campaign of the civil war. Muawiyah also sent Sufyan ibn Awf to Iraq to burn the crops and homes of Ali's supporters.[9]During the great Viking invasion of England that was opposed by Alfred the Great and various other Saxon and Welsh rulers, the Viking chieftain Hastein marched his men to Chester in late summer 893 to occupy the ruined Roman fortress there. The refortified fortress would have made an excellent base for raiding northern Mercia, but the Mercians are recorded as having taken the drastic measure of destroying all crops and livestock in the surrounding countryside to starve the Vikings out.[10][self-published source?] They left Chester next year and marched into Wales.In the Harrying of the North, William the Conqueror's solution to stop a rebellion in 1069 was the brutal conquest and subjugation of northern England. William's men burnt whole villages from the Humber to Tees and slaughtered the inhabitants. Food stores and livestock were destroyed so that anyone surviving the initial massacre would soon succumb to starvation over the winter. The destruction is depicted in the Bayeux Tapestry.[11] The survivors were reduced to cannibalism,[12] with one report stating that the skulls of the dead were cracked open so that their brains could be eaten. Between 100,000 and 150,000 perished, and the area took centuries to recover from the damage.During 1019 and 1022\xa0AD the Chandela Kingdom was attacked by Mahmud of Ghazni. The Chandellas adopted a scorched earth policy. Mahmud, afraid of penetrating too far into the interior, had each time to retreat without much gain and ultimately established a friendly relationship with the Chandellas.[citation needed]During the Hundred Years' War, both the English and the French conducted chevauchée raids over the enemy territory to damage its infrastructure.Robert the Bruce counselled using those methods to hold off the forces of Edward I of England, who were Scotland, according to an anonymous 14th-century poem:[13]in strait places gar keep all store,And byrnen ye plainland them before,That they shall pass away in haistWhat that they find na thing but waist....\xa0This is the counsel and intentOf gud King Robert's testiment.In 1336, the defenders of Pilėnai, Lithuania, set their castle on fire and committed mass suicide to make the attacking Teutonic Order have only a Pyrrhic victory.The strategy was widely used in Wallachia and Moldavia, now mostly in Romania and Moldova. Prince Mircea I of Wallachia used it against the Ottoman Empire in 1395, and Prince Stephen III of Moldavia did the same as the Ottoman Army advanced in 1475 and 1476.A slighting is the deliberate destruction, whether partial or complete, of a fortification without opposition. Sometimes, such as during the Wars of Scottish Independence and the English Civil War, it was done to render the structure unusable as a fortress.[14][15][16] In England, adulterine (unauthorised) castles would usually be slighted if captured by a king.[17] During the Wars of Scottish Independence, Robert the Bruce adopted a strategy of slighting Scottish castles to prevent them being occupied by the invading English.[16][18] A strategy of slighting castles in Palestine was also adopted by the Mamelukes during their wars with the Crusaders.Further use of scorched-earth policies in a war was seen during the 16th century in Ireland, where it was used by English commanders such as Walter Devereux and Richard Bingham.The Desmond Rebellions were a famous case in Ireland. Much of the province of Munster was laid waste. The poet Edmund Spenser left an account of it:In those late wars in Munster; for notwithstanding that the same was a most rich and plentiful country, full of corn and cattle, that you would have thought they could have been able to stand long, yet ere one year and a half they were brought to such wretchedness, as that any stony heart would have rued the same. Out of every corner of the wood and glens they came creeping forth upon their hands, for their legs could not bear them; they looked Anatomies [of] death, they spoke like ghosts, crying out of their graves; they did eat of the carrions, happy where they could find them, yea, and one another soon after, in so much as the very carcasses they spared not to scrape out of their graves; and if they found a plot of water-cresses or shamrocks, there they flocked as to a feast for the time, yet not able long to continue therewithal; that in a short space there were none almost left, and a most populous and plentiful country suddenly left void of man or beast.In 1630, Field-Marshal General Torquato Conti was in command of the Holy Roman Empire's forces during the Thirty Years' War. Forced to retreat from the advancing Swedish army of King Gustavus Adolphus, Conti ordered his troops to burn houses, destroy villages and cause as much harm generally to property and people as possible. His actions were remembered thus:[19]To revenge himself upon the Duke of Pomerania, the imperial general permitted his troops, upon his retreat, to exercise every barbarity on the unfortunate inhabitants of Pomerania, who had already suffered but too severely from his avarice. On pretence of cutting off the resources of the Swedes, the whole country was laid waste and plundered; and often, when the Imperialists were unable any longer to maintain a place, it was laid in ashes, in order to leave the enemy nothing but ruins.During the Great Northern War, Russian Emperor Peter the Great's forces used scorched-earth tactics to hold back Swedish King Charles XII's campaign towards Moscow.In 1462, a massive Ottoman army, led by Sultan Mehmed II, marched into Wallachia. Vlad the Impaler retreated to Transylvania. During his departure, he conducted scorched-earth tactics to ward off Mehmed's approach. When the Ottoman forces approached Tirgoviste, they encountered over 20,000 people impaled by the forces of Vlad the Impaler, creating a 'forest' of dead or dying bodies on stakes. The atrocious, gut-wrenching sight caused Mehmed to withdraw from battle and to send instead Radu, Vlad's brother, to fight Vlad the Impaler.In early 1565, Grandmaster Jean Parisot de Valette ordered the harvesting of all the crops in Malta, including unripened grain, to deprive the Ottomans of any local food supplies since spies had warned of an imminent Ottoman attack. Furthermore, the Knights poisoned all of the wells with bitter herbs and dead animals. The Ottomans arrived on 18 May, and the Great Siege of Malta began. The Ottomans managed to capture one fort but were eventually defeated by the Knights, the Maltese militia and a Spanish relief force.In 1688, France attacked the German Electoral Palatinate. The German states responded by forming an alliance and assembling a sizeable armed force to push the French out of Germany. The French had not prepared for such an eventuality. Realising that the war in Germany was not going to end quickly and that the war would not be a brief and decisive parade of French glory, Louis XIV and War Minister Marquis de Louvois resolved upon a scorched-earth policy in the Palatinate, Baden and Württemberg. The French were intent on denying enemy troops local resources and on preventing the Germans from invading France.[20] By 20 December 1688, Louvois had selected all the cities, towns, villages and châteaux intended for destruction. On 2 March 1689, the Count of Tessé torched Heidelberg, and on 8 March, Montclar levelled Mannheim. Oppenheim and Worms were finally destroyed on 31 May, followed by Speyer on 1 June, and Bingen on 4 June. In all, French troops burnt over 20 substantial towns as well as numerous villages.[21]In the Maratha Empire, Shivaji Maharaj had introduced scorched-earth tactics, known as Ganimi Kava.[22] His forces looted traders and businessmen from Aurangzeb's Mughal Empire and burnt down his cities, but they were strictly ordered not to rape or hurt the innocent civilians and not to cause any sort of disrespect to any of the religious institutes.[23]Shivaji's son, Sambhaji Maharaj, was detested throughout the Mughal Empire for his scorched-earth tactics until he and his men were captured by Muqarrab Khan and his Mughal Army contingent of 25,000.[24] On 11 March 1689, a panel of Mughal qadis indicted and sentenced Sambhaji to death on accusations of casual torture, arson, looting, and massacres but most prominently for giving shelter to Sultan Muhammad Akbar, the fourth son of Aurangzeb, who sought Sambhaji's aid in winning the Mughal throne from the emperor, his father. Sambhaji was particularly condemned for the three days of ravaging committed after the Battle of Burhanpur.[25]During the third Napoleonic invasion of Portugal in 1810, the Portuguese population retreated towards Lisbon and was ordered to destroy all the food supplies the French might capture as well as forage and shelter in a wide belt across the country. (Although effective food-preserving techniques had recently been invented, they were still not fit for military use because a suitably-rugged container had not yet been invented.)[26] The command was obeyed as a result of French plundering and general ill-treatment of civilians in the previous invasions. The poor angry people would rather destroy anything that had to be left behind, rather than leave it to the French.After the Battle of Bussaco, André Masséna's army marched on to Coimbra, where much of the city's old university and library were vandalised. Houses and furniture were destroyed, and the few civilians who did not seek refuge farther south were murdered. While there were instances of similar behavior by British soldiers, since Portugal was their ally, such crimes were generally investigated and those found punished. Coimbra's sack made the populace even more determined to leave nothing, and when the French armies reached the Lines of Torres Vedras on the way to Lisbon, French soldiers reported that the country 'seemed to empty ahead of them'. When Massená reached the city of Viseu, he wanted to replenish his armies' dwindling food supplies, but none of the inhabitants remained, and all there was to eat were grapes and lemons that if eaten in large quantities would be better laxatives than sources of calories. Low morale, hunger, disease and indiscipline greatly weakened the French army and compelled the forces to retreat the next spring. That method was later recommended to Russia when Napoleon made his move.In 1812, Emperor Alexander I was able to render Napoleon's invasion of Russia useless by using a scorched-earth retreat policy, similar to that of Portugal.[27] As Russians withdrew from the advancing French army, they burned the countryside (and allegedly Moscow[28]) over which they passed, leaving nothing of value for the pursuing French army. Encountering only desolate and useless land Napoleon's Grande Armée was prevented from using its usual doctrine of living off the lands that it conquered. Pushing relentlessly on despite dwindling numbers, the Grand Army met with disaster as the invasion progressed. Napoleon's army arrived in a virtually-abandoned Moscow, which was a tattered starving shell of its former self, largely because of scorched-earth tactics by the retreating Russians. Having conquered essentially nothing, Napoleon's troops retreated, but the scorched-earth policy came into effect again because even though some large supply dumps had been established on the advance, the route between them had both been scorched and marched over once already. Thus, the French army starved as it marched along the resource-depleted invasion route.[29]In August 1812, Argentine General Manuel Belgrano led the Jujuy Exodus, a massive forced displacement of people from what is now Jujuy and Salta Provinces to the south. The Jujuy Exodus was conducted by the patriot forces of the Army of the North, which was battling a Royalist army.Belgrano, faced with the prospect of total defeat and territorial loss, ordered all people to pack their necessities, including food and furniture, and to follow him in carriages or on foot together with whatever cattle and beasts of burden that could endure the journey. The rest (houses, crops, food stocks and any objects made of iron) was to be burned to deprive the Royalists of resources. The strict scorched-earth policy made him ask on 29 July 1812 the people of Jujuy to 'show their heroism' and to join the march of the army under his command 'if, as you assure, you want to be free'. The punishment for ignoring the order was execution, with destruction of the defector's properties. Belgrano labored to win the support of the populace and later reported that most of the people had willingly followed him without the need of force.The exodus started on 23 August and gathered people from Jujuy and Salta. People travelled south about 250\xa0km and finally arrived at the banks of the Pasaje River, in Tucumán Province in the early hours of 29 August. They applied a scorched-earth policy and so the Spaniards advanced into a wasteland. Belgrano's army destroyed everything that could provide shelter or be useful to the Royalists.[30]In 1827, Ibrahim Pasha of Egypt led an Ottoman-Egyptian combined force in a campaign to crush Greek revolutionaries in the Peloponnese. In response to Greek guerrilla attacks on his forces in the Peloponnese, Ibrahim launched a scorched earth campaign which threatened the population with starvation and deported many civilians into slavery in Egypt. He also allegedly planned to bring in Arab settlers to replace the Greek population. The fires of burning villages and fields were clearly visible from Allied ships standing offshore. A British landing party reported that the population of Messinia was close to mass starvation.[31] Ibrahim's scorched-earth policy caused much outrage in Europe, which was one factor for the Great Powers (United Kingdom, the Kingdom of France and the Russian Empire) decisively intervening against him in the Battle of Navarino.The Philippine–American War often included scorched-earth campaigns in the countryside. Entire villages were burned and destroyed, with torture (water cure) and the concentration of civilians into 'protected zones.' Many civilian casualties were caused by disease and famine.[32][33]In the hunt for guerrilla leader Emilio Aguinaldo, American troops also poisoned water wells to try to force out the Filipino rebels.[34]In the American Civil War, Union forces under Philip Sheridan and William Tecumseh Sherman used the policy widely.[35] General Sherman used that policy during his March to the Sea.Sherman's tactics were an attempt to destroy the enemy's will and logistics through burning or destroying crops or other resources that might be used for the Confederate force. Later generations of American war leaders would use similar total war tactics in World War II, the Korean War, the Vietnam War, the Iraq war, and the Afghanistan War, largely through the use of air power.[36] During Sherman's campaign, his 'men piled all deed books in front of the courthouse and burned them. The logic was that the big plantations would not be able to prove land ownership. These actions are the bane of Georgia and South Carolina genealogists.”[37]Another event, in response to William Quantrill's raid on Lawrence, Kansas and the many civilian casualties, including the killing of 180 men, Brigadier General Thomas Ewing Jr., Sherman's brother-in-law, issued US Army General Order No. 11 (1863) to order the near-total evacuation of three-and-a-half counties in western Missouri, south of Kansas City, which were subsequently looted and burned by US Army troops.[38] Under Sherman's overall direction, General Philip Sheridan followed that policy in the Shenandoah Valley of Virginia and then in the Indian Wars of the Great Plains.When General Ulysses Grant's forces broke through the defenses of Richmond, Virginia, Confederate President Jefferson Davis ordered the destruction of Richmond's militarily-significant supplies. The resulting conflagration destroyed many buildings, most of which were commercial, as well as Confederate warships docked on the James River. Civilians in panic were forced to escape the fires that had been started.During the wars with Native American tribes of the American West, Kit Carson, under James Henry Carleton's direction, instituted a scorched-earth policy, burning Navajo fields and homes and stealing or killing their livestock. He was aided by other Indian tribes with long-standing enmity toward the Navajos, chiefly the Ute tribe. The Navajo were forced to surrender because of the destruction of their livestock and food supplies. In the spring of 1864, 8000 Navajo men, women, and children were forced to march 300 miles to Fort Sumner, New Mexico. Navajos call it 'The Long Walk.' Many died along the way or during their four years of internment.A military expedition, led by Colonel Ranald S. Mackenzie, was sent to the Texas Panhandle and the Oklahoma Territory Panhandle in 1874 to remove the Indians to reservations in Oklahoma. The Mackenzie expedition captured about 1,200 of the Indians' horses, drove them into Tule Canyon, and shot all of them. Denied their main source of livelihood and demoralized, the Comanche and the Kiowa abandoned the area (see Palo Duro Canyon).Lord Kitchener applied a scorched-earth policy towards the end of the Second Boer War (1899–1902). Numerous Boers, refusing to accept military defeat, adopted guerrilla warfare despite the capture of both of their capital cities. As a result, the British Army under Lord Kitchener's command initiated a policy of the destruction of the farms and the homes of civilians to prevent the Boers who were still fighting from obtaining food and supplies.[39] The policies left Boer women and children without means to survive since crops and livestock had also been destroyed.[40]The existence of the concentration camps was exposed by Emily Hobhouse, who toured the camps and began petitioning the British government to change its policy.[41][42] In an attempt to counter Hobhouse's activism, the British government commissioned the Fawcett Commission, but it confirmed Hobhouse's findings.[43] The British government later perceived the concentration camps as a humanitarian measure, to care for displaced persons until the war was ended, in response to both reports. Negligence by the British, lack of planning and supplies, and overcrowding led to much loss of life.[44] A decade after the war, P.L.A. Goldman officially determined that 27,927 Boers died in the concentration camps, 26,251 women and children (of whom more than 22,000 were under the age of 16) and 1676 men over the age of 16, with 1421 being aged persons.[45]In 1868, the Tūhoe, who had sheltered the Māori leader Te Kooti, were thus subjected to a scorched-earth policy in which their crops and buildings were destroyed and the people of fighting age were captured.On the Eastern Front of World War I, the Imperial Russian Army created a zone of destruction by using a massive scorched-earth strategy during their retreat from the Imperial German Army in the summer and the autumn of 1915. The Russian troops, retreating along a front of more than 600 miles, destroyed anything that might be of use to their enemy, including crops, houses, railways and entire cities. They also forcibly removed huge numbers of people. In pushing the Russian troops back into Russia's interior, the German army gained a large area of territory from the Russian Empire that is now Poland, Ukraine, Belarus, Latvia and Lithuania.[46]On the Western Front on 24 February 1917, the German army made a strategic scorched-earth withdrawal from the Somme battlefield to the prepared fortifications of the Hindenburg Line to shorten the line that had to be occupied. Since a scorched-earth campaign requires a war of movement, the Western Front provided little opportunity for the policy as the war was mostly a stalemate and was fought mostly in the same concentrated area for its entire duration.During the Greco-Turkish War (1919–22), the retreating Greek Army carried out a scorched-earth policy while it was fleeing from Anatolia in the final phase of the war.[47]  The historian Sydney Nettleton Fisher wrote, 'The Greek army in retreat pursued a burned-earth policy and committed every known outrage against defenceless Turkish villagers in its path'.[47]Norman Naimark noted that 'the Greek retreat was even more devastating for the local population than the occupation'.[48]During the Second Sino-Japanese War, the Imperial Japanese Army had a scorched-earth policy, known as 'Three Alls Policy', which caused immense environmental and infrastructure damage to be recorded. It contributed to the complete destruction of entire villages and partial destruction of entire cities.The Chinese National Revolutionary Army destroyed dams and levees in an attempt to flood the land to slow down the advancement of Japanese soldiers, which further added to the environmental impact and resulting in the 1938 Yellow River flood. In the 1938 Changsha fire, the city of Changsha was put on fire by the Kuomintang  to prevent any wealth from falling into enemy hands.[49]At the start of the Winter War in 1939, the Finns used the tactic in the vicinity of the border in order to deprive the invading Soviet Red Army's provisions and shelter for the forthcoming cold winter. In some cases, fighting took place in areas that were familiar to the Finnish soldiers who were fighting it. There were accounts of soldiers burning down their very own homes and parishes. One of the burned parishes was Suomussalmi.When Germany attacked the Soviet Union in June 1941, many district governments took the initiative to begin a partial scorched-earth policy to deny the invaders access to electrical, telecommunications, rail, and industrial resources. Parts of the telegraph network were destroyed, some rail and road bridges were blown up, most electrical generators were sabotaged through the removal of key components, and many mineshafts were collapsed.[citation needed] The process was repeated later in the war by the German forces of Army Group North and Erich von Manstein's Army Group Don, which stole crops, destroyed farms, and razed cities and smaller settlements during several military operations. The rationale for the policy was that it would slow pursuing Soviet forces by forcing them to save their own civilians, but in Manstein's postwar memoirs, the policy was justified as to have prevented the Soviets from stealing food and shelter from their own civilians. The best-known victims of the German scorched-earth policy were the people of the historic city of Novgorod, which was razed during the winter of 1944 to cover Army Group North's retreat from Leningrad.Near the end of the summer of 1944, Finland, which had made a separate peace with the Allies, was required to evict the German forces, which had been fighting against the Soviets alongside Finnish troops in northern Finland. The Finnish forces, under the leadership of General Hjalmar Siilasvuo, struck aggressively in late September 1944 by making a landfall at Tornio. That accelerated the German retreat, and by November 1944, the Germans had left most of northern Finland. The German forces, forced to retreat because of an overall strategic situation, covered their retreat towards Norway by devastating large areas of northern Finland by using a scorched-earth strategy. More than a third of the area's dwellings were destroyed, and the provincial capital Rovaniemi was burned to the ground. All but two bridges in Lapland Province were blown up, and all roads were mined.[50]In northern Norway, which was also being invaded by Soviet forces in pursuit of the retreating Wehrmacht in 1944, the Germans also undertook a scorched-earth policy of destroying every building that could offer shelter and thus interposing a belt of 'scorched earth' between themselves and the allies.[51]In 1945, Adolf Hitler ordered his minister of armaments, Albert Speer, to carry out a nationwide scorched-earth policy, in what became known as the Nero Decree. Speer, who was looking to the future, actively resisted the order, just as he had earlier refused Hitler's command to destroy French industry when the Wehrmacht was being driven out of France. Speer managed to continue doing so even after Hitler became aware of his actions.[52]During the Second World War, the railroad plough was used during retreats in Germany, Czechoslovakia and other countries to deny enemy use of railways by partially destroying them.Britain was the first nation to employ herbicides and defoliants (chiefly Agent Orange) to destroy the crops and the bushes of Malayan National Liberation Army (MNLA) insurgents in Malaya during the Malayan Emergency. The intent was to prevent MNLA insurgents from utilizing rice fields to resupply their rations and using them as a cover to ambush passing convoys of Commonwealth troops.In response to India's invasion of Portuguese Goa in December 1961 during the annexation of Portuguese India, orders delivered from Portuguese President Américo Tomás called for a scorched-earth policy for Goa to be destroyed before its surrender to India.[53]However, despite his orders from Lisbon, Governor General Manuel António Vassalo e Silva took stock of the superiority of the Indian troops and of his forces' supplies of food and ammunition and took the decision to surrender. He later described his orders to destroy Goa as 'a useless sacrifice' (um sacrifício inútil)'.The United States used Agent Orange as a part of its herbicidal warfare program Operation Ranch Hand to destroy crops and foliage to expose possible enemy hideouts during the Vietnam War. Agent Blue was used on rice fields to deny food to the Viet Cong.During the 1990 Gulf War, when Iraqi forces were driven out of Kuwait, they set more than 600 Kuwaiti oil wells on fire.[54] That was done as part of a scorched-earth policy during the retreat from Kuwait in 1991 after Iraqi forces had been driven out by Coalition military forces. The fires were started in January and February 1991, and the last one was extinguished by November 1991.[55]Efraín Ríos Montt used the policy in Guatemala's highlands in 1981 and 1982, but it had been used under the previous president, Fernando Romeo Lucas García. Upon entering office, Ríos Montt implemented a new counterinsurgency strategy that called for the use of scorched earth to combat the Guatemalan National Revolutionary Unity rebels. Plan Victoria 82 was more commonly known by the nickname of the rural pacification elements of the strategy, Fusiles y Frijoles (Bullets and Beans).[56]  Ríos Montt's policies resulted in the death of thousands, most of them indigenous Mayans.The Indonesian military used the method during Indonesian National Revolution when the British forces in Bandung gave an ultimatum for Indonesian fighters to leave the city. In response, the southern part of Bandung was deliberately burned down in an act of defiance as they left the city on 24 March 1946. This event is known as the Bandung Sea of Fire (Bandung Lautan Api).[57]The Indonesian military and pro-Indonesia militias also used the method in the 1999 East Timorese crisis. The Timor-Leste scorched-earth campaign was around the time of East Timor's referendum for independence in 1999.The method was used during the Yugoslav Wars, such as against the Serbs in Krajina by the Croatian Army,[58][59] and by Serbian paramilitary groups.[60]The Sudanese government has used scorched earth as a military strategy in Darfur.During the Sri Lankan Civil War in 2009 the United Nations Regional Information Centre (UNRIC) has accused the Sri Lankan government of utilizing scorched-earth tactics.[61][62][63]During the 2011 Libyan civil war, forces loyal to Moammar Gadhafi planted a large number of landmines within the petroleum port of Brega to prevent advancing rebel forces from utilizing the port facilities.[citation needed] Libyan rebel forces practiced scorched-earth policies when they completely demolished and refused to rebuild critical infrastructure[example  needed] in towns and cities formerly loyal to Moammar Gadhafi such as Sirte and Tawargha.[64]As part of the ceasefire agreement 2020 Nagorno-Karabakh war, Armenian forces agreed to relinquish control of areas of the Republic of Artsakh that fell outside of the borders of the old Soviet Nagorno-Karabakh Autonomous Oblast. Scorched-earth offensive tactic used by the Azerbaijani Armed Forces enabled quick advances in the populated areas. The Azerbaijani Armed Forces used scorched-earth tactics to advance and gain control over large forested and populated areas using incendiary weapons (possibly, white phosphorus).[65] The incendiary attacks[66] inflicted extensive damage to nature[67] and destroyed objects essential for the survival of the villages (i.e., livestock, wood for the winter, water sources, etc.)[68][69] in the vicinity of the affected areas. Some villages (e.g., Aknaghbyur[70]) were the object of direct incendiary attacks or arson. This led to a mass exodus of combatants and civilian population from villages facing violent takeover of the approaching Azerbaijani Armed Forces, as both military[71] and civilian casualties of the incendiary attacks[72] made holding positions unsustainable. This offensive tactic effectively allowed the Azerbaijani Armed Forces to progress rapidly and seize control of large populated areas of Nagorno-Karabakh (Artsakh) region.It is prohibited to attack, destroy, remove, or render useless objects indispensable to the survival of the civilian population, such as foodstuffs, agricultural areas for the production of foodstuffs, crops, livestock, drinking water installations and supplies, and irrigation works, for the specific purpose of denying them for their sustenance value to the civilian population or to the adverse Party, whatever the motive, whether in order to starve out civilians, to cause them to move away, or for any other motive.[1]", 'attributes': {'Scorched earth': {}}} (scraper.py:257)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Bastion_fort> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Kremlin_(fortification)> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/RPG-29> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/SdKfz_252%E5%8D%8A%E5%B1%A5%E5%B8%A6%E8%BD%A6>
{'keyword': '装甲运输车', 'source': 'wiki', 'title': 'SdKfz 252半履带车', 'url': 'https://zh.wikipedia.org/wiki/SdKfz_252%E5%8D%8A%E5%B1%A5%E5%B8%A6%E8%BD%A6', 'date': ' ', 'content': '第252号特种车辆（德语：Sonderkraftfahrzeug 252，简称：Sd.Kfz. 252），又称轻型装甲弹药运输车（leichter gepanzerter Munitionskraftwagen），是纳粹德国在二战期间使用的一款轻型半履带装甲运输车。Sd.Kfz. 252的设计基于Sd.Kfz. 250半履带车，并使用同款底盘。1940年6月至12月由德马格（英语：Demag）和韦格曼（英语：Krauss-Maffei Wegmann）负责生产。1941年1月至9月则由德意志造船厂负责生产，一共制造了413辆[1]。主要用途是为突击炮部队运输弹药，在东西线皆有使用。为了增加弹药运载能力，使用Sd.Ah. 32/1（Sonder-Anhänger 32/1） 拖车，可以额外运载36枚75毫米炮弹[2]。法国战役期间，第640和659突击炮连使用了Sd.Kfz. 252。在东线，使用者为第184、190和210突击炮营[3]。1941年之后停止生产，被Sd.Kfz. 250/6半履带车取代[4]。', 'attributes': {'SdKfz 252半履带车': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Bundesarchiv_Bild_101I-154-1968-16%2C_Russland%2C_Sch%C3%BCtzenpanzer_im_Gel%C3%A4nde.jpg/181px-Bundesarchiv_Bild_101I-154-1968-16%2C_Russland%2C_Sch%C3%BCtzenpanzer_im_Gel%C3%A4nde.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Balkenkreuz.svg/30px-Balkenkreuz.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/Sd.Kfz._252_01.png/300px-Sd.Kfz._252_01.png'], '类型': '轻型半履带装甲弹药运输车', '原产地': '纳粹德国', '服役期间': '1940年-？', '参与战争／冲突': '二战', '研发者': '德马格（英语：Demag）', '生产商': '德马格（英语：Demag）、韦格曼（英语：Krauss-Maffei Wegmann）、德意志造船厂', '生产日期': '1940年6月至12月（德马格、韦格曼)，1941年1月至9月（德意志造船厂）', '制造数量': '413', '重量': '5.73吨', '长度': '4.7米', '宽度': '1.95米', '高度': '1.8米', '操作人数': '2', '发动机': '迈巴赫HL42 TRKM 6缸水冷引擎', '作战范围': '320公里 公路175公里 越野', '速度': '65公里/小时'}}} (scraper.py:257)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E7%9B%B4%E5%8D%87%E6%A9%9F>
{'keyword': '直升机', 'source': 'wiki', 'title': '直升机', 'url': 'https://zh.wikipedia.org/wiki/%E7%9B%B4%E5%8D%87%E6%A9%9F', 'date': ' ', 'content': '直升机是一种由水平旋转的动力旋翼提供向上升力和飞行推进力的飞行器，是旋翼航空器的主要种类。直升机具有大多数固定翼飞机所不具备的垂直起降、悬停和随意向前、向后或侧向飞行的能力，这些特点使得直升机在很多狭窄、崎岖、缺乏跑道的复杂环境下有许多优势。与固定翼飞机相比，直升机的缺点是速度低、耗油量较高、航程较短、载重较少。直升机旋翼产生升力的原理与固定翼飞机的机翼相似，通过翼剖面与空气发生相对运动使得旋翼产生上弱下强的气压差，进而产生升力并通过旋翼的主轴传递给机身，使其可以克服重力实现飞行。和固定翼飞机的机翼一样，直升机旋桨能够产生的升力大小取决于气流速度和其桨叶水平投影面积的总和；但直升机不像固定翼飞机那样必须依赖整个机体的向前运动才能让机翼产生气流，而是依靠翼片的旋转产生与空气的相对运动。但旋翼在提供升力的同时也会产生反扭矩（与旋翼的转动方向相反、角动量相等的反作用扭矩）并传递到机身上，这使得最为常见的单旋翼直升机在浮空时会向着旋桨相反的方向自旋。为了平衡反扭矩，直升机需要在机尾位置产生一个与旋翼方向相同、角动量相等的水平旋转推力抵消反力矩，最常见的做法是在机尾末端安装一个垂直的小型螺旋桨（即尾桨）提供推力。而双旋翼和多旋翼直升机多采用让反向旋转的旋翼之间的扭矩相互抵消的方法来清除反扭矩，并可以利用各个旋翼的转速差别来改变飞行状态。在附图的运作说明中可以见得，由上俯视一个顺时针旋转的主翼，它的尾桨会是向黄色箭头所指方向推力的。直升机和自转旋翼机的外观相似，但是飞行原理和性能并不同。自转旋翼机的发动机只驱动尾部的螺旋桨提供前进推力，主旋桨并没有动力源，必须依赖向前运动时的相对反向气流才能被动旋转产生升力。自转旋翼机虽然构造比较简单和低价也可以做到短程起降，但完全没有垂直起降、悬停、随意侧飞和倒飞的能力，不如直升机的性能广泛，是介乎于固定翼飞机和直升机中间的一种对跑道要求较低的飞行器。用途较狭而专业化的航空机构通常拥有直升机，但鲜有采用旋翼机。人类梦想的飞行方式是原地腾空而起，既能自由飞翔又能悬停于空中，并且随意实现定点着陆。例如阿拉伯人的飞毯，希腊神的战车，都是垂直起落飞行器。其中最有价值、最具代表性的是中国古代玩具竹蜻蜓和意大利人达·芬奇关于垂直起降航空器的画作。李约瑟误以为中国晋朝葛洪所著的《抱朴子》有纪录类似竹蜻蜓最早的动力机械[1]，但实际上文章说的是服丹修练成仙成功时，人可以飞行[2]。《简明不列颠百科全书》第9卷写道：“直升机是人类最早的飞行设想之一，多年来人们一直相信最早提出这一想法的是达·芬奇，但现在都知道，中国人比中世纪的欧洲人更早做出了直升机玩具。”这种玩具于14世纪传到欧洲。“英国航空之父”乔治·凯利（1773年－1857年）曾制造过几个竹蜻蜓，用钟表发条作为动力来驱动旋转，飞行高度曾达27米。随着生产力的发展和人类文明的进步，直升机的发展史由幻想时期进入了探索时期。欧洲产业革命之后，机械工业迅速倔起，尤其是本世纪初汽车和轮船的发展，为飞行器准备了发动机和可供借鉴的螺旋桨。经过航空先驱者们勇敢而艰苦的创造和试验，1903年莱特兄弟（Wright brothers）制造的固定翼飞机飞行成功。在此期间，尽管在发展直升机方面，航空先驱们付出了相当的艰辛和努力，但由于直升机技术的复杂性和发动机性能不佳，它的成功飞行比飞机迟了30多年。20世纪初为直升机发展的探索期，多种试验性机型相继问世。试验机方案的多样性表明了探索阶段的技术不成熟性。经过多年实践，这些方案中只有纵列式和共轴双旋翼式保留了下来，至今仍在应用。双桨横列式方案未在直升机家族中延续，但在倾转旋翼飞机中得到了继承和发展。俄国人尤利耶夫另辟捷径，提出了利用尾桨来配平旋翼反扭矩的设计方案并于1912年制造出了试验机。这种单旋翼带尾桨式直升机成为至今最流行的形式。经过20世纪初的努力探索，为直升机发展积累了可贵的经验并取得显著进展，有多架试验机实现了短暂的垂直升空和短距飞行，但离实用还有很大距离。飞机工业的发展使航空发动机的性能迅速提高，为直升机的成功提供了重要条件。旋翼技术的第一次突破，归功于西班牙人Ciervao，他为了创造“不失速”的飞机以解决固定翼飞机的安全问题，采用自转旋翼代替机翼，发明了自转旋翼机。旋翼技术在自转旋翼机上的成功应用和发展，为直升机的诞生提供了另一个重要条件。1907年8月，法国人保罗·科尔尼研制出一架全尺寸载人直升机，并在同年11月13日试飞成功。这架直升机被称为“人类第一架直升机”。1938年，年轻的德国人汉纳赖奇驾驶一架双旋翼直升机在柏林体育场进行了一次完美的飞行表演。这架直升机被直升机界认为是世界上第一种试飞成功的直升机。1936年，德国福克公司在对早期直升机进行多方面改进之后，公开展示了自己制造的FW-61直升机，1年后该机创造了多项世界纪录。[3]1939年春，美国的伊戈尔·伊万诺维奇·西科尔斯基完成了VS-300直升机的全部设计工作，同年夏天制造出一架原型机。这种单旋翼带尾桨直升机构型成为现在最常见的直升机构型。20世纪40年代，美国沃特-西科斯基公司研制的一种2座轻型直升机R-4，它是世界上第一种投入批量生产的直升机，也是美国陆军航空兵、海军、海岸警卫队和英国空军、海军使用的第一种军用直升机。该机的公司编号为VS-316，VS-316A。美国陆军航空兵的编号为R-4，美国海军和海岸防卫队的编号为HNS-1，英国空军将其命名为“食蚜虻1”（Hoverfly 1），英国海军将其命名为“牛虻”（Gadfly）。到30年代末期，在法国、德国、美国和前苏联都有直升机试飞成功，并迅速改进达到了能够实用的程度。第二次世界大战的军事需要，加速了这一进程，促使直升机发展由探索期进入实用期，直升机开始投入生产线生产。到二战结束时，德国工厂已生产了30多架直升机，美国交付的R5、R6直升机已达400多架。[4]20世纪的后半期直升机进入航空实用期，特别是越战期间大量直升机部属到战场，战后直升机的应用领域不断扩展，数量迅速增加。每年八月第三个星期日被列为世界直升机日。单旋翼直升机（monocopter或unicopter）是直升机的主要类型，使用单一的主旋翼（main rotor）产生升力，但因为角动量守恒的原因，必须配有一个反扭矩机制去抵消主旋翼旋转造成的机体反向旋转。有尾桨例子：西科斯基UH-60涵道式尾桨例子：欧直EC-135无尾桨例子：麦道MD520N双旋翼直升机（bicopter）使用两个旋翼合作产生升力，可以用方向相反的旋转互相抵消反扭矩，因此不需要在尾部安装垂直旋桨。纵列式代表：波音CH-47D横列式代表：米里Mi-12倾转式代表：贝尔-波音V-22共轴式代表：卡莫夫Ka-27交错式代表：H-43卡曼公司双旋翼交叉式直升机K-600多旋翼直升机（multicopter）使用三个以上的旋翼来产生升力，是民用无人航空载具的主流类型。最常见的设计是四旋翼直升机（quadcopter），有四个大小相同、分布位置接近对称的旋翼来达到悬停、维持姿态及平飞。小型四旋翼飞行器大疆悟2无人机大疆御Air 2无人机六旋翼无人机直升机的起落架分为滑橇式和轮式两种，轮式又分可收放和不可收放式。滑橇式一般用于轻型直升机；轮式多用在中型、重型直升机。[5][6]直升机的操纵系统有别于固定翼航空器，通常由以下部分组成：单旋翼带尾桨直升机的操纵系统说明表直升机依照用途可分为民用与军用两种。作为民间工作，没有武装且仅有该用途所需的装备的直升机即为民用直升机。依其用途目前主要可分为下列几种：增加装甲和武器，同时加强性能以供军事用途的直升机便为军用直升机。依其用途目前主要可分为下列五种：', 'attributes': {'直升机': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Russian_Air_Force_Kamov_Ka-50.jpg/220px-Russian_Air_Force_Kamov_Ka-50.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Rotor_Antitorque_System.svg/220px-Rotor_Antitorque_System.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Helicopter_rescue_sancy_takeoff.jpg/220px-Helicopter_rescue_sancy_takeoff.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Mil_Mi-6%2C_54RED%2C_Russian_Air_Force.jpg/220px-Mil_Mi-6%2C_54RED%2C_Russian_Air_Force.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/F-WWPB_%288970712548%29.jpg/240px-F-WWPB_%288970712548%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Hatzerim_270613_Apache.jpg/220px-Hatzerim_270613_Apache.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/LAPD_Bell_206_Jetranger.jpg/300px-LAPD_Bell_206_Jetranger.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Antitorque.jpg/303px-Antitorque.jpg'], '航空器专题': ';;;航空器专题;;;单纯利用空气浮力（浮空器）;;;无动力;;动力;;;;气球;;;飞艇;;;空气浮力和空气动力混合;;;无动力;;动力;;;;混合系留气球;风筝式系留气球;;;混合飞艇;;;单纯利用空气动力;;;无动力;;动力;;;无动力固定翼;;动力固定翼;;;;滑翔机;悬挂式滑翔机;滑翔伞;风筝;;;飞机;动力滑翔伞;滚筒飞行器;地效飞行器;;;;;半固定翼和旋翼;;;;;;倾转旋翼机;环翼机;;;无动力旋翼;;动力旋翼;;;;旋翼风筝;;;自转旋翼机;旋翼式螺旋桨飞机;直升机;;;;;扑翼;;;;;;扑翼机;;;其他;;;无动力;;动力;;;;;;飞行实验器;飞行汽车;飞天车;;'}}} (scraper.py:257)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 01:55:49] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Bastion_fort>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Bastion fort', 'url': 'https://en.wikipedia.org/wiki/Bastion_fort', 'date': 202202061000, 'content': "A bastion fort or trace italienne (a phrase derived from non-standard French, literally meaning Italian outline) is a fortification in a style that evolved during the early modern period of gunpowder when the cannon came to dominate the battlefield. It was first seen in the mid-fifteenth century in Italy. Some types, especially when combined with ravelins and other outworks, resembled the related star fort of the same era.The design of the fort is normally a polygon with bastions at the corners of the walls. These outcroppings eliminated protected blind spots, called 'dead zones', and allowed fire along the curtain from positions protected from direct fire. Many bastion forts also feature cavaliers, which are raised secondary structures based entirely inside the primary structure.Their predecessors, medieval fortresses, were usually placed on high hills. From there, arrows were shot at the enemies. The enemies' hope was to either ram the gate or climb over the wall with ladders and overcome the defenders. For the invading force, these fortifications proved quite difficult to overcome, and accordingly, fortresses occupied a key position in warfare.Passive ring-shaped (Enceinte) fortifications of the Medieval era proved vulnerable to damage or destruction by cannon fire, when it could be directed from outside against a perpendicular masonry wall. In addition, an attacking force that could get close to the wall was able to conduct undermining operations in relative safety, as the defenders could not shoot at them from nearby walls, until the development of Machicolation. In contrast, the bastion fortress was a very flat structure composed of many triangular bastions, specifically designed to cover each other, and a ditch. To counteract the cannonballs, defensive walls were made lower and thicker. To counteract the fact that lower walls were easier to climb, the ditch was widened so that attacking infantry were still exposed to fire from a higher elevation, including enfilading fire from the bastions. The outer side of the ditch was usually provided with a glacis to deflect cannonballs aimed at the lower part of the main wall. Further structures, such as ravelins, tenailles, hornworks or crownworks, and even detached forts could be added to create complex outer works to further protect the main wall from artillery, and sometimes provide additional defensive positions. They were built of many materials, usually earth and brick, as brick does not shatter on impact from a cannonball as stone does.[2]Bastion fortifications were further developed in the late fifteenth and early sixteenth centuries, primarily in response to the French invasion of the Italian peninsula. The French army was equipped with new cannon and bombards that were easily able to destroy traditional fortifications built in the Middle Ages. Star forts were employed by Michelangelo in the defensive earthworks of Florence, and refined in the sixteenth century by Baldassare Peruzzi and Vincenzo Scamozzi. The design spread out of Italy in the 1530s and 1540s.It was employed heavily throughout Europe for the following three centuries. Italian engineers were heavily in demand throughout Europe to help build the new fortifications. The late-seventeenth-century architects Menno van Coehoorn and especially Vauban, Louis XIV's military engineer, are considered to have taken the form to its logical extreme. 'Fortresses... acquired ravelins and redoubts, bonnettes and lunettes, tenailles and tenaillons, counterguards and crownworks and hornworks and curvettes and fausse brayes and scarps and cordons and banquettes and counterscarps...'[3]The star-shaped fortification had a formative influence on the patterning of the Renaissance ideal city: 'The Renaissance was hypnotized by one city type which for a century and a half—from Filarete to Scamozzi—was impressed upon all utopian schemes: this is the star-shaped city.'[4] In the 19th century, the development of the explosive shell changed the nature of defensive fortifications. Elvas, in Portugal is considered by some to be the best surviving example of the Dutch school of fortifications.When the newly-effective manoeuvrable siege cannon came into military strategy in the fifteenth century, the response from military engineers was to arrange for the walls to be embedded into ditches fronted by earthen slopes (glacis) so that they could not be attacked by destructive direct fire and to have the walls topped by earthen banks that absorbed and largely dissipated the energy of plunging fire. Where conditions allowed, as in Fort Manoel in Malta, the ditches were cut into the native rock, and the wall at the inside of the ditch was simply unquarried native rock. As the walls became lower, they also became more vulnerable to assault.The rounded shape that had previously been dominant for the design of turrets created 'dead space', or 'dead zones', which were relatively sheltered from defending fire, because direct fire from other parts of the defences could not be directed around curved walls. To prevent this, what had previously been round or square turrets were extended into diamond-shaped points to eliminate potential cover for attacking troops. The ditches and walls channelled the attackers into carefully constructed zwinger, bailey, or similar 'kill zone' areas where the attackers had no place to shelter from the fire of the defenders.A further and more subtle change was to move from a passive model of defence to an active one. The lower walls were more vulnerable to being stormed, and the protection that the earthen banking provided against direct fire failed if the attackers could occupy the slope on the outside of the ditch and mount an attacking cannon there. Therefore, the shape was designed to make maximum use of enfilade (or flanking) fire against any attackers who should reach the base of any of the walls. The indentations in the base of each point on the star sheltered cannons. Those cannons would have a clear line of fire directly down the edge of the neighbouring points, while their point of the star was protected by fire from the base of those points. The evolution of these ideas can be seen in transitional fortifications such as Sarzana in northwest Italy.[5]Thus forts evolved complex shapes that allowed defensive batteries of cannon to command interlocking fields of fire. Forward batteries commanded the slopes which defended walls deeper in the complex from direct fire. The defending cannon were not simply intended to deal with attempts to storm the walls, but to actively challenge attacking cannon and deny them approach close enough to the fort to engage in direct fire against the vulnerable walls.The key to the fort's defence moved to the outer edge of the ditch surrounding the fort, known as the covered way, or covert way. Defenders could move relatively safely in the cover of the ditch and could engage in active countermeasures to keep control of the glacis, the open slope that lay outside the ditch, by creating defensive earthworks to deny the enemy access to the glacis and thus to firing points that could bear directly onto the walls and by digging counter mines to intercept and disrupt attempts to mine the fort walls.Compared to medieval fortifications, forts became both lower and larger in area, providing defence in depth, with tiers of defences that an attacker needed to overcome in order to bring cannon to bear on the inner layers of defences.Firing emplacements for defending cannon were heavily defended from bombardment by external fire, but open towards the inside of the fort, not only to diminish their usefulness to the attacker should they be overcome, but also to allow the large volumes of smoke that the defending cannon would generate to dissipate.Fortifications of this type continued to be effective while the attackers were armed only with cannon, where the majority of the damage inflicted was caused by momentum from the impact of solid shot. Because only low explosives such as black powder were available, explosive shells were largely ineffective against such fortifications. The development of mortars, high explosives, and the consequent large increase in the destructive power of explosive shells and thus plunging fire rendered the intricate geometry of such fortifications irrelevant. Warfare was to become more mobile. It took, however, many years to abandon the old fortress thinking.Bastion forts were very expensive. Amsterdam's 22 bastions cost 11 million florins, and Siena in 1544 bankrupted itself to pay for its defences. For this reason, bastion forts were often improvised from earlier defences. Medieval curtain walls were torn down, and a ditch was dug in front of them. The earth used from the excavation was piled behind the walls to create a solid structure. While purpose-built fortifications would often have a brick fascia because of the material's ability to absorb the shock of artillery fire, many improvised defences cut costs by leaving this stage out and instead opting for more earth. Improvisation could also consist of lowering medieval round towers and infilling them with earth to strengthen the structures.It was also often necessary to widen and deepen the ditch outside the walls to create a more effective barrier to frontal assault and mining. Engineers from the 1520s were also building massive, gently sloping banks of earth called glacis in front of ditches so that the walls were almost totally hidden from horizontal artillery fire. The main benefit of the glaces was to deny enemy artillery the ability to fire point-blank. The lower the angle of elevation, the higher the stopping power.The first key instance of a trace Italianate was at the Papal port of Civitavecchia, where the original walls were lowered and thickened because the stone tended to shatter under bombardment.The first major battle which truly showed the effectiveness of trace Italienne was the defence of Pisa in 1500 against a combined Florentine and French army. With the original medieval fortifications beginning to crumble to French cannon fire, the Pisans constructed an earthen rampart behind the threatened sector. It was discovered that the sloping earthen rampart could be defended against escalade and was also much more resistant to cannon fire than the curtain wall it had replaced.The second siege was that of Padua in 1509. A monk engineer named Fra Giocondo, trusted with the defence of the Venetian city, cut down the city's medieval wall and surrounded the city with a broad ditch that could be swept by flanking fire from gun ports set low in projections extending into the ditch. Finding that their cannon fire made little impression on these low ramparts, the French and allied besiegers made several bloody and fruitless assaults and then withdrew.The new type of fortification also played a role in the numerous Mediterranean wars, slowing down the Ottoman expansion. Although Rhodes had been partially upgraded to the new type of fortifications after the 1480 siege, it was still conquered in 1522; nevertheless it was a long and bloody siege, and the besieged had no hope of outside relief because the island was close to the Ottoman power base and far from any allies. On the other hand, the Ottomans failed to take Corfu in 1537 in no small part because of the new fortifications, and several attempts spanning almost two centuries (another major one was in 1716) also failed.[7][8]Two star forts were built by the Order of Saint John on the island of Malta in 1552, Fort Saint Elmo and Fort Saint Michael. Fort Saint Elmo played a critical role in the Ottoman siege of 1565 when it managed to hold out heavy bombardment for over a month. Eventually it fell, but the Ottoman casualties were very high, and it bought time for the relief force which arrived from Sicily to relieve the rest of the besieged island. The star fort therefore played a crucial and decisive role in the siege.[9]After the fall of Venice to Napoleon, Corfu was occupied in 1797 by the French republican armies. The now ancient fortifications were still of some value at this point. A Russian–Ottoman–English alliance led at sea by Admiral Ushakov and with troops sent by Ali Pasha retook Corfu in 1799 after a four-month siege, when the garrison led by general Louis François Jean Chabot, being short of provisions and having lost the key island of Vido at the entrance of the port, surrendered and was allowed passage back to France.[10][11]According to Geoffrey Parker in his article, The Military Revolution 1560–1660: A Myth?, the appearance of the trace Italienne in early modern Europe, and the difficulty of taking such fortifications, resulted in a profound change in military strategy, most importantly, Parker argued, an increase in army sizes necessary to attack these forts. 'Wars became a series of protracted sieges,' Parker suggests, and open-pitch battles became 'irrelevant' in regions where the trace Italienne existed. Ultimately, Parker argues, 'military geography', in other words, the existence or absence of the trace Italienne in a given area, shaped military strategy in the early modern period. This is a profound alteration of the Military Revolution thesis originally proposed by Michael Roberts in 1955.Parker's emphasis on the fortification as the key element has attracted substantial criticism from some academics, such as John A. Lynn and M. S. Kingra, particularly with respect to the claimed causal link between the new fortress design and increases in army sizes during this period.[12]In the nineteenth century, with the development of more powerful artillery and explosive shells, star forts were replaced by simpler but more robust polygonal forts. In the twentieth century, with the development of tanks and aerial warfare during and after the First World War, fixed fortifications became and have remained less important than in previous centuries.", 'attributes': {'Bastion fort': {}}} (scraper.py:257)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Kremlin_(fortification)>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Kremlin (fortification)', 'url': 'https://en.wikipedia.org/wiki/Kremlin_(fortification)', 'date': 202202280732, 'content': "A kremlin (Russian: кремль, romanized:\xa0kreml', ˈkrʲemlʲ) is a major fortified central complex found in historic Russian cities.[1][2] This word is often used to refer to the most famous one, the Moscow Kremlin,[3] or metonymically to the government that is based there.[4] Other such fortresses are called detinets, such as the Novgorod Detinets.The Russian word is of uncertain origin. Different versions include the word originating from the Turkic languages, the Greek language or from Baltic languages.[5][6][7][8][9][10] The word may share the same root as kremen' (Russian: кремень, krʲɪˈmʲenʲ, 'flint').[11]The Slavs began to build fortresses to protect their lands from enemies in the ninth century. It is known that the Scandinavians called the Slavic lands the land of fortresses - 'Gardariki'. Arabic geographer Al-Bakri wrote: 'And that is how the Slavs build a large part of their fortresses: they head for meadows, rich in water and reeds, and there mark a round or rectangular place, depending on the shape they want to make a fortress, and they dig around the moat, and the dugout earth is dumped in a rampart, reinforcing it with planks and piles, like beaten earth, until the wall reaches the desired height. Then they measure the door at whichever side they want, and approach by a wooden bridge'.[12] In ancient times, a wooden fence was built on the crest of a rampart, a palisade or zapolot (the wall made of logs, vertically one above the other, and connected with horizontally laid timbers). The way of defending the settlement was primitive; later wooden fortress walls became more preferable.In the VIII century, the earliest known stone and wooden fortress - Lubšanská fortress near Staraya Ladoga was built. The ancient stone and wooden kremlins include a fortress on Truvorov settlement near Izborsk (IX century) and the first Stara Ladoga Kremlin (the end of IX century, later rebuilt). Single stone towers, gates and bends of walls appeared in other cities (Vladimir, Kyiv, Novgorod, Pereyaslavl): the Golden Gate of Kievan citadel and the gate of the Vladimir Kremlin bearing the same name survived.[13]A special type of wooden and stone Kremlins appeared under the influence of architectural traditions of Poland and Hungary. They were characterised by the juxtaposition of wooden walls and towers with vezha - high stone towers standing inside the fortress, which were used as watchtowers. Constructions, called Volyn towers, were erected, for example, in the citadels of Kholmsk, Kamenets and Gorodeni.[13]During the Mongol-Tatar invasion, many Russian wooden and stone-wooden fortresses were taken and destroyed by the Mongols. The long-lasting Mongol-Tatar yoke slowed down the development of Russian fortification architecture for a century and a half, as internecine wars stopped and the need to build fortresses disappeared.The tradition of fortress construction was preserved in Novgorod and Pskov lands which were not damaged by the Mongol invasion. Here are built not only kremlins (Izborsk, Porkhov) but - for the first time in Russia - fortresses, which were not many cities in the full sense of the word, as defensive structures (Koporie, Oreshek, Yam, Korela, Ostrov, Kobyla). The strongest of the Russian fortresses was the Pskov Kremlin, which had no equal in Russia in the number of sustained sieges.[13]The term Kremlin (in the variant Kremnik) is first encountered in chronicles of 1317 in accounts of the construction of the Tver Kremlin, where a wooden city-fortress was erected, which was clayed and whitewashed.[14]Wooden fortresses were erected everywhere in the Russian state - from the Far East lands to the Swedish borders. They were numerous in the South, where they served as a link of fortified fortification zones cutting off the way to the central regions from Crimean Tatars. Aesthetically wooden fortresses were not inferior to stone ones - and we can regret that the towers of wooden kremlins have not survived to this day. Wooden fortresses were built quickly: in 1638 in Mtsensk fortress walls of Bolshoi Ostrog and Pletny Gorod with a total length of about 3 kilometres with 13 towers and almost one hundred meters long bridge over the River Zusha were erected in 20 days. The town of Sviyazhsk was built similarly during the Kazan campaign in the spring of 1551: fortress walls about 2.5 kilometres long, many churches and houses were erected in a month.Later on, many Kremlins were rebuilt and strengthened. Thus, the Moscow Kremlin under Ivan the Third was reconstructed of bricks.In the XVI-XVII centuries, about 30 stone fortresses were built in the Russian State. New Kremlins have regular geometric forms in plan (Zaraisky and Tula Kremlins). The Tula Kremlin is unique because it was built in a valley (which was possible because of undeveloped siege artillery of nomad Tatars).Construction of the Kremlin lasted until the turn of the XVII-XVIII centuries. The last Kremlin structure was built of stone in 1699-1717 in the town of Tobolsk (the easternmost Kremlin in Russia). [further explanation needed]After the disintegrations of the Kievan Rus, the Russian Empire and the USSR, some fortresses considered Kremlin-type, remained beyond the borders of modern Russia. Some are listed below:The same structure in Novgorodshina, Ukraine and other Old Russian territories is also called dytynets ( Ukrainian: дитинець, from dytyna – child). The term has been in use since the 11th century. The term kremlin first appeared in 14th century in various Russian territories, where it replaced dytynets.Many Russian monasteries have been built in a fortress-like style similar to that of a kremlin. For a partial list, see Monasteries in Russia.", 'attributes': {'Kremlin (fortification)': {}}} (scraper.py:257)
[2022-03-10 01:55:50] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:55:50] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1604,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 38688,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 2.91009,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 55, 50, 85455),
 'httpcompression/response_bytes': 140641,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 34,
 'log_count/INFO': 22,
 'memusage/max': 67608576,
 'memusage/startup': 67608576,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 55, 47, 175365)} (statscollectors.py:47)
[2022-03-10 01:55:50] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/RPG-29>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'RPG-29', 'url': 'https://en.wikipedia.org/wiki/RPG-29', 'date': 202202081156, 'content': "The RPG-29 'Vampir' is a Soviet reusable rocket-propelled grenade (RPG) launcher. Adopted by the Soviet Army in 1989,[5] it was the last RPG to be adopted by the Soviet military before the fall of the Soviet Union in 1991.The RPG-29 has since been supplemented by other rocket-propelled systems, such as the RPG-30 and RPG-32. The RPG-29 has been implicated in an attack on the British Challenger 2 tanks in Iraq, as well as in attacks on Israeli Merkava tanks in Lebanon, which breached the tanks' armor and in some cases injured or killed members of the crew.[6][7]The RPG-29 is a shoulder-launched, unguided, tube-style, breech-loading anti-tank rocket system with a range of 500 meters. The light weapon is designed to be carried and used by a single soldier. On the top of the launch tube is a 2.7× 1P38 optical sight.When launched, the missile deploys eight fins as the rocket leaves the launcher, stabilizing the rocket during flight, up to a range of 500 meters.[8]Two warheads are available for the weapon:The RPG-29 is unusual among Russian anti-tank rocket launchers in that it lacks an initial propellant charge to place the projectile at a safe distance from the operator before the rocket ignites. Instead, the rocket engine starts as soon as the trigger is pulled, and burns out before the projectile leaves the barrel.On the bottom of the tube is a shoulder brace for proper positioning along with a pistol grip trigger mechanism. A 1PN51-2 night sight can be fitted.[10]The RPG-29 was developed during the late 1980s, following the development of the RPG-26, and entered service with the Soviet Army in 1989. It has recently seen intermittent use by irregular forces in the Middle East theater, including in combat against Allied forces during the Iraq War, and the 2006 Lebanon War, when it was used against Israeli forces.The RPG-29 is believed to have been used in skirmishes against American and British forces during the initial 2003 invasion of Iraq.[11] An RPG-29 round was reported in August 2006 to have penetrated the frontal underside hull (equipped with ERA) of a Challenger 2 tank during an engagement in al-Amarah, Iraq, maiming one and wounding several other crew members, but only lightly damaging the tank, which drove home under its own power.[12]On August 25, 2007 a PG-29V hit a passing M1 Abrams in the hull rear wounding 3 crew members.[13] On September 5, 2007, a PG-29V hit the side turret of an M1 Abrams in Baghdad, killing 2 of the crew and wounding 1, and the tank was seriously damaged.[14]In May 2008, The New York Times disclosed that another M1 Abrams tank had also been damaged by an RPG-29 in Iraq, while fighting Shia militias at Sadr City.[11] The US Army ranks the RPG-29 threat to armor so high that they refused to allow the newly formed Iraqi army to buy it, fearing that it would fall into insurgent hands.[15]During the conflict, the Israeli newspaper Haaretz stated that the RPG-29 was a major source of IDF casualties in the 2006 Lebanon War.[16] A spokesman for the Russian Foreign Ministry denied that Russia had supplied arms directly to Hezbollah.[17] Shortly before the end of the conflict the Russian  Kommersant magazine acknowledged through anonymous sources the possibility of a weapons transfer between Syria and Hezbollah during the Syrian withdrawal from Lebanon.[18]During the Syrian Civil War, Syrian Opposition Forces and ISIL both used RPG-29s.[19]The cartels are known to have smuggled RPG-29s with some seized by Mexican forces.[20]During the 2014 Gaza War, Hamas had used RPG-29s to attack IDF Merkava tanks, however because of the recently developed Trophy (countermeasure) they had little effect.[21]During the Iraqi Civil War, ISIL has used RPG-29s in Iraq, probably ones taken in Syria. And anti-ISIL Shia militias in Iraq have also used RPG-29s, the Iranian produced 'Ghadir', which was supplied by Iran.", 'attributes': {'RPG-29': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/RPG-29_operators.png/400px-RPG-29_operators.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/RPG-29_USGov.JPG/300px-RPG-29_USGov.JPG'], 'Type': 'Rocket-propelled grenade', 'Placeoforigin': 'Soviet Union', 'Inservice': '1989–present', 'Usedby': 'See Operators', 'Wars': 'Iraq War;2014 Gaza WarIraqi Civil War', 'Designer': 'Bazalt', 'Designed': 'late 1980s', 'Manufacturer': 'Bazalt', 'Produced': '1989', 'Mass': '12.1kg (27lb) unloaded (with optical sight) 18.8kg (41lb) loaded (ready to fire)', 'Length': '1m (3ft 3in) (disassembled for transportation)1.85m (6ft 1in) (ready to fire)', 'Cartridge': 'PG-29V tandem rocketTBG-29V thermobaric rounds', 'Caliber': '105mm (4.1in) barrel 65 and 105mm (2.6 and 4.1in) warheads', 'Muzzlevelocity': '280m/s (920ft/s)', 'Effectivefiringrange': '500m (1,600ft)800m (2,600ft) (with tripod and fire control unit)', 'Sights': 'Iron, optical, and night sights available with ranges up to 450m (1,480ft); automated day and day-night sights with laser rangefinder', 'Blastyield': '750mm (30in) RHA650mm (26in) RHA after ERA1,500mm (59in) Reinforced concrete 3,700mm (150in) Log and earth fortification'}}} (scraper.py:257)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6>
{'keyword': '装甲救护车', 'source': 'wiki', 'title': '装甲车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6', 'date': ' ', 'content': '装甲车辆是具有装甲防护的各种车辆的统称。坦克和自走炮也是广义的重型装甲车辆，但是在习惯上通常因作战用途另外独立分类，而装甲车辆多半是指防护力与火力较坦克弱的车种，而自行炮在原则上不一定要有装甲。装甲车的特性为具有高度的越野机动性能，有一定的防护和火力，分为履带式和轮式两种。一般军用装甲车会装备一至三门中小口径火炮及数挺机枪，一些还装有反坦克导弹，结构以装甲车体、武器系统、动力装置等组成。为了增强防护和方便成员下车战斗。大多数军用装甲车辆可以在水上行驶，可以执行运输、侦察、指挥、救护、伴随、支援坦克及步兵作战等多种任务，还有执行专门任务的装甲车辆，如装甲回收车、装甲指挥车、装甲扫雷车、装甲架桥车等。在警用领域多用于镇压暴乱等问题。步兵战车和装甲输送车作用相近，都是运送步兵机动作战用的装甲车辆，两者不同的地方是步兵战车的防护力较好，火力较大，能够让步兵乘车作战，本身也能够伴随下车作战的步兵，提供火力支援速度较好，装甲输送车则更接近于有装甲的运输车辆。装甲输送车为在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。装甲侦察车指装有侦察设备的装甲车辆，速度较快但装甲比其它装甲车辆要薄，多用于战场侦察，一般可分为轮式和履带式两种。较著名的装甲侦察车，有德国的狐式轻型装甲侦察车、山猫装甲侦察车，法国的雷诺VBC90轮式侦察车（英语：VBC-90）等等。装甲指挥车是具有装甲保护的移动指挥站，提供指挥官与支援的参谋和其他人员协调部队的相关事宜。装甲指挥车是早期以卡车或者是拖车为基础的移动指挥所衍生出来的架构，用意在于提供指挥单位快速移动，持续掌握情势与下达命令命且提供一些保护。大部分的装甲指挥车是从装甲输送车改装而成，扩大内部的空间以容纳额外的人员，通讯器材与其他设备。在到达预定指挥地点之后，部分装甲指挥车还有另外设置的顶蓬可以伸出车外，进一步的扩大人员使用的空间。装甲通信车是指装有通信设备的装甲车辆，常见的设计有两种型态，一种是将通信装备与装甲指挥车合并在一起，因此并非单纯的通信车辆。另外一种是做为地面通信的活动中转站，以延伸无线电通信的有效距离，或者是克服地形对通信的遮蔽效应，强化地面单位之间的联络与资讯交换。目前各国陆军很少装备单纯的装甲通信车，不过有不少国家配备由一般运输车辆改装的通信车辆来支援地面部队的通信需求。装甲救护车，指在战场环境下实行人员救护的装甲车辆，一般只装备一至两挺机枪作为自卫武器，防护力亦很弱。主要用于抢救人员，并将重伤员运送至后方。装甲扫雷车特指装有清除地雷装置的装甲车辆，以协助地面部队扩速通过地雷区。装甲扫雷车可以是专门设计用来清除地雷，或者是将清除工具附加在一般用途的坦 克底盘上，无论是车轮或是履带型态的扫雷车都可见于不同国家的部队当中。装甲扫雷车并非用于清除整个被发现的地雷区，而是将地雷区清理出一至数条的安全通道，提供地面部队人员和车辆安全通过。排除的地雷可能在过程中加以引爆，或者是移动到安全的地方之后另外加以处理。由于清理的过程当中，扫雷车可能碰触或者是引爆其他尚未发现的地雷或者是爆裂物，车辆本身对于底盘和车辆底部的保护需要特别加强，以免被地雷或者是爆裂物瘫痪而无法完成清除的任务。装甲架桥车指装有车桥及其架设、撤收装置的装甲车辆，主要用于快速架设桥梁，令部队迅速通过河流，普遍装备于工兵部队。装甲架桥车可由一般坦克或自走炮底盘改装而成，部分会保留机枪作防卫用途。步兵坦 克和装甲输送车 - 当示威活动和抗争会转变成失控的暴乱或群众暴力时，警方有时会出动警用装甲车控制场面。一般具有水炮功能，而车窗经特别制造，不易打碎。各地警方大多都有装甲车，以防范暴乱发生。保安公司常用，用来运载现金或其他贵重物品，又称“解款车”或“运钞车”。另外政要及富豪也会使用经过改装、具有防弹甚至抗炸能力的汽车。', 'attributes': {'装甲车': {}}} (scraper.py:257)
[2022-03-10 01:55:50] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:55:50] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1532,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 64404,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 3.186608,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 55, 50, 335801),
 'httpcompression/response_bytes': 250470,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 36,
 'log_count/INFO': 46,
 'memusage/max': 67268608,
 'memusage/startup': 67268608,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 55, 47, 149193)} (statscollectors.py:47)
[2022-03-10 01:55:50] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Rampart_(fortification)> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E6%B5%B7%E8%BB%8D%E6%B5%B7%E6%B4%8B%E7%9B%A3%E5%81%B5%E6%8C%87%E6%8F%AE%E9%83%A8> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Palanka_(fortification)> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Songyue_Pagoda> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Defensive_wall> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Serpent%27s_Wall> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Fortification> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4>
{'keyword': '澎湖机场', 'source': 'wiki', 'title': '澎湖机场', 'url': 'https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4', 'date': ' ', 'content': "澎湖机场（闽南语白话字：.mw-parser-output .IPA{font-family:'Charis SIL','Doulos SIL','Linux Libertine','Segoe UI','Lucida Sans Unicode','Code2000','Gentium','Gentium Alternative','TITUS Cyberbit Basic','Arial Unicode MS','IPAPANNEW','Chrysanthi Unicode','GentiumAlt','Bitstream Vera','Bitstream Cyberbit','Hiragino Kaku Gothic Pro','Lucida Grande',sans-serif;text-decoration:none!important}.mw-parser-output .IPA a:link,.mw-parser-output .IPA a:visited{text-decoration:none!important}Phîⁿ-ô͘/Phêⁿ-ô͘ Ki-tiû；IATA代码：MZG；ICAO代码：RCQC），是一座位于台湾澎湖县湖西乡隘门村的军民合用机场，为该县主要联外机场，旧名“马公机场”。民用部分由交通部民用航空局马公航空站[注 1]管理及营运；军用部分为空军马公基地。由立荣航空、华信航空、德安航空营运台北松山、台中、台南、嘉义、高雄、金门及七美共7条航线，主要以ATR72-600、A321-200、DHC6-400等机型执飞。2019冠状病毒病疫情爆发，国际线需求下降，但离岛航线需求大增，华信航空部分航班由台湾虎航A320-200营运。", 'attributes': {'澎湖机场': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/ROCAF_F-5A_in_Makung_AB_1974.jpg/250px-ROCAF_F-5A_in_Makung_AB_1974.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Magong_Airport.jpg/150px-Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png/80px-%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png', 'https://upload.wikimedia.org/wikipedia/commons/7/7d/Aerial_view_of_Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Taiwan_location_map.svg/250px-Taiwan_location_map.svg.png'], '机场类型': '军民合用', '营运者': '军用： 中华民国空军民用： 交通部民用航空局', '服务城市': '澎湖县', '地理位置': '中华民国（台湾）澎湖县湖西乡隘门村126-5号', '启用日期': '军用：1937年民用：1977年8月1日(1977-08-01)', '海拔高度': '103英尺（31米）', '坐标': '23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833坐标：23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833', '网址': 'www.mkport.gov.tw', '方向': ';;;方向;;长度;;表面;;;米;;英尺;;;02/20;;3,000;;9,843;;混凝土;;', '客运量': '客运量2,320,249 人次货运量6,060.863 公吨起降架次35,682 次', '繁体字': ' 澎湖機場 ', '简化字': ' 澎湖机场 ', '标音': "标音官话-汉语拼音 Péng hú Háng kōng zhàn -威妥玛拼音 Pʻêng2 hu2 hang2 k'ung chan4 -耶鲁拼音 Péng hú háng kūng jàn -注音符号ㄆㄥˊ ㄏㄨˊ ㄏㄤˊ ㄎㄨㄥ ㄓㄢˋ闽语-闽南语白话字 Phîⁿ-ô͘/Phêⁿ-ô͘  hái-khang-chām -台罗拼音 Phînn-ôo/Phênn-ôo hâng-khong-tsām 客家话-客家话拼音 Pang2 fu2 hong2 kung1 zam4 -客语白话字 Phàng-fù hòng-khûng chham ", '汉语': '澎湖航空站'}}} (scraper.py:257)
[2022-03-10 01:55:50] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:55:50] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1586,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 41249,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 3.366432,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 55, 50, 550578),
 'httpcompression/response_bytes': 151062,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 44,
 'log_count/INFO': 21,
 'memusage/max': 67907584,
 'memusage/startup': 67907584,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 55, 47, 184146)} (statscollectors.py:47)
[2022-03-10 01:55:50] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BE%93%E9%80%81%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Earth_structure> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Rampart_(fortification)>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Rampart (fortification)', 'url': 'https://en.wikipedia.org/wiki/Rampart_(fortification)', 'date': 202107210138, 'content': "In fortification architecture, a rampart  is a length of bank or wall forming part of the defensive boundary of a castle, hillfort, settlement or other fortified site. It is usually broad-topped and made of excavated earth and/or masonry.[1][2]Many types of early fortification, from prehistory through to the Early Middle Ages, employed earth ramparts usually in combination with external ditches to defend the outer perimeter of a fortified site or settlement.[2] Hillforts, ringforts or 'raths' and ringworks all made use of ditch and rampart defences, and they are the characteristic feature of circular ramparts. The ramparts could be reinforced and raised in height by the use of palisades. This type of arrangement was a feature of the motte and bailey castle of northern Europe in the early medieval period.The composition and design of ramparts varied from the simple mounds of earth and stone, known as dump ramparts, to more complex earth and timber defences (box ramparts and timberlaced ramparts), as well as ramparts with stone revetments.[2] One particular type, common in Central Europe, used earth, stone and timber posts to form a Pfostenschlitzmauer or 'post-slot wall'. Vitrified ramparts were composed of stone that was subsequently fired, possibly to increase its strength.[2]During the classical era, societies became sophisticated enough to create tall ramparts of stone or brick, provided with a platform or wall walk for the defenders to hurl missiles from and a parapet to protect them from the missiles thrown by attackers. Well known examples of classical stone ramparts include Hadrian's Wall and the Walls of Constantinople.After the fall of the Roman Empire in Europe, there was a return to the widespread use of earthwork ramparts which lasted well into the 11th century, an example is the Norman motte and bailey castle. As castle technology evolved during the Middle Ages and Early Modern times, ramparts continued to form part of the defences, but now they tended to consist of thick walls with crenellated parapets.[3] Fieldworks, however, continued to make use of earth ramparts due to their relatively temporary nature.In response to the introduction of artillery, castle ramparts began to be built with much thicker walling and a lower profile, one of earliest examples first being Ravenscraig Castle in Scotland which was built in 1460.[5] In the first half of the 16th century, the solid masonry walls began to be replaced by earthen banks, sometimes faced with stone, which were better able to withstand the impact of shot; the earth being obtained from the ditch which was dug in front of the rampart. At the same time, the plan or 'trace' of these ramparts began to be formed into angular projections called bastions which allowed the guns mounted on them to create zones of interlocking fire.[6] This bastion system became known as the trace italienne because Italian engineers had been at the forefront of its development, although it was later perfected in northern Europe by engineers such as Coehoorn and Vauban and was the dominant style of fortification until the mid-19th century.As well as the immediate archaeological significance of such ramparts in indicating the development of military tactics and technology, these sites often enclose areas of historical significance that point to the local conditions at the time the fortress was built.[2]", 'attributes': {'Rampart (fortification)': {}}} (scraper.py:257)
[2022-03-10 01:55:50] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E6%B5%B7%E8%BB%8D%E6%B5%B7%E6%B4%8B%E7%9B%A3%E5%81%B5%E6%8C%87%E6%8F%AE%E9%83%A8>
{'keyword': '西屿雷达站', 'source': 'wiki', 'title': '中华民国海军海洋监侦指挥部', 'url': 'https://zh.wikipedia.org/wiki/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E6%B5%B7%E8%BB%8D%E6%B5%B7%E6%B4%8B%E7%9B%A3%E5%81%B5%E6%8C%87%E6%8F%AE%E9%83%A8', 'date': ' ', 'content': '海军海洋监侦指挥部为中华民国海军岸置地对海雷达部队。', 'attributes': {'中华民国海军海洋监侦指挥部': {'存在时期': '1965年至今', '国家或地区': '中华民国', '效忠于': '中华民国', '军种': ' 中华民国海军', '种类': '雷达部队', '规模': '指挥部', '隶属于': '海军舰队指挥部', '装备': '机动雷达车、维星车、电战车、机动诱标车', '别称': '海侦部', 'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/ROCN_Rear_Admiral%27s_Flag.svg/25px-ROCN_Rear_Admiral%27s_Flag.svg.png']}}} (scraper.py:257)
[2022-03-10 01:55:51] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Palanka_(fortification)>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Palanka (fortification)', 'url': 'https://en.wikipedia.org/wiki/Palanka_(fortification)', 'date': 202107252158, 'content': "A palanka (Turkish pronunciation:\xa0[paˈɫaŋka]), also known as parkan in Southern Hungary and palanga,[3][4] was a wooden fortification used by the Ottoman Empire extensively in certain regions of Southeast Europe, including Hungary, the Balkans and the Black Sea coast against rival states, especially the Archduchy of Austria and the Kingdom of Hungary.[5][6] Such wooden forts could be built and expanded quickly, and usually contained a small garrison. These fortifications varied in size and shape but were primarily constructed of palisades. Palankas could be adjacent to a town[7] and later they could be replaced by a more formidable stone fortress as in the case of Uyvar.[8] Palankas could also be built as an extension of the main fortress.[9] Many Ottoman forts were a mixture of palanka type fortifications and stonework.[10] Evliya Çelebi describes the word palanka also as a technique of timber masonry.[1][9]Some palankas developed into larger settlements and word palanga has been also used to describe rural settlements which originates from palankas in Erzincan, Eastern Anatolia.[6]The word comes from Hungarian 'palánkvár' which itself comes from Middle Latin 'palanca' meaning log which is derived from Ancient Greek 'phálanks' or 'phalang' (φάλανξ, φαλαγγ) also meaning log.[11]Typical palanka had a rectangular plan and its entrance could be guarded by a watchtower called ağaçtan lonca köşkü. Walls of a palanka could be made of a single palisade as well as two rows of stockade, creating a gap in between which is filled with earth which might be acquired from the ditch dug around the fortification, called şarampa, thus creating a protected walkway.[7][1] The inner and outer palisades were held together by transverse beams, whose ends were fixed to the outer walls by wooden pins, to counter the pressure of earth filling.[10] In order to increase resistance against cannon fire, wooden walls could be strengthened by applying mortar in a technique called horasani palanka.[2] After that, military buildings such as bastions which cannons are placed, towers, barracks and civilian buildings such as inns, marketplaces, mosques, cisterns could be added. Lastly, a stockade could be constructed around the palanka as a secondary fortification.[5][1]Palankas were the basis of Ottoman frontier defence system in Europe[5] and their purpose was to protect military and riverine routes, which had strategic value, and travellers, who were passing through these routes, against plunderers. These routes connected palankas, thus leading to creation of a defense network.[1] They also allowed effective communication between strategic areas.[12] When Ottoman reached the limit of their conquests in Europe, they used these structures to stabilize the frontier.[4]Although palankas were not indestructible on their own, they were interconnected structures, and if an army too strong to resist attacked, the forces of the other palankas would come to their aid.[5] Wooden walls of palankas were difficult to ignite since they were filled with earth; and stakes used to build them were damp.[7] Most of the troops in palankas were azaps[13] and a palanka functioning in the frontier could have a higher ratio of cavalry troops compared to a fortress defended by cannons.[14]Palankas showed similarities to Roman limes system. In the pre-Ottoman period, there used to be fortifications, where palankas were constructed, and after the conquests these fortifications were rebuilt with remarkable Ottoman characteristics. Due to their makeshift aspect few palankas survive today but researches show that this kind of structures were used between 14th and late 19th century.[12]Havale, which is the fortification that palanka was inspired, acted as a base for troops and artillery during sieges of early Ottoman era. 15th century Ottoman historian Aşıkpaşazade mentions that this kind of fortresses were built during the Siege of Bursa (1326). Havale type forts were also built during the Siege of Sivrihisar in Karaman, and in Giurgiu during the campaign to Hungary (1435–36) by Murad II.[1]Palanka ÁdonyPalanka BaranyavarPalanka PaksPalanka Szeksard", 'attributes': {'Palanka (fortification)': {}}} (scraper.py:257)
[2022-03-10 01:55:51] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Songyue_Pagoda>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Songyue Pagoda', 'url': 'https://en.wikipedia.org/wiki/Songyue_Pagoda', 'date': 202104171423, 'content': "The Songyue Pagoda (Chinese: 嵩岳寺塔; pinyin: Sōngyuè sìtǎ), constructed in AD 523, is located at the Songyue Monastery on Mount Song, in Henan province, China.[1] Built during the Northern Wei Dynasty, this pagoda is one of the few intact sixth-century pagodas in China and is also the earliest known Chinese brick pagoda.[1] Most structures from that period were made of wood and have not survived, although ruins of rammed earth fortifications still exist.[2][3] In 2010, the Pagoda was inscribed on the UNESCO World Heritage List along with other nearby monuments as part of the 'Historic Monuments of Dengfeng in “The Centre of Heaven and Earth”' site. [4]The spread of Buddhism dramatically influenced Chinese architecture. By the sixth century, Buddhism had spread with tremendous momentum throughout China: Chinese culture was adjusting and adapting its traditions to include Buddhism worship.[2] The Chinese transformed the rounded earthen mound of the South Asian stupa into the towering pagoda to house the sacred buried relics of Buddha at its core.[2][3][5]The pagoda has had a changing shape over time from its Indian Buddhist origins to its form in China.  The unique many-sided shape of the Songyue Pagoda suggests that it represents an early attempt to merge the Chinese architecture of straight edges with the circular style of Buddhism from the Indian subcontinent. The perimeter of the pagoda decreases as it rises, as this is seen in Indian and Central Asian Buddhist cave temple pillars and the later round pagodas in China.[2]The Songyue Pagoda is unique in form, being twelve-sided. The tower is 40\xa0m (131\xa0ft) high and built of yellowish brick held together with clay mortar.[6] It is the oldest surviving pagoda and was built at a time when, according to records, almost all pagodas were composed of wood.[3][5]The pagoda has a low, plain brick pedestal or base,  and a very high first story characteristic of pagodas with  multiple eaves, with balconies dividing the first story into two layers and doors connecting the two parts. The   ornamented arch doors and decorative apses or niches are intricately carved into teapots or lions. At the base of the door pillars are carvings shaped as lotus flowers and the  pillar capitals have carved  pearls and lotus flowers. After the first story there are fifteen  closely spaced roofs lined with eaves and  small lattice windows. The pagoda features densely clustered ornamental bracked eaves in the dougong style ornamenting each story. Inside the pagoda,  the wall is cylindrical with eight levels of projecting stone supports for what was probably  wooden flooring originally.[3] Beneath the pagoda is an underground series of   burial rooms to preserve  cultural objects buried with the dead. The inner most chamber contained Buddhist relics, transcripts of Buddhist scriptures and statues of Buddha.[7]", 'attributes': {'Songyue Pagoda': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Pagoda_of_Songyue_Temple%2C_2015-09-25_08.jpg/220px-Pagoda_of_Songyue_Temple%2C_2015-09-25_08.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Pagoda_of_Songyue_Temple%2C_2015-09-25_20.jpg/220px-Pagoda_of_Songyue_Temple%2C_2015-09-25_20.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1d/Map_Henan_adm.png/240px-Map_Henan_adm.png'], 'Affiliation': 'Buddhism', 'Country': 'Dengfeng, Zhengzhou, Henan', 'Geographic coordinates': '34°30′06″N 113°00′57″E\ufeff / \ufeff34.50167°N 113.01583°E\ufeff / 34.50167; 113.01583Coordinates: 34°30′06″N 113°00′57″E\ufeff / \ufeff34.50167°N 113.01583°E\ufeff / 34.50167; 113.01583'}}} (scraper.py:257)
[2022-03-10 01:55:51] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Defensive_wall>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Defensive wall', 'url': 'https://en.wikipedia.org/wiki/Defensive_wall', 'date': 202203010418, 'content': "A defensive wall is a fortification usually used to protect a city, town or other settlement from potential aggressors. The walls can range from simple palisades or earthworks to extensive military fortifications with towers, bastions and gates for access to the city.[1] From ancient to modern times, they were used to enclose settlements. Generally, these are referred to as city walls or town walls, although there were also walls, such as the Great Wall of China, Walls of Benin, Hadrian's Wall, Anastasian Wall, and the Atlantic Wall, which extended far beyond the borders of a city and were used to enclose regions or mark territorial boundaries. In mountainous terrain, defensive walls such as letzis were used in combination with castles to seal valleys from potential attack. Beyond their defensive utility, many walls also had important symbolic functions\xa0–  representing the status and independence of the communities they embraced.Existing ancient walls are almost always masonry structures, although brick and timber-built variants are also known. Depending on the topography of the area surrounding the city or the settlement the wall is intended to protect, elements of the terrain such as rivers or coastlines may be incorporated in order to make the wall more effective.Walls may only be crossed by entering the appropriate city gate and are often supplemented with towers. The practice of building these massive walls, though having its origins in prehistory, was refined during the rise of city-states, and energetic wall-building continued into the medieval period and beyond in certain parts of Europe.Simpler defensive walls of earth or stone, thrown up around hillforts, ringworks, early castles and the like, tend to be referred to as ramparts or banks.From very early history to modern times, walls have been a near necessity for every city. Uruk in ancient Sumer (Mesopotamia) is one of the world's oldest known walled cities. Before that, the proto-city of Jericho in the West Bank had a wall surrounding it as early as the 8th millennium\xa0BC. The earliest known town wall in Europe is of Solnitsata, built in the 6th or 5th millennium BC.The Assyrians deployed large labour forces to build new palaces, temples and defensive walls.[2]Babylon was one of the most famous cities of the ancient world, especially as a result of the building program of Nebuchadnezzar, who expanded the walls and built the Ishtar Gate.The Persians built defensive walls to protect their territories, notably the Derbent Wall and the Great Wall of Gorgan built on the either sides of the Caspian Sea against nomadic nations.Some settlements in the Indus Valley Civilization were also fortified. By about 3500\xa0BC, hundreds of small farming villages dotted the Indus floodplain. Many of these settlements had fortifications and planned streets. The stone and mud brick houses of Kot Diji were clustered behind massive stone flood dykes and defensive walls, for neighboring communities quarreled constantly about the control of prime agricultural land.[3] Mundigak (c. 2500\xa0BC) in present-day south-east Afghanistan has defensive walls and square bastions of sun dried bricks.[4]Large rammed earth walls were built in ancient China since the Shang Dynasty (c. 1600–1050\xa0BC), as the capital at ancient Ao had enormous walls built in this fashion (see siege for more info). Although stone walls were built in China during the Warring States (481–221\xa0BC), mass conversion to stone architecture did not begin in earnest until the Tang Dynasty (618–907\xa0 AD). Sections of the Great Wall had been built prior to the Qin Dynasty (221–207\xa0BC) and subsequently connected and fortified during the Qin dynasty, although its present form was mostly an engineering feat and remodeling of the Ming Dynasty (1368–1644\xa0AD). The large walls of Pingyao serve as one example. Likewise, the walls of the Forbidden City in Beijing were established in the early 15th century by the Yongle Emperor. According to Tonio Andrade, the immense thickness of Chinese city walls prevented larger cannons from being developed, since even industrial era artillery had trouble breaching Chinese walls.[5][6]In ancient Greece, large stone walls had been built in Mycenaean Greece, such as the ancient site of Mycenae (famous for the huge stone blocks of its 'cyclopean' walls). In classical era Greece, the city of Athens built a long set of parallel stone walls called the Long Walls that reached their guarded seaport at Piraeus. Exceptions were few, but neither ancient Sparta nor ancient Rome had walls for a long time, choosing to rely on their militaries for defense instead. Initially, these fortifications were simple constructions of wood and earth, which were later replaced by mixed constructions of stones piled on top of each other without mortar.The Romans fortified their cities with massive, mortar-bound stone walls. Among these are the largely extant Aurelian Walls of Rome and the Theodosian Walls of Constantinople, together with partial remains elsewhere. These are mostly city gates, like the Porta Nigra in Trier or Newport Arch in Lincoln.In Central Europe, the Celts built large fortified settlements which the Romans called oppida, whose walls seem partially influenced by those built in the Mediterranean. The fortifications were continuously expanded and improved.Apart from these, the early Middle Ages also saw the creation of some towns built around castles. These cities were only rarely protected by simple stone walls and more usually by a combination of both walls and ditches. From the 12th century AD hundreds of settlements of all sizes were founded all across Europe, which very often obtained the right of fortification soon afterwards.The founding of urban centers was an important means of territorial expansion and many cities, especially in central and eastern Europe, were founded for this purpose during the period of Eastern settlement. These cities are easy to recognise due to their regular layout and large market spaces. The fortifications of these settlements were continuously improved to reflect the current level of military development.While gunpowder and cannons were invented in China, China never developed wall breaking artillery to the same extent as other parts of the world. Part of the reason is probably because Chinese walls were already highly resistant to artillery and discouraged increasing the size of cannons.[7] In the mid-twentieth century a European expert in fortification commented on their immensity: 'in China … the principal towns are surrounded to the present day by walls so substantial, lofty, and formidable that the medieval fortifications of Europe are puny in comparison.'[7] Chinese walls were thick. The eastern wall of Ancient Linzi, established in 859 BC, had a maximum thickness of 43 metres and an average thickness of 20-30 metres.[8] Ming prefectural and provincial capital walls were 10 to 20 metres (33 to 66\xa0ft) thick at the base and 5 to 10 metres (16 to 33\xa0ft) at the top.In Europe the height of wall construction was reached under the Roman Empire, whose walls often reached 10 metres (33\xa0ft) in height, the same as many Chinese city walls, but were only 1.5 to 2.5 metres (4\xa0ft 11\xa0in to 8\xa0ft 2\xa0in) thick. Rome's Servian Walls reached 3.6 and 4 metres (12 and 13\xa0ft) in thickness and 6 to 10 metres (20 to 33\xa0ft) in height. Other fortifications also reached these specifications across the empire, but all these paled in comparison to contemporary Chinese walls, which could reach a thickness of 20 metres (66\xa0ft) at the base in extreme cases. Even the walls of Constantinople which have been described as 'the most famous and complicated system of defence in the civilized world,'[9] could not match up to a major Chinese city wall.[10] Had both the outer and inner walls of Constantinople been combined, they would have only reached roughly a bit more than a third the width of a major wall in China.[10] According to Philo the width of a wall had to be 4.5 metres (15\xa0ft) thick to be able to withstand artillery.[11] European walls of the 1200s and 1300s could reach the Roman equivalents but rarely exceeded them in length, width, and height, remaining around 2 metres (6\xa0ft 7\xa0in) thick. It is apt to note that when referring to a very thick wall in medieval Europe, what is usually meant is a wall of 2.5 metres (8\xa0ft 2\xa0in) in width, which would have been considered thin in a Chinese context.[12] There are some exceptions such as the Hillfort of Otzenhausen, a Celtic ringfort with a thickness of 40 metres (130\xa0ft) in some parts, but Celtic fort-building practices died out in the early medieval period.[13] Andrade goes on to note that the walls of the marketplace of Chang'an were thicker than the walls of major European capitals.[12]Aside from their immense size, Chinese walls were also structurally different from the ones built in medieval Europe. Whereas European walls were mostly constructed of stone interspersed with gravel or rubble filling and bonded by limestone mortar, Chinese walls had tamped earthen cores which absorbed the energy of artillery shots.[14] Walls were constructed using wooden frameworks which were filled with layers of earth tamped down to a highly compact state, and once that was completed the frameworks were removed for use in the next wall section. Starting from the Song dynasty these walls were improved with an outer layer of bricks or stone to prevent corrosion, and during the Ming, earthworks were interspersed with stone and rubble.[14] Most Chinese walls were also sloped rather than vertical to better deflect projectile energy.[15]The defensive response to cannon in Europe was to build relatively low and thick walls of packed earth, which could both withstand the force of cannon balls and support their own, defensive cannon. Chinese wall-building practice was, by happenstance, extremely resistant to all forms of battering. This held true into the twentieth century, when even modern explosive shells had some difficulty in breaking through tamped earth walls.[5]The Chinese Wall Theory essentially rests on a cost benefit hypothesis, where the Ming recognized the highly resistant nature of their walls to structural damage, and could not imagine any affordable development of the guns available to them at the time to be capable of breaching said walls. Even as late as the 1490s a Florentine diplomat considered the French claim that 'their artillery is capable of creating a breach in a wall of eight feet in thickness'[16] to be ridiculous and the French 'braggarts by nature'.[16] In fact twentieth century explosive shells had some difficulty creating a breach in tamped earthen walls.[5]We fought our way to Nanking and joined in the attack on the enemy capital in December. It was our unit which stormed the Chunghua Gate. We attacked continuously for about a week, battering the brick and earth walls with artillery, but they never collapsed. The night of December 11, men in my unit breached the wall. The morning came with most of our unit still behind us, but we were beyond the wall. Behind the gate great heaps of sandbags were piled up. We 'cleared them away, removed the lock, and opened the gates, with a great creaking noise. We'd done it! We'd opened the fortress! All the enemy ran away, so we didn't take any fire. The residents too were gone. When we passed beyond the fortress wall we thought we had occupied this city.[17]As a response to gunpowder artillery, European fortifications began displaying architectural principles such as lower and thicker walls in the mid-1400s.[18] Cannon towers were built with artillery rooms where cannons could discharge fire from slits in the walls. However this proved problematic as the slow rate of fire, reverberating concussions, and noxious fumes produced greatly hindered defenders. Gun towers also limited the size and number of cannon placements because the rooms could only be built so big. Notable surviving artillery towers include a seven layer defensive structure built in 1480 at Fougères in Brittany, and a four layer tower built in 1479 at Querfurth in Saxony.[19]The star fort, also known as the bastion fort, trace italienne, or renaissance fortress, was a style of fortification that became popular in Europe during the 16th century. The bastion and star fort was developed in Italy, where the Florentine engineer Giuliano da Sangallo (1445–1516) compiled a comprehensive defensive plan using the geometric bastion and full trace italienne that became widespread in Europe.[20]The main distinguishing features of the star fort were its angle bastions, each placed to support their neighbor with lethal crossfire, covering all angles, making them extremely difficult to engage with and attack. Angle bastions consisted of two faces and two flanks. Artillery positions positioned at the flanks could fire parallel into the opposite bastion's line of fire, thus providing two lines of cover fire against an armed assault on the wall, and preventing mining parties from finding refuge. Meanwhile, artillery positioned on the bastion platform could fire frontally from the two faces, also providing overlapping fire with the opposite bastion.[21] Overlapping mutually supporting defensive fire was the greatest advantage enjoyed by the star fort. As a result, sieges lasted longer and became more difficult affairs. By the 1530s the bastion fort had become the dominant defensive structure in Italy.[22]Outside Europe, the star fort became an 'engine of European expansion,'[18] and acted as a force multiplier so that small European garrisons could hold out against numerically superior forces. Wherever star forts were erected the natives experienced great difficulty in uprooting European invaders.[18]In China, Sun Yuanhua advocated for the construction of angled bastion forts in his Xifashenji so that their cannons could better support each other. The officials Han Yun and Han Lin noted that cannons on square forts could not support each side as well as bastion forts. Their efforts to construct bastion forts and their results were inconclusive. Ma Weicheng built two bastion forts in his home county, which helped fend off a Qing incursion in 1638. By 1641, there were ten bastion forts in the county. Before bastion forts could be spread any further, the Ming dynasty fell in 1644, and they were largely forgotten as the Qing dynasty was on the offensive most of the time and had no use for them.[23]In the wake of city growth and the ensuing change of defensive strategy, focusing more on the defense of forts around cities, many city walls were demolished. Also, the invention of gunpowder rendered walls less effective, as siege cannons could then be used to blast through walls, allowing armies to simply march through. Today, the presence of former city fortifications can often only be deduced from the presence of ditches, ring roads or parks.Furthermore, some street names hint at the presence of fortifications in times past, for example when words such as 'wall' or 'glacis' occur. Wall Street in New York City, itself a metonym for the entire United States financial system, is one example.In the 19th century, less emphasis was placed on preserving the fortifications for the sake of their architectural or historical value\xa0–  on the one hand, complete fortifications were restored (Carcassonne), on the other hand many structures were demolished in an effort to modernize the cities. One exception to this is the 'monument preservation' law by the Bavarian King Ludwig I of Bavaria, which led to the nearly complete preservation of many monuments such as the Rothenburg ob der Tauber, Nördlingen and Dinkelsbühl. The countless small fortified towns in the Franconia region were also preserved as a consequence of this edict.Walls and fortified wall structures were still built in the modern era. They did not, however, have the original purpose of being a structure able to resist a prolonged siege or bombardment. Modern examples of defensive walls include:Additionally, in some countries, different embassies may be grouped together in a single 'embassy district', enclosed by a fortified complex with walls and towers\xa0– this usually occurs in regions where the embassies run a high risk of being target of attacks. An early example of such a compound was the Legation Quarter in Beijing in the late 19th and early 20th centuries.Most of these modern city walls are made of steel and concrete. Vertical concrete plates are put together so as to allow the least space in between them, and are rooted firmly in the ground. The top of the wall is often protruding and beset with barbed wire in order to make climbing them more difficult. These walls are usually built in straight lines and covered by watchtowers at the corners. Double walls with an interstitial 'zone of fire', as the former Berlin Wall had, are now rare.In September 2014, Ukraine announced the construction of the 'European Rampart' alongside its border with Russia to be able to successfully apply for a visa-free movement with the European Union.[25]A view of the Berlin Wall in 1986A 'peace line' in Belfast, Northern IrelandThe fortified wall of a police station in Belfast, Northern IrelandAt its simplest, a defensive wall consists of a wall enclosure and its gates. For the most part, the top of the walls were accessible, with the outside of the walls having tall parapets with embrasures or merlons. North of the Alps, this passageway at the top of the walls occasionally had a roof.In addition to this, many different enhancements were made over the course of the centuries:The defensive towers of west and south European fortifications in the Middle Ages were often very regularly and uniformly constructed (cf. Ávila, Provins), whereas Central European city walls tend to show a variety of different styles. In these cases the gate and wall towers often reach up to considerable heights, and gates equipped with two towers on either side are much rarer. Apart from having a purely military and defensive purpose, towers also played a representative and artistic role in the conception of a fortified complex. The architecture of the city thus competed with that of the castle of the noblemen and city walls were often a manifestation of the pride of a particular city.Urban areas outside the city walls, so-called Vorstädte, were often enclosed by their own set of walls and integrated into the defense of the city. These areas were often inhabited by the poorer population and held the 'noxious trades'. In many cities, a new wall was built once the city had grown outside of the old wall. This can often still be seen in the layout of the city, for example in Nördlingen, and sometimes even a few of the old gate towers are preserved, such as the white tower in Nuremberg. Additional constructions prevented the circumvention of the city, through which many important trade routes passed, thus ensuring that tolls were paid when the caravans passed through the city gates, and that the local market was visited by the trade caravans.Furthermore, additional signaling and observation towers were frequently built outside the city, and were sometimes fortified in a castle-like fashion. The border of the area of influence of the city was often partially or fully defended by elaborate ditches, walls and hedges. The crossing points were usually guarded by gates or gate houses. These defenses were regularly checked by riders, who often also served as the gate keepers. Long stretches of these defenses can still be seen to this day, and even some gates are still intact. To further protect their territory, rich cities also established castles in their area of influence. An example of this practice is the Romanian Bran Castle, which was intended to protect nearby Kronstadt (today's Braşov).The city walls were often connected to the fortifications of hill castles via additional walls. Thus the defenses were made up of city and castle fortifications taken together. Several examples of this are preserved, for example in Germany Hirschhorn on the Neckar, Königsberg and Pappenheim, Franken, Burghausen in Oberbayern and many more.A few castles were more directly incorporated into the defensive strategy of the city (e.g. Nuremberg, Zons, Carcassonne), or the cities were directly outside the castle as a sort of 'pre-castle' (Coucy-le-Chateau, Conwy and others). Larger cities often had multiple stewards\xa0–  for example Augsburg was divided into a Reichstadt and a clerical city. These different parts were often separated by their own fortifications.A defensive wall in Taroudannt, MoroccoDefensive walls around the ancient Egyptian settlement of BuhenCastillo San Cristóbal in San Juan, Puerto Rico, a UNESCO World Heritage SiteDefensive wall in Cartagena, ColombiaPart of the wall in San Francisco de Campeche, a UNESCO World Heritage SitePorte St. Louis, part of Ramparts of Quebec City, the only remaining fortified city walls in North America north of MexicoWall of Hittite Capital Hattusa (reconstruction)Derbent Walls, late Sassanian periodWalls of the Ark of BukharaDerawar Wall located in Bahawalpur, PakistanWalls of Kumbhalgarh FortWalls of the Rohtas FortThe defensive walls of Intramuros, the 'Walled City' of old Manila, PhilippinesLate Han dynasty castle (wubi)Fortress and soldiers training, Tang dynastyPrince of Teng Pavilion, Yuan dynastyOld City of Shanghai with walls and seafront.Top of the Beijing city wallBarbican of Linhai city wallWalled tulou villagesDaorson, Bosnia, built around a prehistoric central fortified settlement or acropolis (existed there cca. 17-16th to the end of the Bronze Age, cca. 9-8th c. BCE), surrounded by cyclopean walls (similar to Mycenae) dated to the 4th c. BCE.[26][27]City walls in Ávila, Spain, a UNESCO World Heritage SiteThe remaining section of city walls in town of Svätý Jur, SlovakiaThe walls of Tallinn, Estonia, a UNESCO World Heritage SiteA city gate with its towers, the defensive walls, and the city ditch from the 13th century in Metz, FranceThe medieval fortress overlooking the city of Ohrid in North MacedoniaNarikala fortress, Tbilisi, GeorgiaBadajoz (Spain).The gate of the Gonio castleLugo's Roman walls, Galicia, Spain, a UNESCO World Heritage Site", 'attributes': {'Defensive wall': {}}} (scraper.py:257)
[2022-03-10 01:55:51] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Serpent%27s_Wall>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': "Serpent's Wall", 'url': 'https://en.wikipedia.org/wiki/Serpent%27s_Wall', 'date': 202201272224, 'content': "Serpent's Wall (Ukrainian: Змієві вали, romanized:\xa0Zmiievi valy is an ancient system of earthen earthworks (valla) located in the middle Dnieper Ukraine (Naddniprianshchyna)[1] that stretch across primarily Kyiv Oblast, Ukraine. They seem to be similar in purpose and character to Trajan's Wall situated to the southwest in Bessarabia. The remaining ancient walls have a total length of 1,000\xa0km and constitute less than 20% of the original wall system.[1]According to a legend, the earthworks are results of ancient events when a mythical hero (bohatyr) Kozmodemian (or Borysohlib) in order to slay gargantuan Dragon (Serpent) harnessed it in a giant plow and furrowed.[1] The Dragon (Serpent) bit the dust and from plowing there were left furrows on both sides of which towered immense chunks of earth that among people were named as Serpent's Wall.[1]The ancient walls were built between the 2nd century BC and 7th century AD, according to carbon dating. There are three theories as to what peoples built the walls: either the Sarmatians against the Scythians, or the Goths of Oium against the Huns, or the Early East Slavs against the nomads of the southern steppes. In Slavic culture, the warlike nomads are often associated with the winged dragon, hence the name.On the right bank of Dnieper between its tributaries Teteriv and Ros the remnants of wall create six lines elongated from west to east.[1] One Serpent's Wall was passed over the left bank of Dnieper and its tributary Sula.[1]The 1974-85 explorations has established that Serpent's Wall is a remnant of wooded earth fortifications built at the end of 10th and the first half of 11th centuries, smaller part in the 12th century, to protect middle Dnieper Ukraine and Kyiv from pechenegs and cumans.[1]Vallums near village of Ivankovychi, Vasylkiv RaionWall near village of IvankovycheThis Ukrainian history-related article is a stub. You can help Wikipedia by expanding it.", 'attributes': {"Serpent's Wall": {}}} (scraper.py:257)
[2022-03-10 01:55:51] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Fortification>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Fortification', 'url': 'https://en.wikipedia.org/wiki/Fortification', 'date': 202202230412, 'content': "A fortification is a military construction or building designed for the defense of territories in warfare, and is also used to establish rule in a region during peacetime. The term is derived from Latin fortis ('strong') and facere ('to make').From very early history to modern times, defensive walls have often been necessary for cities to survive in an ever-changing world of invasion and conquest. Some settlements in the Indus Valley Civilization were the first small cities to be fortified. In ancient Greece, large stone walls had been built in Mycenaean Greece, such as the ancient site of Mycenae (famous for the huge stone blocks of its 'cyclopean' walls). A Greek phrourion was a fortified collection of buildings used as a military garrison, and is the equivalent of the Roman castellum or English fortress. These constructions mainly served the purpose of a watch tower, to guard certain roads, passes, and borders. Though smaller than a real fortress, they acted as a border guard rather than a real strongpoint to watch and maintain the border.The art of setting out a military camp or constructing a fortification traditionally has been called 'castrametation' since the time of the Roman legions. Fortification is usually divided into two branches: permanent fortification and field fortification. There is also an intermediate branch known as semi-permanent fortification. Castles are fortifications which are regarded as being distinct from the generic fort or fortress in that they are a residence of a monarch or noble and command a specific defensive territory.Roman forts and hill forts were the main antecedents of castles in Europe, which emerged in the 9th century in the Carolingian Empire. The Early Middle Ages saw the creation of some towns built around castles.Medieval-style fortifications were largely made obsolete by the arrival of cannons in the 14th century. Fortifications in the age of black powder evolved into much lower structures with greater use of ditches and earth ramparts that would absorb and disperse the energy of cannon fire. Walls exposed to direct cannon fire were very vulnerable, so the walls were sunk into ditches fronted by earth slopes to improve protection.The arrival of explosive shells in the 19th century led to yet another stage in the evolution of fortification. Star forts did not fare well against the effects of high explosive, and the intricate arrangements of bastions, flanking batteries and the carefully constructed lines of fire for the defending cannon could be rapidly disrupted by explosive shells. Steel-and-concrete fortifications were common during the 19th and early 20th centuries. The advances in modern warfare since World War I have made large-scale fortifications obsolete in most situations.Many United States Army installations are known as forts, although they are not always fortified. Indeed, during the pioneering era of North America, many outposts on the frontiers, even non-military outposts, were referred to generically as forts. Larger military installations may be called fortresses; smaller ones were once known as fortalices. The word fortification can also refer to the practice of improving an area's defense with defensive works. City walls are fortifications but are not necessarily called fortresses.The art of setting out a military camp or constructing a fortification traditionally has been called castrametation since the time of the Roman legions. The art/science of laying siege to a fortification and of destroying it is commonly called siegecraft or siege warfare and is formally known as poliorcetics. In some texts this latter term also applies to the art of building a fortification.Fortification is usually divided into two branches: permanent fortification and field fortification. Permanent fortifications are erected at leisure, with all the resources that a state can supply of constructive and mechanical skill, and are built of enduring materials. Field fortifications—for example breastworks—and often known as fieldworks or earthworks, are extemporized by troops in the field, perhaps assisted by such local labour and tools as may be procurable and with materials that do not require much preparation, such as earth, brushwood and light timber, or sandbags (see sangar). An example of field fortification[1] was the construction of Fort Necessity by George Washington in 1754.There is also an intermediate branch known as semi-permanent fortification.[2] This is employed when in the course of a campaign it becomes desirable to protect some locality with the best imitation of permanent defences that can be made in a short time, ample resources and skilled civilian labour being available. An example of this is the construction of Roman forts in England and in other Roman territories where camps were set up with the intention of staying for some time, but not permanently.Castles are fortifications which are regarded as being distinct from the generic fort or fortress in that it describes a residence of a monarch or noble and commands a specific defensive territory. An example of this is the massive medieval castle of Carcassonne.From very early history to modern times, walls have been a necessity for many cities. In Bulgaria, near the town of Provadia a walled fortified settlement today called Solnitsata starting from 4700 BC had a diameter of about 300 feet (100 meters), was home to 350 people living in two-storey houses, and was encircled by a fortified wall. The huge walls around the settlement, which were built very tall and with stone blocks which are 6 feet (2 meters) high and 4.5 feet (1.5 meters) thick, make it one of the earliest walled settlements in Europe[3][4] but it is younger than the walled town of Sesklo in Greece from 6800 BC.[5][6] Uruk in ancient Sumer (Mesopotamia) is one of the world's oldest known walled cities. The Ancient Egyptians also built fortresses on the frontiers of the Nile Valley to protect against invaders from neighbouring territories, as well as circle-shaped mud brick walls around their cities. Many of the fortifications of the ancient world were built with mud brick, often leaving them no more than mounds of dirt for today's archaeologists.A massive prehistoric stone wall surrounded the ancient temple of Ness of Brodgar 3200 BC in Scotland. Named the 'Great Wall of Brodgar' it was four metres thick and four metres tall. The wall had some symbolic or ritualistic function.[7][8] The Assyrians deployed large labour forces to build new palaces, temples and defensive walls.[9]Some settlements in the Indus Valley Civilization were also fortified. By about 3500 BC, hundreds of small farming villages dotted the Indus floodplain. Many of these settlements had fortifications and planned streets. The stone and mud brick houses of Kot Diji were clustered behind massive stone flood dykes and defensive walls, for neighbouring communities bickered constantly about the control of prime agricultural land.[10] Mundigak (c. 2500 BC) in present-day south-east Afghanistan has defensive walls and square bastions of sun dried bricks.[11] The entire city of Kerma in Nubia was encompassed by fortified walls surrounded by a ditch. Archaeology has revealed various Bronze Age bastions and foundations constructed of stone together with either baked or unfired brick.[12] In Bronze Age Malta, some settlements also began to be fortified. The most notable surviving example is Borġ in-Nadur, where a bastion built in around 1500 BC was found. Babylon was one of the most famous cities of the ancient world, especially as a result of the building program of Nebuchadnezzar, who expanded the walls and built the Ishtar Gate. Exceptions were few—notably, ancient Sparta and ancient Rome did not have walls for a long time, choosing to rely on their militaries for defence instead. Initially, these fortifications were simple constructions of wood and earth, which were later replaced by mixed constructions of stones piled on top of each other without mortar. In ancient Greece, large stone walls had been built in Mycenaean Greece, such as the ancient site of Mycenae (famous for the huge stone blocks of its 'cyclopean' walls). In classical era Greece, the city of Athens built two parallel stone walls, called the Long Walls, that reached their fortified seaport at Piraeus a few miles away.In Central Europe, the Celts built large fortified settlements known as oppida, whose walls seem partially influenced by those built in the Mediterranean. The fortifications were continuously being expanded and improved. Around 600 BC, in Heuneburg, Germany, forts were constructed with a limestone foundation supported by a mudbrick wall approximately 4 metres tall, probably topped by a roofed walkway, thus reaching a total height of 6 metres. The wall was clad with lime plaster, regularly renewed. Towers protruded outwards from it.[13][14]The Oppidum of Manching (German: Oppidum von Manching) was a large Celtic proto-urban or city-like settlement at modern-day Manching (near Ingolstadt), Bavaria (Germany). The settlement was founded in the 3rd century BC and existed until c. 50–30 BC. It reached its largest extent during the late La Tène period (late 2nd century BC), when it had a size of 380 hectares. At that time, 5,000 to 10,000 people lived within its 7.2\xa0km long walls. The oppidum of Bibracte is another example of a Gaulish fortified settlement.The Mura aureliane are a line of city walls built between 271 AD and 275 AD in Rome, Italy, during the reign of the Roman Emperors Aurelian and Probus. The walls enclosed all the seven hills of Rome plus the Campus Martius and, on the right bank of the Tiber, the Trastevere district. The river banks within the city limits appear to have been left unfortified, although they were fortified along the Campus Martius. The full circuit ran for 19 kilometres (12\xa0mi) surrounding an area of 13.7 square kilometres (5.3\xa0sq\xa0mi). The walls were constructed in brick-faced concrete, 3.5 metres (11\xa0ft) thick and 8 metres (26\xa0ft) high, with a square tower every 100 Roman feet (29.6 metres (97\xa0ft)). In the 5th century, remodelling doubled the height of the walls to 16 metres (52\xa0ft). By 500 AD, the circuit possessed 383 towers, 7,020 crenellations, 18 main gates, 5 postern gates, 116 latrines, and 2,066 large external windows.[15]The Romans fortified their cities with massive, mortar-bound stone walls. The most famous of these are the largely extant Aurelian Walls of Rome and the Theodosian Walls of Constantinople, together with partial remains elsewhere. These are mostly city gates, like the Porta Nigra in Trier or Newport Arch in Lincoln. Hadrian's Wall was built by the Roman Empire across the width of what is now northern England following a visit by Roman Emperor Hadrian (AD\xa076–138) in AD\xa0122.A number of forts dating from the Later Stone Age to the British Raj may be found in India. 'Fort' is the word used in India for all old fortifications. Numerous Indus Valley Civilization sites exhibit evidences of fortifications. While Dholavira has stone-built fortification walls, Harrapa is fortified using baked bricks; sites such as Kalibangan exhibit mudbrick fortifications with bastions and Lothal has a quadrangular fortified layout. Evidence also suggested of fortifications in Mohenjo-daro. Even a small town – for instance, Kotada Bhadli, exhibiting sophisticated fortification-like bastions – shows that nearly all major and minor towns of the Indus Valley Civilization were fortified.[16] Forts also appeared in urban cities of the Gangetic valley during the second urbanisation period between 600 and 200 BC, and as many as 15 fortification sites have been identified by archaeologists throughout the Gangetic valley, such as Kaushambi, Mahasthangarh, Pataliputra, Mathura, Ahichchhatra, Rajgir, and Lauria Nandangarh. The earliest vedic brick fortification occurs in one of the stupa mounds of Lauria Nandangarh, which is 1.6\xa0km in perimeter and oval in plan and encloses a habitation area.[17] India currently has over 180 forts, with the state of Maharashtra alone having over 70 forts, which are also known as durg,[18][19][20] many of them built by Shivaji, founder of the Maratha state. A large majority of forts in India are in North India. The most notable forts are the Red Fort at Delhi, the Red Fort at Agra, the Chittor Fort and Mehrangarh Fort in Rajasthan, the Ranthambhor Fort, Amer Fort and Jaisalmer Fort also in Rajasthan and Gwalior Fort in Madhya Pradesh.[19]Large tempered earth (i.e. rammed earth) walls were built in ancient China since the Shang dynasty (c. 1600–1050 BC); the capital at ancient Ao had enormous walls built in this fashion (see siege for more info). Although stone walls were built in China during the Warring States (481–221 BC), mass conversion to stone architecture did not begin in earnest until the Tang dynasty (618–907 AD). The Great Wall of China had been built since the Qin dynasty (221–207 BC), although its present form was mostly an engineering feat and remodelling of the Ming dynasty (1368–1644 AD).In addition to the Great Wall, a number of Chinese cities also employed the use of defensive walls to defend their cities. Notable Chinese city walls include the city walls of Hangzhou, Nanjing, the Old City of Shanghai, Suzhou, Xi'an and the walled villages of Hong Kong. The famous walls of the Forbidden City in Beijing were established in the early 15th century by the Yongle Emperor. The Forbidden City made up the inner portion of the Beijing city fortifications.During the Spanish Era several forts and outposts were built throughout the archipelago. Most notable is Intramuros, the old walled city of Manila located along the southern bank of the Pasig River.[21] The historic city was home to centuries-old churches, schools, convents, government buildings and residences, the best collection of Spanish colonial architecture before much of it was destroyed by the bombs of World War II. Of all the buildings within the 67-acre city, only one building, the San Agustin Church, survived the war.Partial listing of Spanish forts:The Ivatan people of the northern islands of Batanes built their so-called idjang on hills and elevated areas[22] to protect themselves during times of war. These fortifications were likened to European castles because of their purpose. Usually, the only entrance to the castles would be via a rope ladder that would only be lowered for the villagers and could be kept away when invaders arrived.The Igorots built forts made of stone walls that averaged several meters in width and about two to three times the width in height around 2000 BC.[23]The Muslim Filipinos of the south built strong fortresses called kota or moong to protect their communities. Usually, many of the occupants of these kotas are entire families rather than just warriors. Lords often had their own kotas to assert their right to rule, it served not only as a military installation but as a palace for the local Lord. It is said that at the height of the Maguindanao Sultanate's power, they blanketed the areas around Western Mindanao with Kotas and other fortifications to block the Spanish advance into the region. These kotas were usually made of stone and bamboo or other light materials and surrounded by trench networks. As a result, some of these kotas were burned easily of destroyed. With further Spanish campaigns in the region, the Sultanate was subdued and majority of Kotas dismantled or destroyed. Kotas were not only used by the Muslims as defense against Spaniards and other foreigners, renegades and rebels also built fortifications in defiance of other chiefs in the area.[24] During the American occupation, rebels built strongholds and the Datus, Rajahs or Sultans often built and reinforced their kotas in a desperate bid to maintain rule over their subjects and their land.[25] Many of these forts were also destroyed by American expeditions, as a result, very very few kotas still stand to this day.Notable Kotas:During Muhammad's era in Arabia, many tribes made use of fortifications. In the Battle of the Trench, the largely outnumbered defenders of Medina, mainly Muslims led by Islamic prophet Muhammad, dug a trench, which together with Medina's natural fortifications, rendered the confederate cavalry (consisting of horses and camels) useless, locking the two sides in a stalemate. Hoping to make several attacks at once, the confederates persuaded the Medina-allied Banu Qurayza to attack the city from the south. However, Muhammad's diplomacy derailed the negotiations, and broke up the confederacy against him. The well-organized defenders, the sinking of confederate morale, and poor weather conditions caused the siege to end in a fiasco.[27]During the Siege of Ta'if in January 630,[28] Muhammad ordered his followers to attack enemies who fled from the Battle of Hunayn and sought refuge in the fortress of Taif.[29]The walls of Benin are described as the world's second longest man-made structure, as well as the most extensive earthwork in the world, by the Guinness Book of Records, 1974.[30][31] The walls may have been constructed between the thirteenth and mid-fifteenth century CE[32] or, during the first millennium CE.[32][33]Strong citadels were also built other in areas of Africa. Yorubaland for example had several sites surrounded by the full range of earthworks and ramparts seen elsewhere, and sited on ground. This improved defensive potential- such as hills and ridges. Yoruba fortifications were often protected with a double wall of trenches and ramparts, and in the Congo forests concealed ditches and paths, along with the main works, often bristled with rows of sharpened stakes. Inner defenses were laid out to blunt an enemy penetration with a maze of defensive walls allowing for entrapment and crossfire on opposing forces.[34]A military tactic of the Ashanti was to create powerful log stockades at key points. This was employed in later wars against the British to block British advances. Some of these fortifications were over a hundred yard long, with heavy parallel tree trunks. They were impervious to destruction by artillery fire. Behind these stockades numerous Ashanti soldiers were mobilized to check enemy movement. While formidable in construction, many of these strongpoints failed because Ashanti guns, gunpowder and bullets were poor, and provided little sustained killing power in defense. Time and time again British troops overcame or bypassed the stockades by mounting old-fashioned bayonet charges, after laying down some covering fire.[35]Defensive works were of importance in the tropical African Kingdoms. In the Kingdom of Kongo field fortifications were characterized by trenches and low earthen embankments. Such strongpoints ironically, sometimes held up much better against European cannon than taller, more imposing structures.[36]Roman forts and hill forts were the main antecedents of castles in Europe, which emerged in the 9th century in the Carolingian Empire. The Early Middle Ages saw the creation of some towns built around castles. These cities were only rarely protected by simple stone walls and more usually by a combination of both walls and ditches. From the 12th century hundreds of settlements of all sizes were founded all across Europe, which very often obtained the right of fortification soon afterwards.The founding of urban centres was an important means of territorial expansion and many cities, especially in eastern Europe, were founded precisely for this purpose during the period of Eastern Colonisation. These cities are easy to recognise due to their regular layout and large market spaces. The fortifications of these settlements were continuously improved to reflect the current level of military development.During the Renaissance era, the Venetian Republic raised great walls around cities, and the finest examples, among others, are in Nicosia (Cyprus), Rocca di Manerba del Garda (Lombardy) and Palmanova (Italy), or Dubrovnik (Croatia), which proved to be futile against attacks but still stand to this day. Unlike Venetians the Ottomans used to built smaller fortifications but in greater numbers, and only rarely fortified entire settlements such as Počitelj, Vratnik and Jajce in Bosnia.Medieval-style fortifications were largely made obsolete by the arrival of cannons on the 14th century battlefield. Fortifications in the age of black powder evolved into much lower structures with greater use of ditches and earth ramparts that would absorb and disperse the energy of cannon fire. Walls exposed to direct cannon fire were very vulnerable, so were sunk into ditches fronted by earth slopes.This placed a heavy emphasis on the geometry of the fortification to allow defensive cannonry interlocking fields of fire to cover all approaches to the lower and thus more vulnerable walls.The evolution of this new style of fortification can be seen in transitional forts such as Sarzanello[37] in North West Italy which was built between 1492 and 1502. Sarzanello consists of both crenellated walls with towers typical of the medieval period but also has a ravelin like angular gun platform screening one of the curtain walls which is protected from flanking fire from the towers of the main part of the fort. Another example are the fortifications of Rhodes which were frozen at 1522 so that Rhodes is the only European walled town that still shows the transition between the classical medieval fortification and the modern ones.[38]Fortifications also extended in depth, with protected batteries for defensive cannonry, to allow them to engage attacking cannon to keep them at a distance and prevent them bearing directly on the vulnerable walls.The result was star shaped fortifications with tier upon tier of hornworks and bastions, of which Fort Bourtange is an excellent example. There are also extensive fortifications from this era in the Nordic states and in Britain, the fortifications of Berwick-upon-Tweed and the harbour archipelago of Suomenlinna at Helsinki being fine examples.The arrival of explosive shells in the 19th century led to yet another stage in the evolution of fortification. Star forts did not fare well against the effects of high explosive and the intricate arrangements of bastions, flanking batteries and the carefully constructed lines of fire for the defending cannon could be rapidly disrupted by explosive shells.Worse, the large open ditches surrounding forts of this type were an integral part of the defensive scheme, as was the covered way at the edge of the counter scarp. The ditch was extremely vulnerable to bombardment with explosive shells.In response, military engineers evolved the polygonal style of fortification. The ditch became deep and vertically sided, cut directly into the native rock or soil, laid out as a series of straight lines creating the central fortified area that gives this style of fortification its name.Wide enough to be an impassable barrier for attacking troops, but narrow enough to be a difficult target for enemy shellfire, the ditch was swept by fire from defensive blockhouses set in the ditch as well as firing positions cut into the outer face of the ditch itself.The profile of the fort became very low indeed, surrounded outside the ditch covered by caponiers by a gently sloping open area so as to eliminate possible cover for enemy forces, while the fort itself provided a minimal target for enemy fire. The entrypoint became a sunken gatehouse in the inner face of the ditch, reached by a curving ramp that gave access to the gate via a rolling bridge that could be withdrawn into the gatehouse.Much of the fort moved underground. Deep passages and tunnels now connected the blockhouses and firing points in the ditch to the fort proper, with magazines and machine rooms deep under the surface. The guns, however, were often mounted in open emplacements and protected only by a parapet; both in order to keep a lower profile and also because experience with guns in closed casemates had seen them put out of action by rubble as their own casemates were collapsed around them.Gone were citadels surrounding towns: forts were to be moved to the outside of the cities some 12\xa0km to keep the enemy at a distance so their artillery could not bombard the city center. From now on a ring of forts were to be built at a spacing that would allow them to effectively cover the intervals between them.The new forts abandoned the principle of the bastion, which had also been made obsolete by advances in arms. The outline was a much simplified polygon, surrounded by a ditch. These forts, built in masonry and shaped stone, were designed to shelter their garrison against bombardment. One organizing feature of the new system involved the construction of two defensive curtains: an outer line of forts, backed by an inner ring or line at critical points of terrain or junctions (see, for example, Séré de Rivières system in France).Traditional fortification however continued to be applied by European armies engaged in warfare in colonies established in Africa against lightly armed attackers from amongst the indigenous population. A relatively small number of defenders in a fort impervious to primitive weaponry could hold out against high odds, the only constraint being the supply of ammunition.Steel-and-concrete fortifications were common during the 19th and early 20th centuries. However the advances in modern warfare since World War I have made large-scale fortifications obsolete in most situations. In the 1930s and 1940s, some fortifications were built with designs taking into consideration the new threat of aerial warfare, for example Fort Campbell in Malta.[39] Despite this, only underground bunkers are still able to provide some protection in modern wars. Many historical fortifications were demolished during the modern age, but a considerable number survive as popular tourist destinations and prominent local landmarks today.The downfall of permanent fortifications had two causes:Instead field fortification rose to dominate defensive action. Unlike the trench warfare which dominated World War I, these defences were more temporary in nature. This was an advantage because since it was less extensive it formed a less obvious target for enemy force to be directed against.If sufficient power were massed against one point to penetrate it, the forces based there could be withdrawn and the line could be re-established relatively quickly. Instead of a supposedly impenetrable defensive line, such fortifications emphasized defence in depth, so that as defenders were forced to pull back or were overrun, the lines of defenders behind them could take over the defence.Because the mobile offensives practised by both sides usually focused on avoiding the strongest points of a defensive line, these defences were usually relatively thin and spread along the length of a line. The defence was usually not equally strong throughout however.The strength of the defensive line in an area varied according to how rapidly an attacking force could progress in the terrain that was being defended—both the terrain the defensive line was built on and the ground behind it that an attacker might hope to break out into. This was both for reasons of the strategic value of the ground, and its defensive value.This was possible because while offensive tactics were focused on mobility, so were defensive tactics. The dug in defences consisted primarily of infantry and antitank guns. Defending tanks and tank destroyers would be concentrated in mobile brigades behind the defensive line. If a major offensive was launched against a point in the line, mobile reinforcements would be sent to reinforce that part of the line that was in danger of failing.Thus the defensive line could be relatively thin because the bulk of the fighting power of the defenders was not concentrated in the line itself but rather in the mobile reserves. A notable exception to this rule was seen in the defensive lines at the Battle of Kursk during World War II, where German forces deliberately attacked into the strongest part of the Soviet defences seeking to crush them utterly.The terrain that was being defended was of primary importance because open terrain that tanks could move over quickly made possible rapid advances into the defenders' rear areas that were very dangerous to the defenders. Thus such terrain had to be defended at all cost.In addition, since in theory the defensive line only had to hold out long enough for mobile reserves to reinforce it, terrain that did not permit rapid advance could be held more weakly because the enemy's advance into it would be slower, giving the defenders more time to reinforce that point in the line. For example, the battle of the Hurtgen Forest in Germany during the closing stages of World War II is an excellent example of how difficult terrain could be used to the defenders' advantage.After World War II, ICBMs capable of reaching much of the way around the world were developed, and so speed became an essential characteristic of the strongest militaries and defenses. Missile silos were developed, so missiles could be fired from the middle of a country and hit cities and targets in another country, and airplanes (and air carriers) became major defenses and offensive weapons (leading to an expansion of the use of airports and airstrips as fortifications). Mobile defenses could be had underwater, too, in the form of nuclear submarines capable of firing missiles. Some bunkers in the mid to late 20th century came to be buried deep inside mountains and prominent rocks, such as Gibraltar and the Cheyenne Mountain Complex. On the ground itself, minefields have been used as hidden defences in modern warfare, often remaining long after the wars that produced them have ended.Demilitarized zones along borders are arguably another type of fortification, although a passive kind, providing a buffer between potentially hostile militaries.Military airfields offer a fixed 'target rich' environment for even relatively small enemy forces, using hit-and-run tactics by ground forces, stand-off attacks (mortars and rockets), air attacks, or ballistic missiles. Key targets – aircraft, munitions, fuel, and vital technical personnel – can be protected by fortifications.Aircraft can be protected by revetments, Hesco barriers, or hardened aircraft shelters which will protect from many types of attack. Larger aircraft types tend to be based outside the operational theatre.Munition storage follows safety rules which use fortifications (bunkers and bunds) to provide protection against accident and chain reactions (sympathetic detonations). Weapons for rearming aircraft can be stored in small fortified expense stores closer to the aircraft. At Bien Hoa South Vietnam on the morning of 16 May 1965, as aircraft were being re-fuelled and armed, a chain reaction explosion destroyed 13 aircraft, killed 34 personnel, and injured over 100; this, along with damage and losses of aircraft to enemy attack (by both infiltration and stand off attacks), led to the construction of revetments and shelters to protect aircraft throughout South Vietnam.Aircrew and ground personnel will need protection during enemy attacks and fortifications range from culvert section 'duck and cover' shelters to permanent air-raid shelters. Soft locations with high personnel densities such as accommodation and messing facilities can have limited protection by placing prefabricated concrete walls or barriers around them, examples of barriers are Jersey Barriers, T Barriers or Splinter Protection Units (SPUs). Older fortification may prove useful such as the old 'Yugo' pyramid shelters built in the 1980s which were used by US personnel on 8 Jan 2020 when Iran fired 11 ballistic missiles at Ayn al-Asad Airbase in Iraq.Fuel is volatile and has to comply with rules for storage which provide protection against accident. Fuel in underground bulk fuel installations is well protected though valves and controls are vulnerable to enemy action. Above ground tanks can be susceptible to attack.Ground support equipment will need to be protected by fortifications to be usable after an enemy attack.Permanent (concrete) guard fortifications are safer, stronger, last longer and are more cost effective than sandbag fortifications. Prefabricated positions can be made from concrete culvert sections. The British Yarnold Bunker is made from sections of a concrete pipe.Guard Towers provide increased field of view but a lower level of protection.Dispersal and camouflage of assets can supplement fortifications against some forms of airfield attack.Just as in colonial periods, comparatively obsolete fortifications are still used for low-intensity conflicts. Such fortifications range in size from small patrol bases or forward operating bases up to huge airbases such as Camp Bastion/Leatherneck in Afghanistan. Much like in the 18th and 19th century, because the enemy is not a powerful military force with the heavy weaponry required to destroy fortifications, walls of gabion, sandbag or even simple mud can provide protection against small arms and anti-tank weapons – although such fortifications are still vulnerable to mortar and artillery fire.Forts in modern American usage often refer to space set aside by governments for a permanent military facility; these often do not have any actual fortifications, and can have specializations (military barracks, administration, medical facilities, or intelligence).However, there are some modern fortifications that are referred to as forts. These are typically small semi permanent fortifications. In urban combat they are built by upgrading existing structures such as houses or public buildings. In field warfare they are often log, sandbag or gabion type construction.Such forts are typically only used in low level conflict, such as counterinsurgency conflicts or very low level conventional conflicts, such as the Indonesia–Malaysia confrontation, which saw the use of log forts for use by forward platoons and companies. The reason for this is that static above ground forts can not survive modern direct or indirect fire weapons larger than mortars, RPGs and small arms.Fortifications designed to keep the inhabitants of a facility in rather than attacker out can also be found, in prisons, concentration camps, and other such facilities, with supermaxes having some of the strongest of those. Those are covered in other articles, as most prisons and concentration camps are not primarily military forts (although forts, camps, and garrison towns have been used as prisons and/or concentration camps; such as Theresienstadt, Guantanamo Bay detention camp and the Tower of London for example).Fort componentsTypes of forts and fortificationFortification and siege warfareNotable experts", 'attributes': {'Fortification': {}}} (scraper.py:257)
[2022-03-10 01:55:51] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:55:51] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1568,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 49199,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 4.698423,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 55, 51, 815626),
 'httpcompression/response_bytes': 199807,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 57,
 'log_count/INFO': 73,
 'memusage/max': 66748416,
 'memusage/startup': 66748416,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 55, 47, 117203)} (statscollectors.py:47)
[2022-03-10 01:55:51] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:55:51] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4>
{'keyword': '马公机场', 'source': 'wiki', 'title': '澎湖机场', 'url': 'https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4', 'date': ' ', 'content': "澎湖机场（闽南语白话字：.mw-parser-output .IPA{font-family:'Charis SIL','Doulos SIL','Linux Libertine','Segoe UI','Lucida Sans Unicode','Code2000','Gentium','Gentium Alternative','TITUS Cyberbit Basic','Arial Unicode MS','IPAPANNEW','Chrysanthi Unicode','GentiumAlt','Bitstream Vera','Bitstream Cyberbit','Hiragino Kaku Gothic Pro','Lucida Grande',sans-serif;text-decoration:none!important}.mw-parser-output .IPA a:link,.mw-parser-output .IPA a:visited{text-decoration:none!important}Phîⁿ-ô͘/Phêⁿ-ô͘ Ki-tiû；IATA代码：MZG；ICAO代码：RCQC），是一座位于台湾澎湖县湖西乡隘门村的军民合用机场，为该县主要联外机场，旧名“马公机场”。民用部分由交通部民用航空局马公航空站[注 1]管理及营运；军用部分为空军马公基地。由立荣航空、华信航空、德安航空营运台北松山、台中、台南、嘉义、高雄、金门及七美共7条航线，主要以ATR72-600、A321-200、DHC6-400等机型执飞。2019冠状病毒病疫情爆发，国际线需求下降，但离岛航线需求大增，华信航空部分航班由台湾虎航A320-200营运。", 'attributes': {'澎湖机场': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/ROCAF_F-5A_in_Makung_AB_1974.jpg/250px-ROCAF_F-5A_in_Makung_AB_1974.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Magong_Airport.jpg/150px-Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png/80px-%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png', 'https://upload.wikimedia.org/wikipedia/commons/7/7d/Aerial_view_of_Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Taiwan_location_map.svg/250px-Taiwan_location_map.svg.png'], '机场类型': '军民合用', '营运者': '军用： 中华民国空军民用： 交通部民用航空局', '服务城市': '澎湖县', '地理位置': '中华民国（台湾）澎湖县湖西乡隘门村126-5号', '启用日期': '军用：1937年民用：1977年8月1日(1977-08-01)', '海拔高度': '103英尺（31米）', '坐标': '23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833坐标：23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833', '网址': 'www.mkport.gov.tw', '方向': ';;;方向;;长度;;表面;;;米;;英尺;;;02/20;;3,000;;9,843;;混凝土;;', '客运量': '客运量2,320,249 人次货运量6,060.863 公吨起降架次35,682 次', '繁体字': ' 澎湖機場 ', '简化字': ' 澎湖机场 ', '标音': "标音官话-汉语拼音 Péng hú Háng kōng zhàn -威妥玛拼音 Pʻêng2 hu2 hang2 k'ung chan4 -耶鲁拼音 Péng hú háng kūng jàn -注音符号ㄆㄥˊ ㄏㄨˊ ㄏㄤˊ ㄎㄨㄥ ㄓㄢˋ闽语-闽南语白话字 Phîⁿ-ô͘/Phêⁿ-ô͘  hái-khang-chām -台罗拼音 Phînn-ôo/Phênn-ôo hâng-khong-tsām 客家话-客家话拼音 Pang2 fu2 hong2 kung1 zam4 -客语白话字 Phàng-fù hòng-khûng chham ", '汉语': '澎湖航空站'}}} (scraper.py:257)
[2022-03-10 01:55:52] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BE%93%E9%80%81%E8%BD%A6>
{'keyword': '装甲防护车', 'source': 'wiki', 'title': '装甲输送车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BE%93%E9%80%81%E8%BD%A6', 'date': ' ', 'content': '装甲输送车（英文：Armoured personnel carrier，缩写：APC）又称装甲运兵车，指在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。在必要时，也可以使用车上的武器攻击敌人。\xa0加拿大：\xa0中华民国 ：\xa0中华人民共和国：\xa0芬兰：\xa0法国：\xa0德国：\xa0以色列：\xa0日本：\xa0俄罗斯：\xa0新加坡：\xa0瑞士：\xa0美国：\xa0乌克兰：\xa0土耳其：装甲输送车出现的时间与战车约略同期，第一次世界大战末期，英国推出专门用来运输步兵的马克IX型坦克。由于坦克本身的成本较当时使用的卡车高出许多，有些国家是以加装装甲的汽车权充兼作运输的用途。1930年代许多国家开始发展机械化部队，由于全履带车的造价与维护成本依旧居高不下，为了配合战车的运动速度与越野能力，半履带车加上防护装甲之后成为最常见的型态。二次世界大战期间，美国的M3半履带车与德国SdKfz 251半履带车是最著名的代表。这些车辆拥有防御小口径武器与弹药破片的侧面装甲，但是欠缺顶部的保护。车体上以携带机枪最为常见。而战争中期以后盟军开始将M4中型坦克改装成装甲输送车使用。到冷战时期，由于核战阴影的威胁、履带动力装置成本下降加上铝合金的使用，装甲输送车开始具备封闭式车身，为了与步兵共同作战而演化出步兵战斗车这类重武装车种。', 'attributes': {'装甲输送车': {}}} (scraper.py:257)
[2022-03-10 01:55:52] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6>
{'keyword': '装甲扫雷车', 'source': 'wiki', 'title': '装甲车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6', 'date': ' ', 'content': '装甲车辆是具有装甲防护的各种车辆的统称。坦克和自走炮也是广义的重型装甲车辆，但是在习惯上通常因作战用途另外独立分类，而装甲车辆多半是指防护力与火力较坦克弱的车种，而自行炮在原则上不一定要有装甲。装甲车的特性为具有高度的越野机动性能，有一定的防护和火力，分为履带式和轮式两种。一般军用装甲车会装备一至三门中小口径火炮及数挺机枪，一些还装有反坦克导弹，结构以装甲车体、武器系统、动力装置等组成。为了增强防护和方便成员下车战斗。大多数军用装甲车辆可以在水上行驶，可以执行运输、侦察、指挥、救护、伴随、支援坦克及步兵作战等多种任务，还有执行专门任务的装甲车辆，如装甲回收车、装甲指挥车、装甲扫雷车、装甲架桥车等。在警用领域多用于镇压暴乱等问题。步兵战车和装甲输送车作用相近，都是运送步兵机动作战用的装甲车辆，两者不同的地方是步兵战车的防护力较好，火力较大，能够让步兵乘车作战，本身也能够伴随下车作战的步兵，提供火力支援速度较好，装甲输送车则更接近于有装甲的运输车辆。装甲输送车为在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。装甲侦察车指装有侦察设备的装甲车辆，速度较快但装甲比其它装甲车辆要薄，多用于战场侦察，一般可分为轮式和履带式两种。较著名的装甲侦察车，有德国的狐式轻型装甲侦察车、山猫装甲侦察车，法国的雷诺VBC90轮式侦察车（英语：VBC-90）等等。装甲指挥车是具有装甲保护的移动指挥站，提供指挥官与支援的参谋和其他人员协调部队的相关事宜。装甲指挥车是早期以卡车或者是拖车为基础的移动指挥所衍生出来的架构，用意在于提供指挥单位快速移动，持续掌握情势与下达命令命且提供一些保护。大部分的装甲指挥车是从装甲输送车改装而成，扩大内部的空间以容纳额外的人员，通讯器材与其他设备。在到达预定指挥地点之后，部分装甲指挥车还有另外设置的顶蓬可以伸出车外，进一步的扩大人员使用的空间。装甲通信车是指装有通信设备的装甲车辆，常见的设计有两种型态，一种是将通信装备与装甲指挥车合并在一起，因此并非单纯的通信车辆。另外一种是做为地面通信的活动中转站，以延伸无线电通信的有效距离，或者是克服地形对通信的遮蔽效应，强化地面单位之间的联络与资讯交换。目前各国陆军很少装备单纯的装甲通信车，不过有不少国家配备由一般运输车辆改装的通信车辆来支援地面部队的通信需求。装甲救护车，指在战场环境下实行人员救护的装甲车辆，一般只装备一至两挺机枪作为自卫武器，防护力亦很弱。主要用于抢救人员，并将重伤员运送至后方。装甲扫雷车特指装有清除地雷装置的装甲车辆，以协助地面部队扩速通过地雷区。装甲扫雷车可以是专门设计用来清除地雷，或者是将清除工具附加在一般用途的坦 克底盘上，无论是车轮或是履带型态的扫雷车都可见于不同国家的部队当中。装甲扫雷车并非用于清除整个被发现的地雷区，而是将地雷区清理出一至数条的安全通道，提供地面部队人员和车辆安全通过。排除的地雷可能在过程中加以引爆，或者是移动到安全的地方之后另外加以处理。由于清理的过程当中，扫雷车可能碰触或者是引爆其他尚未发现的地雷或者是爆裂物，车辆本身对于底盘和车辆底部的保护需要特别加强，以免被地雷或者是爆裂物瘫痪而无法完成清除的任务。装甲架桥车指装有车桥及其架设、撤收装置的装甲车辆，主要用于快速架设桥梁，令部队迅速通过河流，普遍装备于工兵部队。装甲架桥车可由一般坦克或自走炮底盘改装而成，部分会保留机枪作防卫用途。步兵坦 克和装甲输送车 - 当示威活动和抗争会转变成失控的暴乱或群众暴力时，警方有时会出动警用装甲车控制场面。一般具有水炮功能，而车窗经特别制造，不易打碎。各地警方大多都有装甲车，以防范暴乱发生。保安公司常用，用来运载现金或其他贵重物品，又称“解款车”或“运钞车”。另外政要及富豪也会使用经过改装、具有防弹甚至抗炸能力的汽车。', 'attributes': {'装甲车': {}}} (scraper.py:257)
[2022-03-10 01:55:52] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6>
{'keyword': '装甲侦察车', 'source': 'wiki', 'title': '装甲车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6', 'date': ' ', 'content': '装甲车辆是具有装甲防护的各种车辆的统称。坦克和自走炮也是广义的重型装甲车辆，但是在习惯上通常因作战用途另外独立分类，而装甲车辆多半是指防护力与火力较坦克弱的车种，而自行炮在原则上不一定要有装甲。装甲车的特性为具有高度的越野机动性能，有一定的防护和火力，分为履带式和轮式两种。一般军用装甲车会装备一至三门中小口径火炮及数挺机枪，一些还装有反坦克导弹，结构以装甲车体、武器系统、动力装置等组成。为了增强防护和方便成员下车战斗。大多数军用装甲车辆可以在水上行驶，可以执行运输、侦察、指挥、救护、伴随、支援坦克及步兵作战等多种任务，还有执行专门任务的装甲车辆，如装甲回收车、装甲指挥车、装甲扫雷车、装甲架桥车等。在警用领域多用于镇压暴乱等问题。步兵战车和装甲输送车作用相近，都是运送步兵机动作战用的装甲车辆，两者不同的地方是步兵战车的防护力较好，火力较大，能够让步兵乘车作战，本身也能够伴随下车作战的步兵，提供火力支援速度较好，装甲输送车则更接近于有装甲的运输车辆。装甲输送车为在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。装甲侦察车指装有侦察设备的装甲车辆，速度较快但装甲比其它装甲车辆要薄，多用于战场侦察，一般可分为轮式和履带式两种。较著名的装甲侦察车，有德国的狐式轻型装甲侦察车、山猫装甲侦察车，法国的雷诺VBC90轮式侦察车（英语：VBC-90）等等。装甲指挥车是具有装甲保护的移动指挥站，提供指挥官与支援的参谋和其他人员协调部队的相关事宜。装甲指挥车是早期以卡车或者是拖车为基础的移动指挥所衍生出来的架构，用意在于提供指挥单位快速移动，持续掌握情势与下达命令命且提供一些保护。大部分的装甲指挥车是从装甲输送车改装而成，扩大内部的空间以容纳额外的人员，通讯器材与其他设备。在到达预定指挥地点之后，部分装甲指挥车还有另外设置的顶蓬可以伸出车外，进一步的扩大人员使用的空间。装甲通信车是指装有通信设备的装甲车辆，常见的设计有两种型态，一种是将通信装备与装甲指挥车合并在一起，因此并非单纯的通信车辆。另外一种是做为地面通信的活动中转站，以延伸无线电通信的有效距离，或者是克服地形对通信的遮蔽效应，强化地面单位之间的联络与资讯交换。目前各国陆军很少装备单纯的装甲通信车，不过有不少国家配备由一般运输车辆改装的通信车辆来支援地面部队的通信需求。装甲救护车，指在战场环境下实行人员救护的装甲车辆，一般只装备一至两挺机枪作为自卫武器，防护力亦很弱。主要用于抢救人员，并将重伤员运送至后方。装甲扫雷车特指装有清除地雷装置的装甲车辆，以协助地面部队扩速通过地雷区。装甲扫雷车可以是专门设计用来清除地雷，或者是将清除工具附加在一般用途的坦 克底盘上，无论是车轮或是履带型态的扫雷车都可见于不同国家的部队当中。装甲扫雷车并非用于清除整个被发现的地雷区，而是将地雷区清理出一至数条的安全通道，提供地面部队人员和车辆安全通过。排除的地雷可能在过程中加以引爆，或者是移动到安全的地方之后另外加以处理。由于清理的过程当中，扫雷车可能碰触或者是引爆其他尚未发现的地雷或者是爆裂物，车辆本身对于底盘和车辆底部的保护需要特别加强，以免被地雷或者是爆裂物瘫痪而无法完成清除的任务。装甲架桥车指装有车桥及其架设、撤收装置的装甲车辆，主要用于快速架设桥梁，令部队迅速通过河流，普遍装备于工兵部队。装甲架桥车可由一般坦克或自走炮底盘改装而成，部分会保留机枪作防卫用途。步兵坦 克和装甲输送车 - 当示威活动和抗争会转变成失控的暴乱或群众暴力时，警方有时会出动警用装甲车控制场面。一般具有水炮功能，而车窗经特别制造，不易打碎。各地警方大多都有装甲车，以防范暴乱发生。保安公司常用，用来运载现金或其他贵重物品，又称“解款车”或“运钞车”。另外政要及富豪也会使用经过改装、具有防弹甚至抗炸能力的汽车。', 'attributes': {'装甲车': {}}} (scraper.py:257)
[2022-03-10 01:55:52] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4>
{'keyword': '花莲机场', 'source': 'wiki', 'title': '花莲机场', 'url': 'https://zh.wikipedia.org/wiki/%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4', 'date': ' ', 'content': '花莲机场（阿美语：Pahikukiyan nu Kalinku，太鲁阁语：Rduwan Msangay Asu Skiya Skangki，IATA代码：HUN；ICAO代码：RCYU）是位于台湾花莲县新城乡的机场，场区位在花莲市中心北方，横亘整个新城乡最南部。该机场为一军民合用机场（英语：Civil enclave），也是东台湾第一座国际机场，主要由中华民国空军管理，分为山侧的空军佳山基地、以及海侧的空军花莲基地；民用部分位于海侧，称为花莲航空站，由交通部民用航空局经营。由于本场为军民合用，机场内有大量军事设施，故禁止于起降时对机场内摄影。花莲机场的前身是日治时期的“花莲港北飞行场”，兴建于1936年，属于军民共用的机场，由日本航空运输（日语：日本航空輸送）经营。第二次世界大战结束后，由中华民国政府接收。※视评估扩充5~7号登机门及空桥，扩建工程第一期第一阶段并无建设。国内航线由立荣航空及华信航空营运台北松山、台中及高雄共3条航线，主要以ATR72-600机型执飞。国际航线由韩国低成本航空公司易斯达航空营运韩国首尔仁川、釜山共2条包机航线，主要以B737-800机型执飞，目前因2019冠状病毒病关系停航。', 'attributes': {'花莲机场': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Hualien_Air_Force_Base_entrance_20120210.jpg/220px-Hualien_Air_Force_Base_entrance_20120210.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/%E5%8D%B3%E5%B0%87%E9%99%8D%E8%90%BD%E6%96%BC%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4%E7%9A%84%E8%8F%AF%E4%BF%A1%E8%88%AA%E7%A9%BA%28%E6%94%9D%E6%96%BC%E8%8A%B1%E8%93%AE%E5%B8%82%E5%9C%8B%E5%BC%B7%E9%87%8C%29.jpg/220px-%E5%8D%B3%E5%B0%87%E9%99%8D%E8%90%BD%E6%96%BC%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4%E7%9A%84%E8%8F%AF%E4%BF%A1%E8%88%AA%E7%A9%BA%28%E6%94%9D%E6%96%BC%E8%8A%B1%E8%93%AE%E5%B8%82%E5%9C%8B%E5%BC%B7%E9%87%8C%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Road_signs_in_Hualien_Airport.jpg/220px-Road_signs_in_Hualien_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%BA%94%E6%88%B0%E8%A1%93%E6%B7%B7%E5%90%88%E8%81%AF%E9%9A%8A.png/80px-%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%BA%94%E6%88%B0%E8%A1%93%E6%B7%B7%E5%90%88%E8%81%AF%E9%9A%8A.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/HuaLien_Airport.jpg/280px-HuaLien_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Taiwan_location_map.svg/250px-Taiwan_location_map.svg.png'], '机场类型': '军民合用', '所有者': '交通部民用航空局国防部空军司令部', '营运者': '军用： 中华民国空军民用： 交通部民用航空局', '服务城市': '花莲市', '地理位置': '中华民国（台湾）花莲县新城乡嘉里村机场一号', '启用日期': '1962年5月16日(1962-05-16)', '海拔高度': '51英尺（16米）', '坐标': '24°01′24″N 121°36′36″E\ufeff / \ufeff24.02333°N 121.61000°E\ufeff / 24.02333; 121.61000坐标：24°01′24″N 121°36′36″E\ufeff / \ufeff24.02333°N 121.61000°E\ufeff / 24.02333; 121.61000', '网址': 'www.hulairport.gov.tw', '方向': ';;;方向;;长度;;表面;;;米;;英尺;;;03/21;;2,751;;9,026;;混凝土;;', '客运量': '客运量214,279人次货运量402.2公吨起降架次4,799次', '国家（地区）': '中华民国（台湾）', '位置': '花莲县', '类型': '航空安检站', '出入境管理机关': '内政部移民署国境事务大队基隆港国境事务队', '海关': '财政部关务署基隆关', '繁体字': ' 花蓮機場 ', '简化字': ' 花莲机场 ', '标音': "标音官话-汉语拼音 Huā lián  Jī chǎng -威妥玛拼音 hua lien2 chi ch'ang3 -耶鲁拼音 Hwā lyán Jī chǎng -注音符号ㄏㄨㄚ ㄌㄧㄢˊ ㄐㄧ ㄔㄤˇ闽语-闽南语白话字 Hoa-liân Ki-tiûⁿ -台罗拼音 Hua-liân Ki-tiûnn 客家话-客家话拼音 Fa1 lian2  Gi1 cong2 -客语白话字 Fâ-lièn Kî-chhòng "}}} (scraper.py:257)
[2022-03-10 01:55:52] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Earth_structure>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Earth structure', 'url': 'https://en.wikipedia.org/wiki/Earth_structure', 'date': 202110022308, 'content': "An earth structure is a building or other structure made largely from soil. Since soil is a widely available material, it has been used in construction since prehistoric times.It may be combined with other materials, compressed and/or baked to add strength. Soil is still an economical material for many applications, and may have low environmental impact both during and after construction.Earth structure materials may be as simple as mud, or mud mixed with straw to make cob. Sturdy dwellings may be also built from sod or turf. Soil may be stabilized by the addition of lime or cement, and may be compacted into rammed earth. Construction is faster with pre-formed adobe or mudbricks, compressed earth blocks, earthbags or fired clay bricks.[a]Types of earth structure include earth shelters, where a dwelling is wholly or partly embedded in the ground or encased in soil. Native American earth lodges are examples. Wattle and daub houses use a 'wattle' of poles interwoven with sticks to provide stability for mud walls. Sod houses were built on the northwest coast of Europe, and later by European settlers on the North American prairies. Adobe or mud-brick buildings are built around the world and include houses, apartment buildings, mosques and churches. Fujian Tulous are large fortified rammed earth buildings in southeastern China that shelter as many as 80 families. Other types of earth structure include mounds and pyramids used for religious purposes, levees, mechanically stabilized earth retaining walls, forts, trenches and embankment dams.Soil is created from rock that has been chemically or physically weathered, transported, deposited and precipitated.[2]Soil particles include sand, silt and clay. Sand particles are the largest at 2 to 0.05 millimetres (0.0787 to 0.0020\xa0in) in diameter and clay the smallest at less than 0.002 millimetres (7.9×10−5\xa0in) in diameter.[3]Both sand and silt are mostly inert rock particles, including quartz, calcite, feldspar and mica.[4]Clays typically are phyllosilicate minerals with a sheet-like structure.[3]The very small clay particles interact with each other physically and chemically. Even a small proportion of clay affects the physical properties of the soil much more than might be expected.[4]Clays such as kaolinite do not expand or contract when wetted or dried, and are useful for brick-making. Others, such as smectites, expand or contract considerably when wet or dry, and are not suitable for building.[3]Loam is a mix of sand, silt and clay in which none predominates. Soils are given different names depending on the relative proportions of sand, silt and clay such as 'Silt Loam', 'Clay Loam' and 'Silty Clay'.[5]Loam construction, the subject of this article, referred to as adobe construction when it uses unfired clay bricks, is an ancient building technology. It was used in the early civilizations of the Mediterranean, Egypt and Mesopotamia, in the Indus, Ganges and Yellow river valleys, in Central and South America. As of 2005 about 1.5 billion people lived in houses built of loam.[6][b]In recent years, interest in loam construction has revived in the developed world. It is seen as a way to minimize use of fossil fuels and pollution, particularly carbon dioxide, during manufacture, and to create a comfortable living environment through the high mass and high absorption of the material.[7]The two main technologies are stamped or rammed earth, clay or loam, called pise de terre in French, and adobe, typically using sun-dried bricks made of a mud and straw mixture.[7][c]Earth usually requires some sort of processing for use in construction. It may be combined with water to make mud, straw may be added, some form of stabilizing material such as lime or cement may be used to harden the earth, and the earth may be compacted to increase strength.[8]Coursed mud construction is one of the oldest approaches to building walls. Moist mud is formed by hand to make the base of a wall, and allowed to dry. More mud is added and allowed to dry to form successive courses until the wall is complete. With puddled mud, a hand-made mud form is filled with wetter mud and allowed to dry.[9]In Iran, puddled mud walls are called chine construction. Each course is about 18 to 24 inches (460 to 610\xa0mm) thick, and about 18 to 24 inches (460 to 610\xa0mm) high. Typically the technique is used for garden walls but not for house construction, presumably because of concern about the strength of walls made in this way.[10]A disadvantage to the approach is that a lot of time can be spent waiting for each course to dry.[11]Another technique, used in areas where wood is plentiful, is to build a wood-frame house and to infill it with mud, primarily to provide insulation. In parts of England a similar technique was used with cob.[9]Cob, sometimes referred to as 'monolithic adobe',[12] is a natural building material made from soil that includes clay, sand or small stones and an organic material such as straw. Cob walls are usually built up in courses, have no mortar joints and need 30% or more clay in the soil. Cob can be used as in-fill in post-and-beam buildings, but is often used for load bearing walls, and can bear up to two stories. A cob wall should be at least 16 inches (410\xa0mm) thick, and the ratio of width to height should be no more than one to ten.[12] It will typically be plastered inside and out with a mix of lime, soil and sand. Cob is fireproof, and its thermal mass helps stabilize indoor temperatures.[12] Tests have shown that cob has some resistance to seismic activity. However, building codes in the developed world may not recognize cob as an approved material.[13]Cut sod bricks, called terrone in Spanish, can be used to make tough and durable walls. The sod is cut from soil that has a heavy mat of grass roots, which may be found in river bottom lands. It is stood on edge to dry before being used in construction.[11]European settlers on the North American Prairies found that the sod least likely to deteriorate due to freezing or rain came from dried sloughs.[14] Turf was once extensively used for the walls of houses in Ireland, Scotland and Iceland, where some turf houses may still be found. A turf house may last fifty years or longer if well-maintained in a cold climate.[15]The Icelanders find that the best quality turf is the Strengur, the top 5 centimetres (2.0\xa0in) of the grass turf.[16]Clay is usually hard and strong when dry, but becomes very soft when it absorbs water. The dry clay helps hold an earth wall together, but if the wall is directly exposed to rain, or to water leaking down from the roof, it may become saturated.[17]Earth may be 'stabilized' to make it more weather resistant. The practice of stabilizing earth by adding burnt lime is centuries old.[18]Portland cement or bitumen may also be added to earth intended for construction which adds strength, although the stabilized earth is not as strong as fired clay or concrete.[18] Mixtures of cement and lime, or pozzolana and lime, may also be used for stabilization.[19]Preferably the sand content of the soil will be 65% – 75%. Soils with low clay content, or with no more than 15% non-expansive clay, are suitable for stabilized earth.[20] The clay percentage may be reduced by adding sand, if available.[21]If there is more than 15% clay it may take more than 10% cement to stabilize the soil, which adds to the cost.[20]If earth contains little clay and holds 10% or more cement, it is in effect concrete.Cement is not particularly environmentally friendly, since the manufacturing process generates large amounts of carbon dioxide.[22]Low-density stabilized earth will be porous and weak. The earth must therefore be compacted either by a machine that makes blocks or within the wall using the 'rammed earth' technique.[19]Rammed earth is a technique for building walls using natural raw materials such as earth, chalk, lime or gravel.A rammed earth wall is built by placing damp soil in a temporary form. The soil is manually or mechanically compacted and then the form is removed.[23]Rammed earth is generally made without much water, and so does not need much time to dry as the building rises. It is susceptible to moisture, so must be laid on a course that stops rising dampness, must be roofed or covered to keep out water from above, and may need protection through some sort of plaster, paint or sheathing.[22]In China, rammed earth walls were built by the Longshan people in 2600–1900 BC, during the period when cities first appeared in the region. Thick sloping walls made of rammed earth became a characteristic of traditional Buddhist monasteries throughout the Himalayas and became very common in northern Indian areas such as Sikkim.[24] The technique spread to the Middle East, and to North Africa, and the city of Carthage was built of rammed earth. From there the technology was brought to Europe by the Romans.[25]Rammed earth structures may be long lasting. Most of the Great Wall of China was made from rammed earth, as was the Alhambra in the Kingdom of Granada. In Northern Europe there are rammed earth buildings up to seven stories high and two hundred years old.[22]The Romans made durable concrete strong enough for load-bearing walls.[26] Roman concrete contains a rubble of broken bricks and rocks set in mortar. The mortar included lime and pozzolana, a volcanic material that contributed significantly to its strength.[27] Roman concrete structures such as the Colosseum, completed in 80 AD, still stand.[28]Their longevity may be explained by the fact that the builders used a relatively dry mix of mortar and aggregate and compacted it by pounding it down to eliminate air pockets.[29] Although derived from earth products, concrete structures would not usually be considered earth structures.[1]Mudbricks or Adobe bricks are preformed modular masonry units of sun-dried mud that were invented at different times in different parts of the world as civilization developed.[30] Construction with bricks avoids the delays while each course of puddled mud dries. Wall murals show that adobe production techniques were highly advanced in Egypt by 2500 BC.[11] Adobe construction is common throughout much of Africa today.[31] Adobe bricks are traditionally made from sand and clay mixed with water to a plastic consistency, with straw or grass as a binder.[32][d]The mud is prepared, placed in wooden forms, tamped and leveled, and then turned out of the mold to dry for several days. The bricks are then stood on end to air-cure for a month or more.[32]In the southwest United States and Mexico adobe buildings had massive walls and were rarely more than two stories high. Adobe mission churches were never more than about 35 feet (11\xa0m).[33]Since adobe surfaces are fragile, coatings are used to protect them. These coatings, periodically renewed, have included mud plaster, lime plaster, whitewash[e] or stucco.[34]Adobe walls were historically made by laying the bricks with mud mortar, which swells and shrinks at the same rate as the bricks when wetted or dried, heated or cooled. Modern adobe may be stabilized with cement and bonded with cement mortars, but cement mortars will cause unstabilized adobe bricks to deteriorate due to the different rates of thermal expansion and contraction.[33]Compressed earth blocks (CEB) were traditionally made by using a stick to ram soil into a wooden mold. Today they are usually made from subsoil compressed in a hand-operated or powered machine. In the developing world, manual machines can be a cost-effective solution for making uniform building blocks, while the more complex and expensive motorized machines are less likely to be appropriate. Although labor-intensive, CEB construction avoids the cost of buying and transporting materials.[35]Block-making machines may form blocks that have interlocking shapes to reduce the requirement for mortar.The block may have holes or grooves so rods such as bamboo can be inserted to improve earthquake resistance.[36]Suitable earth must be used, with enough clay to hold the block together and resist erosion, but not too much expansive clay.[37]When the block has been made from stabilized earth, which contains cement, the concrete must be given perhaps three weeks to cure.During this time the blocks should be stacked and kept from drying out by sprinkling water over them. This may be a problem in hot, dry climates where water is scarce.Closely stacking the blocks and covering them with a polythene sheet may help reduce water loss.[38]Earthbag construction is a natural building technique that has evolved from historic military construction techniques for bunkers.[39]Local subsoil of almost any composition can be used, although an adobe mix would be preferable.The soil is moistened so it will compact into a stable structure when packed into woven polypropylene or burlap sacks or tubes. Plastic mesh is sometimes used. Polypropylene (pp) sacks are most common, since they are durable when covered, cheap, and widely available.[39]The bags are laid in courses, with barbed wire between each course to prevent slipping. Each course is tamped after it is laid.[40]The structure in pp bags is similar to adobe but more flexible. With mesh tubing the structure is like rammed earth.[39]Earthbags may be used to make dome-shaped or vertical wall buildings. With soil stabilization they may also be used for retaining walls.[41]The technique of firing clay bricks in a kiln dates to about 3500 BC. Fired bricks were being used to build durable masonry across Europe, Asia and North Africa by 1200 BC and still remain an important building material.[42] Modern fired clay bricks are formed from clays or shales, shaped and then fired in a kiln for 8–12 hours at a temperature of 900–1150\xa0°C.[43][f]The result is a ceramic that is mainly composed of silica and alumina, with other ingredients such as quartz sand. The porosity of the brick depends on the materials and on the firing temperature and duration. The bricks may vary in color depending on the amount of iron and calcium carbonate in the materials used, and the amount of oxygen in the kiln.[43]Bricks may decay due to crystallization of salts on the brick or in its pores, from frost action and from acidic gases.[45]Bricks are laid in courses bonded with mortar, a combination of Portland cement, lime and sand.[46]A wall that is one brick thick will include stretcher bricks with their long, narrow side exposed and header bricks crossing from side to side. There are various brickwork 'bonds', or patterns of stretchers and headers, including the English, Dutch and Flemish bonds.[47]Earth sheltering has been used for thousands of years to make energy-efficient dwellings.[48]There are various configurations. At one extreme, an earth sheltered dwelling is completely underground, with perhaps an open courtyard to provide air and light. An earth house may be set into a slope, with windows or door openings in one or more of its sides, or the building may be on ground level, but with earth mounded against the walls, and perhaps with an earth roof.[49]Pit houses made by Hohokam farmers between 100 and 900 AD, in what is now the southwest of the US, were bermed structures, partially embedded in south-facing slopes. Their successful design was used for hundreds of years.[50]At Matmata, Tunisia, most of the ancient homes were built 12 metres (39\xa0ft) below ground level, and surrounded courtyards about 12 metres (39\xa0ft) square.[51][g]The homes were reached through tunnels. Other examples of subterranean, semi-subterranean or cliff-based dwellings in both hot and cold climates are found in Turkey, northern China and the Himalayas, and the southwest USA.[51] A number of Buddhist monasteries built from earth and other materials into cliff sides or caves in Himalayan areas such as Tibet, Bhutan, Nepal and northern India are often perilously placed. Starting in the 1970s, interest in the technique has revived in developed countries.[48] By setting an earth house into the ground, the house will be cooler in the warm season and warmer in the cool season.[49]An earth lodge is a circular building made by some of the Native Americans of North America. They have wood post and beam construction and are dome-shaped.[53]A typical structure would have four or more central posts planted in the ground and connected at the top by cross beams. The smoke hole would be left open in the center. Around the central structure there was a larger ring of shorter posts, also connected by cross beams. Rafters radiated from the central cross beams to the outside cross beams, and then split planks or beams formed the slanting or vertical side walls.[54]The structure was covered by sticks and brush or grass, covered in turn by a heavy layer of earth or sod.Some groups plastered the whole structure with mud, which dried to form a shell.[54]Wattle and daub is an old building technique in which vines or smaller sticks are interwoven between upright poles, and then mud mixed with straw and grass is plastered over the wall.[55]The technique is found around the world, from the Nile Delta to Japan, where bamboo was used to make the wattle.[56]In Cahokia, now in Illinois, USA, wattle and daub houses were built with the floor lowered by 1 to 3 feet (0.30 to 0.91\xa0m) below the ground. A variant of the technique is called bajareque in Colombia.[55]In prehistoric Britain simple circular wattle and daub shelters were built wherever adequate clay was available.[57]Wattle and daub is still found as the panels in timber-framed buildings.[58] Generally the walls are not structural, and in interior use the technique in the developed world was replaced by lath and plaster, and then by gypsum wallboard.[56]European pioneer farmers in the prairies of North America, where there is no wood for construction, often made their first home in a dug-out cave in the side of a hill or ravine, with a covering over the entrance. When they had time, they would build a sod house. The farmer would use a plow to cut the sod into bricks 1 by 2 feet (0.30 by 0.61\xa0m), which were then piled up to form the walls.[59]The sod strips were piled grass-side down, staggered in the same way as brickwork, in three side-by-side rows, resulting in a wall over 3 feet (0.91\xa0m) thick. The sod wall was built around door and window frames, and the corners of the wall were secured by rods driven vertically through them. The roof was made with poles or brush, covered with prairie grass, and then sealed with a layer of sod.[60]Sod houses were strong and often lasted many years, but they were damp and dirty unless the interior walls were plastered.[59]The roofs tended to leak, and sometimes collapsed in a rainstorm.[60]There are innumerable examples of mud brick or adobe building around the world. The walled city of Shibam in Yemen, designated a World Heritage Site in 1982, is known fr its ten-story unreinforced mud-brick buildings.[61]The Djinguereber Mosque of Timbuktu, Mali, was first built at the start of the 14th century AD (8th century AH) from round mud bricks and a stone-mud misture, and was rebuilt several times afterwards, steadily growing in size.[62]Further south in Mali, the Great Mosque of Djenné, a dramatic example of Sahel mudbrick architecture. was built in 1907, based on the design of an earlier Great Mosque first built on the site in 1280. Mudbrick requires maintenance, and the fundamentalist ruler Seku Amadu had let the previous mosque collapse.[63]The Casa Grande Ruins, now a national monument in Arizona protected by a modern roof, is a massive four-story adobe structure built by Hohokam people between 1200 and 1450 AD.[64]The first European to record the great house was a Jesuit priest, Father Eusebio Kino, who visited the site in 1694. At that time it had long been abandoned.[65]By the time a temporary roof was installed in 1903 the adobe building had been standing empty and unmaintained for hundreds of years.[66]Huaca de la Luna in what is now northern Peru is a large adobe temple built by the Moche people. The building went through a series of construction phases, growing eventually to a height of about 32 metres (105\xa0ft), with three main platforms, four plazas and many smaller rooms and enclosures. The walls were covered by striking multi-colored murals and friezes; those visible today date from about 400–610 AD.[67]High-rise mud brick buildings in ShibamMud wall and mosque in TimbuktuOld mud dwellings and modern mud mosque in MaliGreat Mosque of Djenné, Mali, in 1972Casa Grande Ruins National Monument in ArizonaSan Francisco de Asis Mission Church at Ranchos de Taos, New MexicoInterior of Huaca de la Luna, Trujillo, PeruArt on an adobe building at Shantiniketan University, Bolpur, West BengalA Fujian Tulou is a type of rural dwelling of the Hakka people in the mountainous areas in southeastern Fujian, China.[68]They were mostly built between the 13th and the 20th centuries.[69] A tulou is a large, enclosed and fortified earth building, rectangular or circular, with very thick load-bearing rammed earth walls between three and five stories high.A toulou might house up to 80 families. Smaller interior buildings are often enclosed by these huge peripheral walls which can contain halls, storehouses, wells and living areas.The structure resembles a small fortified city.[70]The walls are formed by compacting earth mixed with stone, bamboo, wood and other readily available materials, and are to 6 feet (1.8\xa0m) thick. The result is a well-lit, well-ventilated, windproof and earthquake-proof building that is warm in winter and cool in summer.[70]Ziggurats were elevated temples constructed by the Sumerians between the end of the 4th millennium BC and the 2nd millennium BC, rising in a series of terraces to a temple up to 200 feet (61\xa0m) above ground level. The Ziggurat of Ur contained about three million bricks, none more than 15 inches (380\xa0mm) in length, so construction would have been a huge project.[71]The largest ziggurat was in Babylon, and is thought by some to be the Tower of Babel mentioned in the Bible. It was destroyed by Alexander the Great and only the foundations remain, but originally it stood 300 feet (91\xa0m) high on a base about 660 feet (200\xa0m) square.[72]Sun-dried bricks were used for the interior and kiln-fired bricks for the facing. The bricks were held together by clay or bitumen.[73]Many pre-Columbian Native American societies of ancient North America built large pyramidal earth structures known as platform mounds. Among the largest and best-known of these structures is Monks Mound at the site of Cahokia in what became Illinois, completed around 1100 AD, which has a base larger than that of the Great Pyramid at Giza. Many of the mounds underwent multiple episodes of mound construction at periodic intervals, some becoming quite large. They are believed to have played a central role in the mound-building peoples' religious life and documented uses include semi-public chief's house platforms, public temple platforms, mortuary platforms, charnel house platforms, earth lodge/town house platforms, residence platforms, square ground and rotunda platforms, and dance platforms.[74][75]The 207 feet (63\xa0m) Pyramid of the Sun in Teotihuacan, Mexico, was started in 100 AD. The stone-faced structure contains two million tons of rammed earth.[25]Earthworks are engineering works created through moving or processing quantities of soil or unformed rock. The material may be moved to another location and formed into a desired shape for a purpose.[76]Levees, embankments and dams are types of earthwork.A levee, floodbank or stopbank is an elongated natural ridge or artificially constructed dirt fill wall that regulates water levels. It is usually earthen and often runs parallel to the course of a river in its floodplain or along low-lying coastlines.[77]Mechanically stabilized earth (MSE) retaining walls may be used for embankments.[78]MSE walls combine a concrete leveling pad, wall facing panels, coping, soil reinforcement and select backfill.[79]A variety of designs of wall facing panels may be used.[79]After the leveling pad has been laid and the first row of panels has been placed and braced, the first layer of earth backfill is brought in behind the wall and compacted.The first set of reinforcements is then laid over the earth.[80]The reinforcements, which may be tensioned polymer or galvanized metal strips or grids, are attached to the facing panels.[81]This process is repeated with successive layers of panels, earth and reinforcements.The panels are thus tied into the earth embankment to make a stable structure with balanced stresses.[82]Although construction using the basic principles of MSE has a long history, MSE was developed in its current form in the 1960s. The reinforcing elements used can vary but include steel and geosynthetics. The term MSE is usually used in the US to distinguish it from 'Reinforced Earth', a trade name of the Reinforced Earth Company, but elsewhere Reinforced Soil is the generally accepted term.[78] MSE construction is relatively fast and inexpensive, and although labor-intensive, it does not demand high levels of skill. It is therefore suitable for developing as well as developed countries.[83]Earth has been used to construct fortifications for thousands of years, including strongholds and walls, often protected by ditches.Aerial photography in Europe has revealed traces of earth fortifications from the Roman era, and later medieval times.[84]Offa's Dyke is a huge earthwork that stretches along the disputed border between England and Wales.[85]Little is known about the period or the builder, King Offa of Mercia, who died in 796 AD.[86]An early timber and earth fortification might later be succeeded by a brick or stone structure on the same site.[87]Trenches were used by besieging forces to approach a fortification while protected from missiles.Sappers would build 'saps', or trenches, that zig-zagged towards the fortress being attacked.They piled the excavated dirt to make a protective wall or gabion. The combined trench depth and gabion height might be 8 to 10 feet (2.4 to 3.0\xa0m). Sometimes the sap was a tunnel, dug several feet below the surface. Sappers were highly skilled and highly paid due to the extreme danger of their work.[88]In the American Civil War (1861−1865) trenches were used for defensive positions throughout the struggle, but played an increasingly important role in the campaigns of the last two years.[89]Military earthworks perhaps culminated in the vast network of trenches built during World War I (1914−1918) that stretched from Switzerland to the North Sea by the end of 1914.[90]The two lines of trenches faced each other, manned by soldiers living in appalling conditions of cold, damp and filth.[91]Conditions were worst in the Allied trenches. The Germans were more willing to accept the trenches as long-term positions, and used concrete blocks to build secure shelters deep underground, often with electrical lighting and heating.[92]An embankment dam is a massive artificial water barrier. It is typically created by the emplacement and compaction of a complex semi-plastic mound of various compositions of soil, sand, clay and/or rock. It has a semi-permanent natural waterproof covering for its surface, and a dense, waterproof core. This makes such a dam impervious to surface or seepage erosion.[93]The force of the impoundment creates a downward thrust upon the mass of the dam, greatly increasing the weight of the dam on its foundation. This added force effectively seals and makes waterproof the underlying foundation of the dam, at the interface between the dam and its stream bed.[94] Such a dam is composed of fragmented independent material particles. The friction and interaction of particles binds the particles together into a stable mass rather than by the use of a cementing substance.[95]The Syncrude Mildred Lake Tailings Dyke in Alberta, Canada, is an embankment dam about 18 kilometres (11\xa0mi) long and from 40 to 88 metres (131 to 289\xa0ft) high. By volume of fill, as of 2001 it was believed to be the largest earth structure in the world.[96]Regions with low seismic risk are safe for most earth buildings, but historic construction techniques often cannot resist even medium earthquake levels effectively because of earthen buildings' three highly undesirable qualities as a seismic building material: being relatively 'weak, heavy and brittle'. However, earthen buildings can be built to resist seismic loads.[97]Key factors to improved seismic performance are soil strength, construction quality, robust layout and seismic reinforcement.[98]Stronger soils make stronger walls. Adobe builders can test cured blocks for strength by dropping from a specific height or by breaking them with a lever.[99] Builders using immediate techniques like earthbag, cob, or rammed earth may prefer approximate crushing tests on smaller samples that can be oven-dried and crushed under a small lever.[100]Builders must understand construction processes and be able to produce consistent quality for strong buildings.[101]Robust layout means buildings more square than elongated, and symmetrical not L-shaped,[102] as well as no 'soft' first stories (stories with large windows, buildings on unbraced columns). New Zealand's earthen building guidelines check for enough bracing wall length in each of the two principal directions, based on wall thickness, story height, bracing wall spacing, and the roof, loft and second story weight above earthen walls.[103]Building techniques that are more ductile than brittle, like the contained earth type of earthbag, or tire walls of earthships, may better avoid collapse than brittle unreinforced earth. Contained gravel base courses may add base isolation potential.Wall containment can be added to techniques like adobe to resist loss of material that leads to collapse.[104] Confined masonry is effective for adobe against quake forces of 0.3 g[105][106] may be useful with earthen masonry.Many types of reinforcement can increase wall strength, such as plastic or wire mesh and reinforcing rods of steel or fiberglass or bamboo. Earth resists compression well but is weak when twisted. Tensile reinforcement must span potential damage points and be well-anchored to increase out-of-plane stability. Bond beams at wall tops are vital and must be well attached to walls.[107]Builders should be aware that organic reinforcements embedded in walls may be destroyed before the building is retired. Attachment details of reinforcement are critical to resist higher forces. Best adobe shear strength came from horizontal reinforcement attached directly to vertical rebar spanning from footing to bond beam.[108]Interlaced wood in earthen walls reduces quake damage if wood is not damaged by dry rot or insects. Timberlacing includes finely webbed Dhajji,[109] and other types.[110]", 'attributes': {'Earth structure': {}}} (scraper.py:257)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:55:52] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1676,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 44150,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.542847,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 55, 52, 669008),
 'httpcompression/response_bytes': 179734,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 69,
 'memusage/max': 66748416,
 'memusage/startup': 66748416,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 55, 47, 126161)} (statscollectors.py:47)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:55:52] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1568,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 48925,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.578934,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 55, 52, 687405),
 'httpcompression/response_bytes': 199589,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 86,
 'memusage/max': 66478080,
 'memusage/startup': 66478080,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 55, 47, 108471)} (statscollectors.py:47)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:55:52] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1604,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 39501,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.533004,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 55, 52, 690528),
 'httpcompression/response_bytes': 141127,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 54,
 'memusage/max': 67297280,
 'memusage/startup': 67297280,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 55, 47, 157524)} (statscollectors.py:47)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:55:52] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1586,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 41569,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.529215,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 55, 52, 695413),
 'httpcompression/response_bytes': 151557,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 50,
 'memusage/max': 67608576,
 'memusage/startup': 67608576,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 55, 47, 166198)} (statscollectors.py:47)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:55:52] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 6645,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 429696,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'elapsed_time_seconds': 5.602718,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 55, 52, 700232),
 'httpcompression/response_bytes': 1896597,
 'httpcompression/response_count': 12,
 'item_scraped_count': 11,
 'log_count/DEBUG': 63,
 'log_count/INFO': 102,
 'memusage/max': 66142208,
 'memusage/startup': 66142208,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2022, 3, 10, 1, 55, 47, 97514)} (statscollectors.py:47)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:55:52] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1568,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 51684,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.566756,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 55, 52, 702488),
 'httpcompression/response_bytes': 226328,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 77,
 'memusage/max': 67002368,
 'memusage/startup': 67002368,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 55, 47, 135732)} (statscollectors.py:47)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 01:55:52] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1586,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 41675,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.509686,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 1, 55, 52, 704671),
 'httpcompression/response_bytes': 155252,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 38,
 'memusage/max': 67907584,
 'memusage/startup': 67907584,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 1, 55, 47, 194985)} (statscollectors.py:47)
[2022-03-10 01:55:52] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 01:55:52] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.006307 (DataCleaning.py:41)
[2022-03-10 01:55:52] [    INFO] [  __main__ ] - 上传文件：/code/./result/wiki/wiki_装甲防护车_装甲防护车_20220310015552015455.json (MultisiteSchedule.py:276)
[2022-03-10 01:55:52] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:291)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 277, in upload_crawl_file
    connect.upload_file(file, "/text_crawl_file/")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 01:55:52] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:395)
[2022-03-10 01:55:52] [    INFO] [  __main__ ] - upload crawl file success (MultisiteSchedule.py:398)
[2022-03-10 01:55:52] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 02:01:42] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 02:01:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_13.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_13.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_13.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 343
    else if(type([]) == type(item['attributes']['img_url'])):
          ^
SyntaxError: invalid syntax
[2022-03-10 02:01:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_13.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 343
    else if(type([]) == type(item['attributes']['img_url'])):
          ^
SyntaxError: invalid syntax
[2022-03-10 02:01:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_13.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_13.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 343
    else if(type([]) == type(item['attributes']['img_url'])):
          ^
SyntaxError: invalid syntax
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 343
    else if(type([]) == type(item['attributes']['img_url'])):
          ^
SyntaxError: invalid syntax
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 343
    else if(type([]) == type(item['attributes']['img_url'])):
          ^
SyntaxError: invalid syntax
[2022-03-10 02:01:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_13.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 343
    else if(type([]) == type(item['attributes']['img_url'])):
          ^
SyntaxError: invalid syntax
[2022-03-10 02:01:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_13.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_13.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 343
    else if(type([]) == type(item['attributes']['img_url'])):
          ^
SyntaxError: invalid syntax
[2022-03-10 02:01:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_13.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 02:01:42] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 343
    else if(type([]) == type(item['attributes']['img_url'])):
          ^
SyntaxError: invalid syntax
[2022-03-10 02:01:42] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_13.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:01:42] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:16] [CRITICAL] [   twisted ] - Unhandled error in Deferred: (_legacy.py:147)
[2022-03-10 02:02:16] [CRITICAL] [   twisted ] -  (_legacy.py:147)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/local/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/code/TextProcessorScrapy/pipelines.py", line 343
    else if(type([]) == type(item['attributes']['img_url'])):
          ^
SyntaxError: invalid syntax
[2022-03-10 02:02:16] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.012232 (DataCleaning.py:41)
[2022-03-10 02:02:16] [    INFO] [  __main__ ] - 上传文件：/code/./result/wiki/wiki_装甲防护车_装甲防护车_20220310015552015455.json (MultisiteSchedule.py:276)
[2022-03-10 02:02:16] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:291)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 277, in upload_crawl_file
    connect.upload_file(file, "/text_crawl_file/")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 02:02:16] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:395)
[2022-03-10 02:02:16] [    INFO] [  __main__ ] - upload crawl file success (MultisiteSchedule.py:398)
[2022-03-10 02:02:16] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
[2022-03-10 02:02:21] [    INFO] [  __main__ ] - TextCrawler On! (MultisiteSchedule.py:373)
[2022-03-10 02:02:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_14.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 02:02:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_14.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 02:02:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_14.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 02:02:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_14.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 02:02:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_14.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 02:02:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_14.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 02:02:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_14.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 02:02:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_14.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 02:02:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_14.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 02:02:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_14.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 02:02:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.crawler ] - Overridden settings:
{'BOT_NAME': 'TextProcessorScrapy',
 'COMMANDS_MODULE': 'TextProcessorScrapy.commands',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 32,
 'CONCURRENT_REQUESTS_PER_IP': 128,
 'LOG_FILE': 'log/scrapy_2022_3_10_14.log',
 'NEWSPIDER_MODULE': 'TextProcessorScrapy.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SPIDER_MODULES': ['TextProcessorScrapy.spiders'],
 'TELNETCONSOLE_ENABLED': False} (crawler.py:60)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled downloader middlewares:
['TextProcessorScrapy.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.middleware ] - Enabled item pipelines:
['TextProcessorScrapy.pipelines.ImagePipeline',
 'TextProcessorScrapy.pipelines.WikiPipeline'] (middleware.py:48)
[2022-03-10 02:02:21] [    INFO] [scrapy.core.engine ] - Spider opened (engine.py:272)
[2022-03-10 02:02:21] [    INFO] [scrapy.extensions.logstats ] - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) (logstats.py:48)
[2022-03-10 02:02:22] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 02:02:22] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 02:02:22] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (redirect.py:42)
[2022-03-10 02:02:22] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 02:02:22] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 02:02:22] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 02:02:22] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 02:02:22] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 02:02:22] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (redirect.py:42)
[2022-03-10 02:02:22] [   DEBUG] [scrapy.downloadermiddlewares.redirect ] - Redirecting (302) to <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> from <GET https://zh.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (redirect.py:42)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E9%A9%AC%E5%85%AC%E6%9C%BA%E5%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E7%9B%B4%E5%8D%87%E6%A9%9F> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E7%9B%B4%E5%8D%87%E6%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BE%93%E9%80%81%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E9%98%B2%E6%8A%A4%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4>
{'keyword': '马公机场', 'source': 'wiki', 'title': '澎湖机场', 'url': 'https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4', 'date': ' ', 'content': "澎湖机场（闽南语白话字：.mw-parser-output .IPA{font-family:'Charis SIL','Doulos SIL','Linux Libertine','Segoe UI','Lucida Sans Unicode','Code2000','Gentium','Gentium Alternative','TITUS Cyberbit Basic','Arial Unicode MS','IPAPANNEW','Chrysanthi Unicode','GentiumAlt','Bitstream Vera','Bitstream Cyberbit','Hiragino Kaku Gothic Pro','Lucida Grande',sans-serif;text-decoration:none!important}.mw-parser-output .IPA a:link,.mw-parser-output .IPA a:visited{text-decoration:none!important}Phîⁿ-ô͘/Phêⁿ-ô͘ Ki-tiû；IATA代码：MZG；ICAO代码：RCQC），是一座位于台湾澎湖县湖西乡隘门村的军民合用机场，为该县主要联外机场，旧名“马公机场”。民用部分由交通部民用航空局马公航空站[注 1]管理及营运；军用部分为空军马公基地。由立荣航空、华信航空、德安航空营运台北松山、台中、台南、嘉义、高雄、金门及七美共7条航线，主要以ATR72-600、A321-200、DHC6-400等机型执飞。2019冠状病毒病疫情爆发，国际线需求下降，但离岛航线需求大增，华信航空部分航班由台湾虎航A320-200营运。", 'attributes': {'澎湖机场': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/ROCAF_F-5A_in_Makung_AB_1974.jpg/250px-ROCAF_F-5A_in_Makung_AB_1974.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Magong_Airport.jpg/150px-Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png/80px-%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png', 'https://upload.wikimedia.org/wikipedia/commons/7/7d/Aerial_view_of_Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Taiwan_location_map.svg/250px-Taiwan_location_map.svg.png'], '机场类型': '军民合用', '营运者': '军用： 中华民国空军民用： 交通部民用航空局', '服务城市': '澎湖县', '地理位置': '中华民国（台湾）澎湖县湖西乡隘门村126-5号', '启用日期': '军用：1937年民用：1977年8月1日(1977-08-01)', '海拔高度': '103英尺（31米）', '坐标': '23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833坐标：23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833', '网址': 'www.mkport.gov.tw', '方向': ';;;方向;;长度;;表面;;;米;;英尺;;;02/20;;3,000;;9,843;;混凝土;;', '客运量': '客运量2,320,249 人次货运量6,060.863 公吨起降架次35,682 次', '繁体字': ' 澎湖機場 ', '简化字': ' 澎湖机场 ', '标音': "标音官话-汉语拼音 Péng hú Háng kōng zhàn -威妥玛拼音 Pʻêng2 hu2 hang2 k'ung chan4 -耶鲁拼音 Péng hú háng kūng jàn -注音符号ㄆㄥˊ ㄏㄨˊ ㄏㄤˊ ㄎㄨㄥ ㄓㄢˋ闽语-闽南语白话字 Phîⁿ-ô͘/Phêⁿ-ô͘  hái-khang-chām -台罗拼音 Phînn-ôo/Phênn-ôo hâng-khong-tsām 客家话-客家话拼音 Pang2 fu2 hong2 kung1 zam4 -客语白话字 Phàng-fù hòng-khûng chham ", '汉语': '澎湖航空站'}}} (scraper.py:257)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Defensive_wall> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1> (referer: None) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E7%9B%B4%E5%8D%87%E6%A9%9F>
{'keyword': '直升机', 'source': 'wiki', 'title': '直升机', 'url': 'https://zh.wikipedia.org/wiki/%E7%9B%B4%E5%8D%87%E6%A9%9F', 'date': ' ', 'content': '直升机是一种由水平旋转的动力旋翼提供向上升力和飞行推进力的飞行器，是旋翼航空器的主要种类。直升机具有大多数固定翼飞机所不具备的垂直起降、悬停和随意向前、向后或侧向飞行的能力，这些特点使得直升机在很多狭窄、崎岖、缺乏跑道的复杂环境下有许多优势。与固定翼飞机相比，直升机的缺点是速度低、耗油量较高、航程较短、载重较少。直升机旋翼产生升力的原理与固定翼飞机的机翼相似，通过翼剖面与空气发生相对运动使得旋翼产生上弱下强的气压差，进而产生升力并通过旋翼的主轴传递给机身，使其可以克服重力实现飞行。和固定翼飞机的机翼一样，直升机旋桨能够产生的升力大小取决于气流速度和其桨叶水平投影面积的总和；但直升机不像固定翼飞机那样必须依赖整个机体的向前运动才能让机翼产生气流，而是依靠翼片的旋转产生与空气的相对运动。但旋翼在提供升力的同时也会产生反扭矩（与旋翼的转动方向相反、角动量相等的反作用扭矩）并传递到机身上，这使得最为常见的单旋翼直升机在浮空时会向着旋桨相反的方向自旋。为了平衡反扭矩，直升机需要在机尾位置产生一个与旋翼方向相同、角动量相等的水平旋转推力抵消反力矩，最常见的做法是在机尾末端安装一个垂直的小型螺旋桨（即尾桨）提供推力。而双旋翼和多旋翼直升机多采用让反向旋转的旋翼之间的扭矩相互抵消的方法来清除反扭矩，并可以利用各个旋翼的转速差别来改变飞行状态。在附图的运作说明中可以见得，由上俯视一个顺时针旋转的主翼，它的尾桨会是向黄色箭头所指方向推力的。直升机和自转旋翼机的外观相似，但是飞行原理和性能并不同。自转旋翼机的发动机只驱动尾部的螺旋桨提供前进推力，主旋桨并没有动力源，必须依赖向前运动时的相对反向气流才能被动旋转产生升力。自转旋翼机虽然构造比较简单和低价也可以做到短程起降，但完全没有垂直起降、悬停、随意侧飞和倒飞的能力，不如直升机的性能广泛，是介乎于固定翼飞机和直升机中间的一种对跑道要求较低的飞行器。用途较狭而专业化的航空机构通常拥有直升机，但鲜有采用旋翼机。人类梦想的飞行方式是原地腾空而起，既能自由飞翔又能悬停于空中，并且随意实现定点着陆。例如阿拉伯人的飞毯，希腊神的战车，都是垂直起落飞行器。其中最有价值、最具代表性的是中国古代玩具竹蜻蜓和意大利人达·芬奇关于垂直起降航空器的画作。李约瑟误以为中国晋朝葛洪所著的《抱朴子》有纪录类似竹蜻蜓最早的动力机械[1]，但实际上文章说的是服丹修练成仙成功时，人可以飞行[2]。《简明不列颠百科全书》第9卷写道：“直升机是人类最早的飞行设想之一，多年来人们一直相信最早提出这一想法的是达·芬奇，但现在都知道，中国人比中世纪的欧洲人更早做出了直升机玩具。”这种玩具于14世纪传到欧洲。“英国航空之父”乔治·凯利（1773年－1857年）曾制造过几个竹蜻蜓，用钟表发条作为动力来驱动旋转，飞行高度曾达27米。随着生产力的发展和人类文明的进步，直升机的发展史由幻想时期进入了探索时期。欧洲产业革命之后，机械工业迅速倔起，尤其是本世纪初汽车和轮船的发展，为飞行器准备了发动机和可供借鉴的螺旋桨。经过航空先驱者们勇敢而艰苦的创造和试验，1903年莱特兄弟（Wright brothers）制造的固定翼飞机飞行成功。在此期间，尽管在发展直升机方面，航空先驱们付出了相当的艰辛和努力，但由于直升机技术的复杂性和发动机性能不佳，它的成功飞行比飞机迟了30多年。20世纪初为直升机发展的探索期，多种试验性机型相继问世。试验机方案的多样性表明了探索阶段的技术不成熟性。经过多年实践，这些方案中只有纵列式和共轴双旋翼式保留了下来，至今仍在应用。双桨横列式方案未在直升机家族中延续，但在倾转旋翼飞机中得到了继承和发展。俄国人尤利耶夫另辟捷径，提出了利用尾桨来配平旋翼反扭矩的设计方案并于1912年制造出了试验机。这种单旋翼带尾桨式直升机成为至今最流行的形式。经过20世纪初的努力探索，为直升机发展积累了可贵的经验并取得显著进展，有多架试验机实现了短暂的垂直升空和短距飞行，但离实用还有很大距离。飞机工业的发展使航空发动机的性能迅速提高，为直升机的成功提供了重要条件。旋翼技术的第一次突破，归功于西班牙人Ciervao，他为了创造“不失速”的飞机以解决固定翼飞机的安全问题，采用自转旋翼代替机翼，发明了自转旋翼机。旋翼技术在自转旋翼机上的成功应用和发展，为直升机的诞生提供了另一个重要条件。1907年8月，法国人保罗·科尔尼研制出一架全尺寸载人直升机，并在同年11月13日试飞成功。这架直升机被称为“人类第一架直升机”。1938年，年轻的德国人汉纳赖奇驾驶一架双旋翼直升机在柏林体育场进行了一次完美的飞行表演。这架直升机被直升机界认为是世界上第一种试飞成功的直升机。1936年，德国福克公司在对早期直升机进行多方面改进之后，公开展示了自己制造的FW-61直升机，1年后该机创造了多项世界纪录。[3]1939年春，美国的伊戈尔·伊万诺维奇·西科尔斯基完成了VS-300直升机的全部设计工作，同年夏天制造出一架原型机。这种单旋翼带尾桨直升机构型成为现在最常见的直升机构型。20世纪40年代，美国沃特-西科斯基公司研制的一种2座轻型直升机R-4，它是世界上第一种投入批量生产的直升机，也是美国陆军航空兵、海军、海岸警卫队和英国空军、海军使用的第一种军用直升机。该机的公司编号为VS-316，VS-316A。美国陆军航空兵的编号为R-4，美国海军和海岸防卫队的编号为HNS-1，英国空军将其命名为“食蚜虻1”（Hoverfly 1），英国海军将其命名为“牛虻”（Gadfly）。到30年代末期，在法国、德国、美国和前苏联都有直升机试飞成功，并迅速改进达到了能够实用的程度。第二次世界大战的军事需要，加速了这一进程，促使直升机发展由探索期进入实用期，直升机开始投入生产线生产。到二战结束时，德国工厂已生产了30多架直升机，美国交付的R5、R6直升机已达400多架。[4]20世纪的后半期直升机进入航空实用期，特别是越战期间大量直升机部属到战场，战后直升机的应用领域不断扩展，数量迅速增加。每年八月第三个星期日被列为世界直升机日。单旋翼直升机（monocopter或unicopter）是直升机的主要类型，使用单一的主旋翼（main rotor）产生升力，但因为角动量守恒的原因，必须配有一个反扭矩机制去抵消主旋翼旋转造成的机体反向旋转。有尾桨例子：西科斯基UH-60涵道式尾桨例子：欧直EC-135无尾桨例子：麦道MD520N双旋翼直升机（bicopter）使用两个旋翼合作产生升力，可以用方向相反的旋转互相抵消反扭矩，因此不需要在尾部安装垂直旋桨。纵列式代表：波音CH-47D横列式代表：米里Mi-12倾转式代表：贝尔-波音V-22共轴式代表：卡莫夫Ka-27交错式代表：H-43卡曼公司双旋翼交叉式直升机K-600多旋翼直升机（multicopter）使用三个以上的旋翼来产生升力，是民用无人航空载具的主流类型。最常见的设计是四旋翼直升机（quadcopter），有四个大小相同、分布位置接近对称的旋翼来达到悬停、维持姿态及平飞。小型四旋翼飞行器大疆悟2无人机大疆御Air 2无人机六旋翼无人机直升机的起落架分为滑橇式和轮式两种，轮式又分可收放和不可收放式。滑橇式一般用于轻型直升机；轮式多用在中型、重型直升机。[5][6]直升机的操纵系统有别于固定翼航空器，通常由以下部分组成：单旋翼带尾桨直升机的操纵系统说明表直升机依照用途可分为民用与军用两种。作为民间工作，没有武装且仅有该用途所需的装备的直升机即为民用直升机。依其用途目前主要可分为下列几种：增加装甲和武器，同时加强性能以供军事用途的直升机便为军用直升机。依其用途目前主要可分为下列五种：', 'attributes': {'直升机': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Russian_Air_Force_Kamov_Ka-50.jpg/220px-Russian_Air_Force_Kamov_Ka-50.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Rotor_Antitorque_System.svg/220px-Rotor_Antitorque_System.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Helicopter_rescue_sancy_takeoff.jpg/220px-Helicopter_rescue_sancy_takeoff.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Mil_Mi-6%2C_54RED%2C_Russian_Air_Force.jpg/220px-Mil_Mi-6%2C_54RED%2C_Russian_Air_Force.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/F-WWPB_%288970712548%29.jpg/240px-F-WWPB_%288970712548%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Hatzerim_270613_Apache.jpg/220px-Hatzerim_270613_Apache.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/LAPD_Bell_206_Jetranger.jpg/300px-LAPD_Bell_206_Jetranger.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Antitorque.jpg/303px-Antitorque.jpg'], '航空器专题': ';;;航空器专题;;;单纯利用空气浮力（浮空器）;;;无动力;;动力;;;;气球;;;飞艇;;;空气浮力和空气动力混合;;;无动力;;动力;;;;混合系留气球;风筝式系留气球;;;混合飞艇;;;单纯利用空气动力;;;无动力;;动力;;;无动力固定翼;;动力固定翼;;;;滑翔机;悬挂式滑翔机;滑翔伞;风筝;;;飞机;动力滑翔伞;滚筒飞行器;地效飞行器;;;;;半固定翼和旋翼;;;;;;倾转旋翼机;环翼机;;;无动力旋翼;;动力旋翼;;;;旋翼风筝;;;自转旋翼机;旋翼式螺旋桨飞机;直升机;;;;;扑翼;;;;;;扑翼机;;;其他;;;无动力;;动力;;;;;;飞行实验器;飞行汽车;飞天车;;'}}} (scraper.py:257)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BE%93%E9%80%81%E8%BD%A6>
{'keyword': '装甲防护车', 'source': 'wiki', 'title': '装甲输送车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BE%93%E9%80%81%E8%BD%A6', 'date': ' ', 'content': '装甲输送车（英文：Armoured personnel carrier，缩写：APC）又称装甲运兵车，指在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。在必要时，也可以使用车上的武器攻击敌人。\xa0加拿大：\xa0中华民国 ：\xa0中华人民共和国：\xa0芬兰：\xa0法国：\xa0德国：\xa0以色列：\xa0日本：\xa0俄罗斯：\xa0新加坡：\xa0瑞士：\xa0美国：\xa0乌克兰：\xa0土耳其：装甲输送车出现的时间与战车约略同期，第一次世界大战末期，英国推出专门用来运输步兵的马克IX型坦克。由于坦克本身的成本较当时使用的卡车高出许多，有些国家是以加装装甲的汽车权充兼作运输的用途。1930年代许多国家开始发展机械化部队，由于全履带车的造价与维护成本依旧居高不下，为了配合战车的运动速度与越野能力，半履带车加上防护装甲之后成为最常见的型态。二次世界大战期间，美国的M3半履带车与德国SdKfz 251半履带车是最著名的代表。这些车辆拥有防御小口径武器与弹药破片的侧面装甲，但是欠缺顶部的保护。车体上以携带机枪最为常见。而战争中期以后盟军开始将M4中型坦克改装成装甲输送车使用。到冷战时期，由于核战阴影的威胁、履带动力装置成本下降加上铝合金的使用，装甲输送车开始具备封闭式车身，为了与步兵共同作战而演化出步兵战斗车这类重武装车种。', 'attributes': {'装甲输送车': {}}} (scraper.py:257)
[2022-03-10 02:02:23] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 02:02:23] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1568,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 49012,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 2.201643,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 2, 2, 23, 789007),
 'httpcompression/response_bytes': 199561,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 28,
 'log_count/INFO': 71,
 'memusage/max': 66297856,
 'memusage/startup': 66297856,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 2, 2, 21, 587364)} (statscollectors.py:47)
[2022-03-10 02:02:23] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Rampart_(fortification)> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/RPG-29> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Fortification> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Songyue_Pagoda> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Kremlin_(fortification)> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 02:02:23] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Scorched_earth> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Defensive_wall>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Defensive wall', 'url': 'https://en.wikipedia.org/wiki/Defensive_wall', 'date': 202203010418, 'content': "A defensive wall is a fortification usually used to protect a city, town or other settlement from potential aggressors. The walls can range from simple palisades or earthworks to extensive military fortifications with towers, bastions and gates for access to the city.[1] From ancient to modern times, they were used to enclose settlements. Generally, these are referred to as city walls or town walls, although there were also walls, such as the Great Wall of China, Walls of Benin, Hadrian's Wall, Anastasian Wall, and the Atlantic Wall, which extended far beyond the borders of a city and were used to enclose regions or mark territorial boundaries. In mountainous terrain, defensive walls such as letzis were used in combination with castles to seal valleys from potential attack. Beyond their defensive utility, many walls also had important symbolic functions\xa0–  representing the status and independence of the communities they embraced.Existing ancient walls are almost always masonry structures, although brick and timber-built variants are also known. Depending on the topography of the area surrounding the city or the settlement the wall is intended to protect, elements of the terrain such as rivers or coastlines may be incorporated in order to make the wall more effective.Walls may only be crossed by entering the appropriate city gate and are often supplemented with towers. The practice of building these massive walls, though having its origins in prehistory, was refined during the rise of city-states, and energetic wall-building continued into the medieval period and beyond in certain parts of Europe.Simpler defensive walls of earth or stone, thrown up around hillforts, ringworks, early castles and the like, tend to be referred to as ramparts or banks.From very early history to modern times, walls have been a near necessity for every city. Uruk in ancient Sumer (Mesopotamia) is one of the world's oldest known walled cities. Before that, the proto-city of Jericho in the West Bank had a wall surrounding it as early as the 8th millennium\xa0BC. The earliest known town wall in Europe is of Solnitsata, built in the 6th or 5th millennium BC.The Assyrians deployed large labour forces to build new palaces, temples and defensive walls.[2]Babylon was one of the most famous cities of the ancient world, especially as a result of the building program of Nebuchadnezzar, who expanded the walls and built the Ishtar Gate.The Persians built defensive walls to protect their territories, notably the Derbent Wall and the Great Wall of Gorgan built on the either sides of the Caspian Sea against nomadic nations.Some settlements in the Indus Valley Civilization were also fortified. By about 3500\xa0BC, hundreds of small farming villages dotted the Indus floodplain. Many of these settlements had fortifications and planned streets. The stone and mud brick houses of Kot Diji were clustered behind massive stone flood dykes and defensive walls, for neighboring communities quarreled constantly about the control of prime agricultural land.[3] Mundigak (c. 2500\xa0BC) in present-day south-east Afghanistan has defensive walls and square bastions of sun dried bricks.[4]Large rammed earth walls were built in ancient China since the Shang Dynasty (c. 1600–1050\xa0BC), as the capital at ancient Ao had enormous walls built in this fashion (see siege for more info). Although stone walls were built in China during the Warring States (481–221\xa0BC), mass conversion to stone architecture did not begin in earnest until the Tang Dynasty (618–907\xa0 AD). Sections of the Great Wall had been built prior to the Qin Dynasty (221–207\xa0BC) and subsequently connected and fortified during the Qin dynasty, although its present form was mostly an engineering feat and remodeling of the Ming Dynasty (1368–1644\xa0AD). The large walls of Pingyao serve as one example. Likewise, the walls of the Forbidden City in Beijing were established in the early 15th century by the Yongle Emperor. According to Tonio Andrade, the immense thickness of Chinese city walls prevented larger cannons from being developed, since even industrial era artillery had trouble breaching Chinese walls.[5][6]In ancient Greece, large stone walls had been built in Mycenaean Greece, such as the ancient site of Mycenae (famous for the huge stone blocks of its 'cyclopean' walls). In classical era Greece, the city of Athens built a long set of parallel stone walls called the Long Walls that reached their guarded seaport at Piraeus. Exceptions were few, but neither ancient Sparta nor ancient Rome had walls for a long time, choosing to rely on their militaries for defense instead. Initially, these fortifications were simple constructions of wood and earth, which were later replaced by mixed constructions of stones piled on top of each other without mortar.The Romans fortified their cities with massive, mortar-bound stone walls. Among these are the largely extant Aurelian Walls of Rome and the Theodosian Walls of Constantinople, together with partial remains elsewhere. These are mostly city gates, like the Porta Nigra in Trier or Newport Arch in Lincoln.In Central Europe, the Celts built large fortified settlements which the Romans called oppida, whose walls seem partially influenced by those built in the Mediterranean. The fortifications were continuously expanded and improved.Apart from these, the early Middle Ages also saw the creation of some towns built around castles. These cities were only rarely protected by simple stone walls and more usually by a combination of both walls and ditches. From the 12th century AD hundreds of settlements of all sizes were founded all across Europe, which very often obtained the right of fortification soon afterwards.The founding of urban centers was an important means of territorial expansion and many cities, especially in central and eastern Europe, were founded for this purpose during the period of Eastern settlement. These cities are easy to recognise due to their regular layout and large market spaces. The fortifications of these settlements were continuously improved to reflect the current level of military development.While gunpowder and cannons were invented in China, China never developed wall breaking artillery to the same extent as other parts of the world. Part of the reason is probably because Chinese walls were already highly resistant to artillery and discouraged increasing the size of cannons.[7] In the mid-twentieth century a European expert in fortification commented on their immensity: 'in China … the principal towns are surrounded to the present day by walls so substantial, lofty, and formidable that the medieval fortifications of Europe are puny in comparison.'[7] Chinese walls were thick. The eastern wall of Ancient Linzi, established in 859 BC, had a maximum thickness of 43 metres and an average thickness of 20-30 metres.[8] Ming prefectural and provincial capital walls were 10 to 20 metres (33 to 66\xa0ft) thick at the base and 5 to 10 metres (16 to 33\xa0ft) at the top.In Europe the height of wall construction was reached under the Roman Empire, whose walls often reached 10 metres (33\xa0ft) in height, the same as many Chinese city walls, but were only 1.5 to 2.5 metres (4\xa0ft 11\xa0in to 8\xa0ft 2\xa0in) thick. Rome's Servian Walls reached 3.6 and 4 metres (12 and 13\xa0ft) in thickness and 6 to 10 metres (20 to 33\xa0ft) in height. Other fortifications also reached these specifications across the empire, but all these paled in comparison to contemporary Chinese walls, which could reach a thickness of 20 metres (66\xa0ft) at the base in extreme cases. Even the walls of Constantinople which have been described as 'the most famous and complicated system of defence in the civilized world,'[9] could not match up to a major Chinese city wall.[10] Had both the outer and inner walls of Constantinople been combined, they would have only reached roughly a bit more than a third the width of a major wall in China.[10] According to Philo the width of a wall had to be 4.5 metres (15\xa0ft) thick to be able to withstand artillery.[11] European walls of the 1200s and 1300s could reach the Roman equivalents but rarely exceeded them in length, width, and height, remaining around 2 metres (6\xa0ft 7\xa0in) thick. It is apt to note that when referring to a very thick wall in medieval Europe, what is usually meant is a wall of 2.5 metres (8\xa0ft 2\xa0in) in width, which would have been considered thin in a Chinese context.[12] There are some exceptions such as the Hillfort of Otzenhausen, a Celtic ringfort with a thickness of 40 metres (130\xa0ft) in some parts, but Celtic fort-building practices died out in the early medieval period.[13] Andrade goes on to note that the walls of the marketplace of Chang'an were thicker than the walls of major European capitals.[12]Aside from their immense size, Chinese walls were also structurally different from the ones built in medieval Europe. Whereas European walls were mostly constructed of stone interspersed with gravel or rubble filling and bonded by limestone mortar, Chinese walls had tamped earthen cores which absorbed the energy of artillery shots.[14] Walls were constructed using wooden frameworks which were filled with layers of earth tamped down to a highly compact state, and once that was completed the frameworks were removed for use in the next wall section. Starting from the Song dynasty these walls were improved with an outer layer of bricks or stone to prevent corrosion, and during the Ming, earthworks were interspersed with stone and rubble.[14] Most Chinese walls were also sloped rather than vertical to better deflect projectile energy.[15]The defensive response to cannon in Europe was to build relatively low and thick walls of packed earth, which could both withstand the force of cannon balls and support their own, defensive cannon. Chinese wall-building practice was, by happenstance, extremely resistant to all forms of battering. This held true into the twentieth century, when even modern explosive shells had some difficulty in breaking through tamped earth walls.[5]The Chinese Wall Theory essentially rests on a cost benefit hypothesis, where the Ming recognized the highly resistant nature of their walls to structural damage, and could not imagine any affordable development of the guns available to them at the time to be capable of breaching said walls. Even as late as the 1490s a Florentine diplomat considered the French claim that 'their artillery is capable of creating a breach in a wall of eight feet in thickness'[16] to be ridiculous and the French 'braggarts by nature'.[16] In fact twentieth century explosive shells had some difficulty creating a breach in tamped earthen walls.[5]We fought our way to Nanking and joined in the attack on the enemy capital in December. It was our unit which stormed the Chunghua Gate. We attacked continuously for about a week, battering the brick and earth walls with artillery, but they never collapsed. The night of December 11, men in my unit breached the wall. The morning came with most of our unit still behind us, but we were beyond the wall. Behind the gate great heaps of sandbags were piled up. We 'cleared them away, removed the lock, and opened the gates, with a great creaking noise. We'd done it! We'd opened the fortress! All the enemy ran away, so we didn't take any fire. The residents too were gone. When we passed beyond the fortress wall we thought we had occupied this city.[17]As a response to gunpowder artillery, European fortifications began displaying architectural principles such as lower and thicker walls in the mid-1400s.[18] Cannon towers were built with artillery rooms where cannons could discharge fire from slits in the walls. However this proved problematic as the slow rate of fire, reverberating concussions, and noxious fumes produced greatly hindered defenders. Gun towers also limited the size and number of cannon placements because the rooms could only be built so big. Notable surviving artillery towers include a seven layer defensive structure built in 1480 at Fougères in Brittany, and a four layer tower built in 1479 at Querfurth in Saxony.[19]The star fort, also known as the bastion fort, trace italienne, or renaissance fortress, was a style of fortification that became popular in Europe during the 16th century. The bastion and star fort was developed in Italy, where the Florentine engineer Giuliano da Sangallo (1445–1516) compiled a comprehensive defensive plan using the geometric bastion and full trace italienne that became widespread in Europe.[20]The main distinguishing features of the star fort were its angle bastions, each placed to support their neighbor with lethal crossfire, covering all angles, making them extremely difficult to engage with and attack. Angle bastions consisted of two faces and two flanks. Artillery positions positioned at the flanks could fire parallel into the opposite bastion's line of fire, thus providing two lines of cover fire against an armed assault on the wall, and preventing mining parties from finding refuge. Meanwhile, artillery positioned on the bastion platform could fire frontally from the two faces, also providing overlapping fire with the opposite bastion.[21] Overlapping mutually supporting defensive fire was the greatest advantage enjoyed by the star fort. As a result, sieges lasted longer and became more difficult affairs. By the 1530s the bastion fort had become the dominant defensive structure in Italy.[22]Outside Europe, the star fort became an 'engine of European expansion,'[18] and acted as a force multiplier so that small European garrisons could hold out against numerically superior forces. Wherever star forts were erected the natives experienced great difficulty in uprooting European invaders.[18]In China, Sun Yuanhua advocated for the construction of angled bastion forts in his Xifashenji so that their cannons could better support each other. The officials Han Yun and Han Lin noted that cannons on square forts could not support each side as well as bastion forts. Their efforts to construct bastion forts and their results were inconclusive. Ma Weicheng built two bastion forts in his home county, which helped fend off a Qing incursion in 1638. By 1641, there were ten bastion forts in the county. Before bastion forts could be spread any further, the Ming dynasty fell in 1644, and they were largely forgotten as the Qing dynasty was on the offensive most of the time and had no use for them.[23]In the wake of city growth and the ensuing change of defensive strategy, focusing more on the defense of forts around cities, many city walls were demolished. Also, the invention of gunpowder rendered walls less effective, as siege cannons could then be used to blast through walls, allowing armies to simply march through. Today, the presence of former city fortifications can often only be deduced from the presence of ditches, ring roads or parks.Furthermore, some street names hint at the presence of fortifications in times past, for example when words such as 'wall' or 'glacis' occur. Wall Street in New York City, itself a metonym for the entire United States financial system, is one example.In the 19th century, less emphasis was placed on preserving the fortifications for the sake of their architectural or historical value\xa0–  on the one hand, complete fortifications were restored (Carcassonne), on the other hand many structures were demolished in an effort to modernize the cities. One exception to this is the 'monument preservation' law by the Bavarian King Ludwig I of Bavaria, which led to the nearly complete preservation of many monuments such as the Rothenburg ob der Tauber, Nördlingen and Dinkelsbühl. The countless small fortified towns in the Franconia region were also preserved as a consequence of this edict.Walls and fortified wall structures were still built in the modern era. They did not, however, have the original purpose of being a structure able to resist a prolonged siege or bombardment. Modern examples of defensive walls include:Additionally, in some countries, different embassies may be grouped together in a single 'embassy district', enclosed by a fortified complex with walls and towers\xa0– this usually occurs in regions where the embassies run a high risk of being target of attacks. An early example of such a compound was the Legation Quarter in Beijing in the late 19th and early 20th centuries.Most of these modern city walls are made of steel and concrete. Vertical concrete plates are put together so as to allow the least space in between them, and are rooted firmly in the ground. The top of the wall is often protruding and beset with barbed wire in order to make climbing them more difficult. These walls are usually built in straight lines and covered by watchtowers at the corners. Double walls with an interstitial 'zone of fire', as the former Berlin Wall had, are now rare.In September 2014, Ukraine announced the construction of the 'European Rampart' alongside its border with Russia to be able to successfully apply for a visa-free movement with the European Union.[25]A view of the Berlin Wall in 1986A 'peace line' in Belfast, Northern IrelandThe fortified wall of a police station in Belfast, Northern IrelandAt its simplest, a defensive wall consists of a wall enclosure and its gates. For the most part, the top of the walls were accessible, with the outside of the walls having tall parapets with embrasures or merlons. North of the Alps, this passageway at the top of the walls occasionally had a roof.In addition to this, many different enhancements were made over the course of the centuries:The defensive towers of west and south European fortifications in the Middle Ages were often very regularly and uniformly constructed (cf. Ávila, Provins), whereas Central European city walls tend to show a variety of different styles. In these cases the gate and wall towers often reach up to considerable heights, and gates equipped with two towers on either side are much rarer. Apart from having a purely military and defensive purpose, towers also played a representative and artistic role in the conception of a fortified complex. The architecture of the city thus competed with that of the castle of the noblemen and city walls were often a manifestation of the pride of a particular city.Urban areas outside the city walls, so-called Vorstädte, were often enclosed by their own set of walls and integrated into the defense of the city. These areas were often inhabited by the poorer population and held the 'noxious trades'. In many cities, a new wall was built once the city had grown outside of the old wall. This can often still be seen in the layout of the city, for example in Nördlingen, and sometimes even a few of the old gate towers are preserved, such as the white tower in Nuremberg. Additional constructions prevented the circumvention of the city, through which many important trade routes passed, thus ensuring that tolls were paid when the caravans passed through the city gates, and that the local market was visited by the trade caravans.Furthermore, additional signaling and observation towers were frequently built outside the city, and were sometimes fortified in a castle-like fashion. The border of the area of influence of the city was often partially or fully defended by elaborate ditches, walls and hedges. The crossing points were usually guarded by gates or gate houses. These defenses were regularly checked by riders, who often also served as the gate keepers. Long stretches of these defenses can still be seen to this day, and even some gates are still intact. To further protect their territory, rich cities also established castles in their area of influence. An example of this practice is the Romanian Bran Castle, which was intended to protect nearby Kronstadt (today's Braşov).The city walls were often connected to the fortifications of hill castles via additional walls. Thus the defenses were made up of city and castle fortifications taken together. Several examples of this are preserved, for example in Germany Hirschhorn on the Neckar, Königsberg and Pappenheim, Franken, Burghausen in Oberbayern and many more.A few castles were more directly incorporated into the defensive strategy of the city (e.g. Nuremberg, Zons, Carcassonne), or the cities were directly outside the castle as a sort of 'pre-castle' (Coucy-le-Chateau, Conwy and others). Larger cities often had multiple stewards\xa0–  for example Augsburg was divided into a Reichstadt and a clerical city. These different parts were often separated by their own fortifications.A defensive wall in Taroudannt, MoroccoDefensive walls around the ancient Egyptian settlement of BuhenCastillo San Cristóbal in San Juan, Puerto Rico, a UNESCO World Heritage SiteDefensive wall in Cartagena, ColombiaPart of the wall in San Francisco de Campeche, a UNESCO World Heritage SitePorte St. Louis, part of Ramparts of Quebec City, the only remaining fortified city walls in North America north of MexicoWall of Hittite Capital Hattusa (reconstruction)Derbent Walls, late Sassanian periodWalls of the Ark of BukharaDerawar Wall located in Bahawalpur, PakistanWalls of Kumbhalgarh FortWalls of the Rohtas FortThe defensive walls of Intramuros, the 'Walled City' of old Manila, PhilippinesLate Han dynasty castle (wubi)Fortress and soldiers training, Tang dynastyPrince of Teng Pavilion, Yuan dynastyOld City of Shanghai with walls and seafront.Top of the Beijing city wallBarbican of Linhai city wallWalled tulou villagesDaorson, Bosnia, built around a prehistoric central fortified settlement or acropolis (existed there cca. 17-16th to the end of the Bronze Age, cca. 9-8th c. BCE), surrounded by cyclopean walls (similar to Mycenae) dated to the 4th c. BCE.[26][27]City walls in Ávila, Spain, a UNESCO World Heritage SiteThe remaining section of city walls in town of Svätý Jur, SlovakiaThe walls of Tallinn, Estonia, a UNESCO World Heritage SiteA city gate with its towers, the defensive walls, and the city ditch from the 13th century in Metz, FranceThe medieval fortress overlooking the city of Ohrid in North MacedoniaNarikala fortress, Tbilisi, GeorgiaBadajoz (Spain).The gate of the Gonio castleLugo's Roman walls, Galicia, Spain, a UNESCO World Heritage Site", 'attributes': {'Defensive wall': {}}} (scraper.py:257)
[2022-03-10 02:02:24] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 02:02:24] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1532,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 64406,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 2.458421,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 2, 2, 24, 85798),
 'httpcompression/response_bytes': 250470,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 35,
 'log_count/INFO': 46,
 'memusage/max': 67104768,
 'memusage/startup': 67104768,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 2, 2, 21, 627377)} (statscollectors.py:47)
[2022-03-10 02:02:24] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 02:02:24] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 02:02:24] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1604,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 39499,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 2.45084,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 2, 2, 24, 87376),
 'httpcompression/response_bytes': 141127,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 35,
 'log_count/INFO': 42,
 'memusage/max': 67375104,
 'memusage/startup': 67375104,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 2, 2, 21, 636536)} (statscollectors.py:47)
[2022-03-10 02:02:24] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E6%BE%8E%E6%B9%96%E6%9C%BA%E5%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E4%BE%A6%E5%AF%9F%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Bastion_fort> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Earth_structure> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Palanka_(fortification)> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://en.wikipedia.org/wiki/Serpent%27s_Wall> (referer: https://en.wikipedia.org/w/index.php?title=Special:Search&limit=20&offset=0&profile=default&search=earth%20fortification&ns0=1) (engine.py:250)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Rampart_(fortification)>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Rampart (fortification)', 'url': 'https://en.wikipedia.org/wiki/Rampart_(fortification)', 'date': 202107210138, 'content': "In fortification architecture, a rampart  is a length of bank or wall forming part of the defensive boundary of a castle, hillfort, settlement or other fortified site. It is usually broad-topped and made of excavated earth and/or masonry.[1][2]Many types of early fortification, from prehistory through to the Early Middle Ages, employed earth ramparts usually in combination with external ditches to defend the outer perimeter of a fortified site or settlement.[2] Hillforts, ringforts or 'raths' and ringworks all made use of ditch and rampart defences, and they are the characteristic feature of circular ramparts. The ramparts could be reinforced and raised in height by the use of palisades. This type of arrangement was a feature of the motte and bailey castle of northern Europe in the early medieval period.The composition and design of ramparts varied from the simple mounds of earth and stone, known as dump ramparts, to more complex earth and timber defences (box ramparts and timberlaced ramparts), as well as ramparts with stone revetments.[2] One particular type, common in Central Europe, used earth, stone and timber posts to form a Pfostenschlitzmauer or 'post-slot wall'. Vitrified ramparts were composed of stone that was subsequently fired, possibly to increase its strength.[2]During the classical era, societies became sophisticated enough to create tall ramparts of stone or brick, provided with a platform or wall walk for the defenders to hurl missiles from and a parapet to protect them from the missiles thrown by attackers. Well known examples of classical stone ramparts include Hadrian's Wall and the Walls of Constantinople.After the fall of the Roman Empire in Europe, there was a return to the widespread use of earthwork ramparts which lasted well into the 11th century, an example is the Norman motte and bailey castle. As castle technology evolved during the Middle Ages and Early Modern times, ramparts continued to form part of the defences, but now they tended to consist of thick walls with crenellated parapets.[3] Fieldworks, however, continued to make use of earth ramparts due to their relatively temporary nature.In response to the introduction of artillery, castle ramparts began to be built with much thicker walling and a lower profile, one of earliest examples first being Ravenscraig Castle in Scotland which was built in 1460.[5] In the first half of the 16th century, the solid masonry walls began to be replaced by earthen banks, sometimes faced with stone, which were better able to withstand the impact of shot; the earth being obtained from the ditch which was dug in front of the rampart. At the same time, the plan or 'trace' of these ramparts began to be formed into angular projections called bastions which allowed the guns mounted on them to create zones of interlocking fire.[6] This bastion system became known as the trace italienne because Italian engineers had been at the forefront of its development, although it was later perfected in northern Europe by engineers such as Coehoorn and Vauban and was the dominant style of fortification until the mid-19th century.As well as the immediate archaeological significance of such ramparts in indicating the development of military tactics and technology, these sites often enclose areas of historical significance that point to the local conditions at the time the fortress was built.[2]", 'attributes': {'Rampart (fortification)': {}}} (scraper.py:257)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/RPG-29>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'RPG-29', 'url': 'https://en.wikipedia.org/wiki/RPG-29', 'date': 202202081156, 'content': "The RPG-29 'Vampir' is a Soviet reusable rocket-propelled grenade (RPG) launcher. Adopted by the Soviet Army in 1989,[5] it was the last RPG to be adopted by the Soviet military before the fall of the Soviet Union in 1991.The RPG-29 has since been supplemented by other rocket-propelled systems, such as the RPG-30 and RPG-32. The RPG-29 has been implicated in an attack on the British Challenger 2 tanks in Iraq, as well as in attacks on Israeli Merkava tanks in Lebanon, which breached the tanks' armor and in some cases injured or killed members of the crew.[6][7]The RPG-29 is a shoulder-launched, unguided, tube-style, breech-loading anti-tank rocket system with a range of 500 meters. The light weapon is designed to be carried and used by a single soldier. On the top of the launch tube is a 2.7× 1P38 optical sight.When launched, the missile deploys eight fins as the rocket leaves the launcher, stabilizing the rocket during flight, up to a range of 500 meters.[8]Two warheads are available for the weapon:The RPG-29 is unusual among Russian anti-tank rocket launchers in that it lacks an initial propellant charge to place the projectile at a safe distance from the operator before the rocket ignites. Instead, the rocket engine starts as soon as the trigger is pulled, and burns out before the projectile leaves the barrel.On the bottom of the tube is a shoulder brace for proper positioning along with a pistol grip trigger mechanism. A 1PN51-2 night sight can be fitted.[10]The RPG-29 was developed during the late 1980s, following the development of the RPG-26, and entered service with the Soviet Army in 1989. It has recently seen intermittent use by irregular forces in the Middle East theater, including in combat against Allied forces during the Iraq War, and the 2006 Lebanon War, when it was used against Israeli forces.The RPG-29 is believed to have been used in skirmishes against American and British forces during the initial 2003 invasion of Iraq.[11] An RPG-29 round was reported in August 2006 to have penetrated the frontal underside hull (equipped with ERA) of a Challenger 2 tank during an engagement in al-Amarah, Iraq, maiming one and wounding several other crew members, but only lightly damaging the tank, which drove home under its own power.[12]On August 25, 2007 a PG-29V hit a passing M1 Abrams in the hull rear wounding 3 crew members.[13] On September 5, 2007, a PG-29V hit the side turret of an M1 Abrams in Baghdad, killing 2 of the crew and wounding 1, and the tank was seriously damaged.[14]In May 2008, The New York Times disclosed that another M1 Abrams tank had also been damaged by an RPG-29 in Iraq, while fighting Shia militias at Sadr City.[11] The US Army ranks the RPG-29 threat to armor so high that they refused to allow the newly formed Iraqi army to buy it, fearing that it would fall into insurgent hands.[15]During the conflict, the Israeli newspaper Haaretz stated that the RPG-29 was a major source of IDF casualties in the 2006 Lebanon War.[16] A spokesman for the Russian Foreign Ministry denied that Russia had supplied arms directly to Hezbollah.[17] Shortly before the end of the conflict the Russian  Kommersant magazine acknowledged through anonymous sources the possibility of a weapons transfer between Syria and Hezbollah during the Syrian withdrawal from Lebanon.[18]During the Syrian Civil War, Syrian Opposition Forces and ISIL both used RPG-29s.[19]The cartels are known to have smuggled RPG-29s with some seized by Mexican forces.[20]During the 2014 Gaza War, Hamas had used RPG-29s to attack IDF Merkava tanks, however because of the recently developed Trophy (countermeasure) they had little effect.[21]During the Iraqi Civil War, ISIL has used RPG-29s in Iraq, probably ones taken in Syria. And anti-ISIL Shia militias in Iraq have also used RPG-29s, the Iranian produced 'Ghadir', which was supplied by Iran.", 'attributes': {'RPG-29': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/RPG-29_operators.png/400px-RPG-29_operators.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/RPG-29_USGov.JPG/300px-RPG-29_USGov.JPG'], 'Type': 'Rocket-propelled grenade', 'Placeoforigin': 'Soviet Union', 'Inservice': '1989–present', 'Usedby': 'See Operators', 'Wars': 'Iraq War;2014 Gaza WarIraqi Civil War', 'Designer': 'Bazalt', 'Designed': 'late 1980s', 'Manufacturer': 'Bazalt', 'Produced': '1989', 'Mass': '12.1kg (27lb) unloaded (with optical sight) 18.8kg (41lb) loaded (ready to fire)', 'Length': '1m (3ft 3in) (disassembled for transportation)1.85m (6ft 1in) (ready to fire)', 'Cartridge': 'PG-29V tandem rocketTBG-29V thermobaric rounds', 'Caliber': '105mm (4.1in) barrel 65 and 105mm (2.6 and 4.1in) warheads', 'Muzzlevelocity': '280m/s (920ft/s)', 'Effectivefiringrange': '500m (1,600ft)800m (2,600ft) (with tripod and fire control unit)', 'Sights': 'Iron, optical, and night sights available with ranges up to 450m (1,480ft); automated day and day-night sights with laser rangefinder', 'Blastyield': '750mm (30in) RHA650mm (26in) RHA after ERA1,500mm (59in) Reinforced concrete 3,700mm (150in) Log and earth fortification'}}} (scraper.py:257)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Fortification>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Fortification', 'url': 'https://en.wikipedia.org/wiki/Fortification', 'date': 202202230412, 'content': "A fortification is a military construction or building designed for the defense of territories in warfare, and is also used to establish rule in a region during peacetime. The term is derived from Latin fortis ('strong') and facere ('to make').From very early history to modern times, defensive walls have often been necessary for cities to survive in an ever-changing world of invasion and conquest. Some settlements in the Indus Valley Civilization were the first small cities to be fortified. In ancient Greece, large stone walls had been built in Mycenaean Greece, such as the ancient site of Mycenae (famous for the huge stone blocks of its 'cyclopean' walls). A Greek phrourion was a fortified collection of buildings used as a military garrison, and is the equivalent of the Roman castellum or English fortress. These constructions mainly served the purpose of a watch tower, to guard certain roads, passes, and borders. Though smaller than a real fortress, they acted as a border guard rather than a real strongpoint to watch and maintain the border.The art of setting out a military camp or constructing a fortification traditionally has been called 'castrametation' since the time of the Roman legions. Fortification is usually divided into two branches: permanent fortification and field fortification. There is also an intermediate branch known as semi-permanent fortification. Castles are fortifications which are regarded as being distinct from the generic fort or fortress in that they are a residence of a monarch or noble and command a specific defensive territory.Roman forts and hill forts were the main antecedents of castles in Europe, which emerged in the 9th century in the Carolingian Empire. The Early Middle Ages saw the creation of some towns built around castles.Medieval-style fortifications were largely made obsolete by the arrival of cannons in the 14th century. Fortifications in the age of black powder evolved into much lower structures with greater use of ditches and earth ramparts that would absorb and disperse the energy of cannon fire. Walls exposed to direct cannon fire were very vulnerable, so the walls were sunk into ditches fronted by earth slopes to improve protection.The arrival of explosive shells in the 19th century led to yet another stage in the evolution of fortification. Star forts did not fare well against the effects of high explosive, and the intricate arrangements of bastions, flanking batteries and the carefully constructed lines of fire for the defending cannon could be rapidly disrupted by explosive shells. Steel-and-concrete fortifications were common during the 19th and early 20th centuries. The advances in modern warfare since World War I have made large-scale fortifications obsolete in most situations.Many United States Army installations are known as forts, although they are not always fortified. Indeed, during the pioneering era of North America, many outposts on the frontiers, even non-military outposts, were referred to generically as forts. Larger military installations may be called fortresses; smaller ones were once known as fortalices. The word fortification can also refer to the practice of improving an area's defense with defensive works. City walls are fortifications but are not necessarily called fortresses.The art of setting out a military camp or constructing a fortification traditionally has been called castrametation since the time of the Roman legions. The art/science of laying siege to a fortification and of destroying it is commonly called siegecraft or siege warfare and is formally known as poliorcetics. In some texts this latter term also applies to the art of building a fortification.Fortification is usually divided into two branches: permanent fortification and field fortification. Permanent fortifications are erected at leisure, with all the resources that a state can supply of constructive and mechanical skill, and are built of enduring materials. Field fortifications—for example breastworks—and often known as fieldworks or earthworks, are extemporized by troops in the field, perhaps assisted by such local labour and tools as may be procurable and with materials that do not require much preparation, such as earth, brushwood and light timber, or sandbags (see sangar). An example of field fortification[1] was the construction of Fort Necessity by George Washington in 1754.There is also an intermediate branch known as semi-permanent fortification.[2] This is employed when in the course of a campaign it becomes desirable to protect some locality with the best imitation of permanent defences that can be made in a short time, ample resources and skilled civilian labour being available. An example of this is the construction of Roman forts in England and in other Roman territories where camps were set up with the intention of staying for some time, but not permanently.Castles are fortifications which are regarded as being distinct from the generic fort or fortress in that it describes a residence of a monarch or noble and commands a specific defensive territory. An example of this is the massive medieval castle of Carcassonne.From very early history to modern times, walls have been a necessity for many cities. In Bulgaria, near the town of Provadia a walled fortified settlement today called Solnitsata starting from 4700 BC had a diameter of about 300 feet (100 meters), was home to 350 people living in two-storey houses, and was encircled by a fortified wall. The huge walls around the settlement, which were built very tall and with stone blocks which are 6 feet (2 meters) high and 4.5 feet (1.5 meters) thick, make it one of the earliest walled settlements in Europe[3][4] but it is younger than the walled town of Sesklo in Greece from 6800 BC.[5][6] Uruk in ancient Sumer (Mesopotamia) is one of the world's oldest known walled cities. The Ancient Egyptians also built fortresses on the frontiers of the Nile Valley to protect against invaders from neighbouring territories, as well as circle-shaped mud brick walls around their cities. Many of the fortifications of the ancient world were built with mud brick, often leaving them no more than mounds of dirt for today's archaeologists.A massive prehistoric stone wall surrounded the ancient temple of Ness of Brodgar 3200 BC in Scotland. Named the 'Great Wall of Brodgar' it was four metres thick and four metres tall. The wall had some symbolic or ritualistic function.[7][8] The Assyrians deployed large labour forces to build new palaces, temples and defensive walls.[9]Some settlements in the Indus Valley Civilization were also fortified. By about 3500 BC, hundreds of small farming villages dotted the Indus floodplain. Many of these settlements had fortifications and planned streets. The stone and mud brick houses of Kot Diji were clustered behind massive stone flood dykes and defensive walls, for neighbouring communities bickered constantly about the control of prime agricultural land.[10] Mundigak (c. 2500 BC) in present-day south-east Afghanistan has defensive walls and square bastions of sun dried bricks.[11] The entire city of Kerma in Nubia was encompassed by fortified walls surrounded by a ditch. Archaeology has revealed various Bronze Age bastions and foundations constructed of stone together with either baked or unfired brick.[12] In Bronze Age Malta, some settlements also began to be fortified. The most notable surviving example is Borġ in-Nadur, where a bastion built in around 1500 BC was found. Babylon was one of the most famous cities of the ancient world, especially as a result of the building program of Nebuchadnezzar, who expanded the walls and built the Ishtar Gate. Exceptions were few—notably, ancient Sparta and ancient Rome did not have walls for a long time, choosing to rely on their militaries for defence instead. Initially, these fortifications were simple constructions of wood and earth, which were later replaced by mixed constructions of stones piled on top of each other without mortar. In ancient Greece, large stone walls had been built in Mycenaean Greece, such as the ancient site of Mycenae (famous for the huge stone blocks of its 'cyclopean' walls). In classical era Greece, the city of Athens built two parallel stone walls, called the Long Walls, that reached their fortified seaport at Piraeus a few miles away.In Central Europe, the Celts built large fortified settlements known as oppida, whose walls seem partially influenced by those built in the Mediterranean. The fortifications were continuously being expanded and improved. Around 600 BC, in Heuneburg, Germany, forts were constructed with a limestone foundation supported by a mudbrick wall approximately 4 metres tall, probably topped by a roofed walkway, thus reaching a total height of 6 metres. The wall was clad with lime plaster, regularly renewed. Towers protruded outwards from it.[13][14]The Oppidum of Manching (German: Oppidum von Manching) was a large Celtic proto-urban or city-like settlement at modern-day Manching (near Ingolstadt), Bavaria (Germany). The settlement was founded in the 3rd century BC and existed until c. 50–30 BC. It reached its largest extent during the late La Tène period (late 2nd century BC), when it had a size of 380 hectares. At that time, 5,000 to 10,000 people lived within its 7.2\xa0km long walls. The oppidum of Bibracte is another example of a Gaulish fortified settlement.The Mura aureliane are a line of city walls built between 271 AD and 275 AD in Rome, Italy, during the reign of the Roman Emperors Aurelian and Probus. The walls enclosed all the seven hills of Rome plus the Campus Martius and, on the right bank of the Tiber, the Trastevere district. The river banks within the city limits appear to have been left unfortified, although they were fortified along the Campus Martius. The full circuit ran for 19 kilometres (12\xa0mi) surrounding an area of 13.7 square kilometres (5.3\xa0sq\xa0mi). The walls were constructed in brick-faced concrete, 3.5 metres (11\xa0ft) thick and 8 metres (26\xa0ft) high, with a square tower every 100 Roman feet (29.6 metres (97\xa0ft)). In the 5th century, remodelling doubled the height of the walls to 16 metres (52\xa0ft). By 500 AD, the circuit possessed 383 towers, 7,020 crenellations, 18 main gates, 5 postern gates, 116 latrines, and 2,066 large external windows.[15]The Romans fortified their cities with massive, mortar-bound stone walls. The most famous of these are the largely extant Aurelian Walls of Rome and the Theodosian Walls of Constantinople, together with partial remains elsewhere. These are mostly city gates, like the Porta Nigra in Trier or Newport Arch in Lincoln. Hadrian's Wall was built by the Roman Empire across the width of what is now northern England following a visit by Roman Emperor Hadrian (AD\xa076–138) in AD\xa0122.A number of forts dating from the Later Stone Age to the British Raj may be found in India. 'Fort' is the word used in India for all old fortifications. Numerous Indus Valley Civilization sites exhibit evidences of fortifications. While Dholavira has stone-built fortification walls, Harrapa is fortified using baked bricks; sites such as Kalibangan exhibit mudbrick fortifications with bastions and Lothal has a quadrangular fortified layout. Evidence also suggested of fortifications in Mohenjo-daro. Even a small town – for instance, Kotada Bhadli, exhibiting sophisticated fortification-like bastions – shows that nearly all major and minor towns of the Indus Valley Civilization were fortified.[16] Forts also appeared in urban cities of the Gangetic valley during the second urbanisation period between 600 and 200 BC, and as many as 15 fortification sites have been identified by archaeologists throughout the Gangetic valley, such as Kaushambi, Mahasthangarh, Pataliputra, Mathura, Ahichchhatra, Rajgir, and Lauria Nandangarh. The earliest vedic brick fortification occurs in one of the stupa mounds of Lauria Nandangarh, which is 1.6\xa0km in perimeter and oval in plan and encloses a habitation area.[17] India currently has over 180 forts, with the state of Maharashtra alone having over 70 forts, which are also known as durg,[18][19][20] many of them built by Shivaji, founder of the Maratha state. A large majority of forts in India are in North India. The most notable forts are the Red Fort at Delhi, the Red Fort at Agra, the Chittor Fort and Mehrangarh Fort in Rajasthan, the Ranthambhor Fort, Amer Fort and Jaisalmer Fort also in Rajasthan and Gwalior Fort in Madhya Pradesh.[19]Large tempered earth (i.e. rammed earth) walls were built in ancient China since the Shang dynasty (c. 1600–1050 BC); the capital at ancient Ao had enormous walls built in this fashion (see siege for more info). Although stone walls were built in China during the Warring States (481–221 BC), mass conversion to stone architecture did not begin in earnest until the Tang dynasty (618–907 AD). The Great Wall of China had been built since the Qin dynasty (221–207 BC), although its present form was mostly an engineering feat and remodelling of the Ming dynasty (1368–1644 AD).In addition to the Great Wall, a number of Chinese cities also employed the use of defensive walls to defend their cities. Notable Chinese city walls include the city walls of Hangzhou, Nanjing, the Old City of Shanghai, Suzhou, Xi'an and the walled villages of Hong Kong. The famous walls of the Forbidden City in Beijing were established in the early 15th century by the Yongle Emperor. The Forbidden City made up the inner portion of the Beijing city fortifications.During the Spanish Era several forts and outposts were built throughout the archipelago. Most notable is Intramuros, the old walled city of Manila located along the southern bank of the Pasig River.[21] The historic city was home to centuries-old churches, schools, convents, government buildings and residences, the best collection of Spanish colonial architecture before much of it was destroyed by the bombs of World War II. Of all the buildings within the 67-acre city, only one building, the San Agustin Church, survived the war.Partial listing of Spanish forts:The Ivatan people of the northern islands of Batanes built their so-called idjang on hills and elevated areas[22] to protect themselves during times of war. These fortifications were likened to European castles because of their purpose. Usually, the only entrance to the castles would be via a rope ladder that would only be lowered for the villagers and could be kept away when invaders arrived.The Igorots built forts made of stone walls that averaged several meters in width and about two to three times the width in height around 2000 BC.[23]The Muslim Filipinos of the south built strong fortresses called kota or moong to protect their communities. Usually, many of the occupants of these kotas are entire families rather than just warriors. Lords often had their own kotas to assert their right to rule, it served not only as a military installation but as a palace for the local Lord. It is said that at the height of the Maguindanao Sultanate's power, they blanketed the areas around Western Mindanao with Kotas and other fortifications to block the Spanish advance into the region. These kotas were usually made of stone and bamboo or other light materials and surrounded by trench networks. As a result, some of these kotas were burned easily of destroyed. With further Spanish campaigns in the region, the Sultanate was subdued and majority of Kotas dismantled or destroyed. Kotas were not only used by the Muslims as defense against Spaniards and other foreigners, renegades and rebels also built fortifications in defiance of other chiefs in the area.[24] During the American occupation, rebels built strongholds and the Datus, Rajahs or Sultans often built and reinforced their kotas in a desperate bid to maintain rule over their subjects and their land.[25] Many of these forts were also destroyed by American expeditions, as a result, very very few kotas still stand to this day.Notable Kotas:During Muhammad's era in Arabia, many tribes made use of fortifications. In the Battle of the Trench, the largely outnumbered defenders of Medina, mainly Muslims led by Islamic prophet Muhammad, dug a trench, which together with Medina's natural fortifications, rendered the confederate cavalry (consisting of horses and camels) useless, locking the two sides in a stalemate. Hoping to make several attacks at once, the confederates persuaded the Medina-allied Banu Qurayza to attack the city from the south. However, Muhammad's diplomacy derailed the negotiations, and broke up the confederacy against him. The well-organized defenders, the sinking of confederate morale, and poor weather conditions caused the siege to end in a fiasco.[27]During the Siege of Ta'if in January 630,[28] Muhammad ordered his followers to attack enemies who fled from the Battle of Hunayn and sought refuge in the fortress of Taif.[29]The walls of Benin are described as the world's second longest man-made structure, as well as the most extensive earthwork in the world, by the Guinness Book of Records, 1974.[30][31] The walls may have been constructed between the thirteenth and mid-fifteenth century CE[32] or, during the first millennium CE.[32][33]Strong citadels were also built other in areas of Africa. Yorubaland for example had several sites surrounded by the full range of earthworks and ramparts seen elsewhere, and sited on ground. This improved defensive potential- such as hills and ridges. Yoruba fortifications were often protected with a double wall of trenches and ramparts, and in the Congo forests concealed ditches and paths, along with the main works, often bristled with rows of sharpened stakes. Inner defenses were laid out to blunt an enemy penetration with a maze of defensive walls allowing for entrapment and crossfire on opposing forces.[34]A military tactic of the Ashanti was to create powerful log stockades at key points. This was employed in later wars against the British to block British advances. Some of these fortifications were over a hundred yard long, with heavy parallel tree trunks. They were impervious to destruction by artillery fire. Behind these stockades numerous Ashanti soldiers were mobilized to check enemy movement. While formidable in construction, many of these strongpoints failed because Ashanti guns, gunpowder and bullets were poor, and provided little sustained killing power in defense. Time and time again British troops overcame or bypassed the stockades by mounting old-fashioned bayonet charges, after laying down some covering fire.[35]Defensive works were of importance in the tropical African Kingdoms. In the Kingdom of Kongo field fortifications were characterized by trenches and low earthen embankments. Such strongpoints ironically, sometimes held up much better against European cannon than taller, more imposing structures.[36]Roman forts and hill forts were the main antecedents of castles in Europe, which emerged in the 9th century in the Carolingian Empire. The Early Middle Ages saw the creation of some towns built around castles. These cities were only rarely protected by simple stone walls and more usually by a combination of both walls and ditches. From the 12th century hundreds of settlements of all sizes were founded all across Europe, which very often obtained the right of fortification soon afterwards.The founding of urban centres was an important means of territorial expansion and many cities, especially in eastern Europe, were founded precisely for this purpose during the period of Eastern Colonisation. These cities are easy to recognise due to their regular layout and large market spaces. The fortifications of these settlements were continuously improved to reflect the current level of military development.During the Renaissance era, the Venetian Republic raised great walls around cities, and the finest examples, among others, are in Nicosia (Cyprus), Rocca di Manerba del Garda (Lombardy) and Palmanova (Italy), or Dubrovnik (Croatia), which proved to be futile against attacks but still stand to this day. Unlike Venetians the Ottomans used to built smaller fortifications but in greater numbers, and only rarely fortified entire settlements such as Počitelj, Vratnik and Jajce in Bosnia.Medieval-style fortifications were largely made obsolete by the arrival of cannons on the 14th century battlefield. Fortifications in the age of black powder evolved into much lower structures with greater use of ditches and earth ramparts that would absorb and disperse the energy of cannon fire. Walls exposed to direct cannon fire were very vulnerable, so were sunk into ditches fronted by earth slopes.This placed a heavy emphasis on the geometry of the fortification to allow defensive cannonry interlocking fields of fire to cover all approaches to the lower and thus more vulnerable walls.The evolution of this new style of fortification can be seen in transitional forts such as Sarzanello[37] in North West Italy which was built between 1492 and 1502. Sarzanello consists of both crenellated walls with towers typical of the medieval period but also has a ravelin like angular gun platform screening one of the curtain walls which is protected from flanking fire from the towers of the main part of the fort. Another example are the fortifications of Rhodes which were frozen at 1522 so that Rhodes is the only European walled town that still shows the transition between the classical medieval fortification and the modern ones.[38]Fortifications also extended in depth, with protected batteries for defensive cannonry, to allow them to engage attacking cannon to keep them at a distance and prevent them bearing directly on the vulnerable walls.The result was star shaped fortifications with tier upon tier of hornworks and bastions, of which Fort Bourtange is an excellent example. There are also extensive fortifications from this era in the Nordic states and in Britain, the fortifications of Berwick-upon-Tweed and the harbour archipelago of Suomenlinna at Helsinki being fine examples.The arrival of explosive shells in the 19th century led to yet another stage in the evolution of fortification. Star forts did not fare well against the effects of high explosive and the intricate arrangements of bastions, flanking batteries and the carefully constructed lines of fire for the defending cannon could be rapidly disrupted by explosive shells.Worse, the large open ditches surrounding forts of this type were an integral part of the defensive scheme, as was the covered way at the edge of the counter scarp. The ditch was extremely vulnerable to bombardment with explosive shells.In response, military engineers evolved the polygonal style of fortification. The ditch became deep and vertically sided, cut directly into the native rock or soil, laid out as a series of straight lines creating the central fortified area that gives this style of fortification its name.Wide enough to be an impassable barrier for attacking troops, but narrow enough to be a difficult target for enemy shellfire, the ditch was swept by fire from defensive blockhouses set in the ditch as well as firing positions cut into the outer face of the ditch itself.The profile of the fort became very low indeed, surrounded outside the ditch covered by caponiers by a gently sloping open area so as to eliminate possible cover for enemy forces, while the fort itself provided a minimal target for enemy fire. The entrypoint became a sunken gatehouse in the inner face of the ditch, reached by a curving ramp that gave access to the gate via a rolling bridge that could be withdrawn into the gatehouse.Much of the fort moved underground. Deep passages and tunnels now connected the blockhouses and firing points in the ditch to the fort proper, with magazines and machine rooms deep under the surface. The guns, however, were often mounted in open emplacements and protected only by a parapet; both in order to keep a lower profile and also because experience with guns in closed casemates had seen them put out of action by rubble as their own casemates were collapsed around them.Gone were citadels surrounding towns: forts were to be moved to the outside of the cities some 12\xa0km to keep the enemy at a distance so their artillery could not bombard the city center. From now on a ring of forts were to be built at a spacing that would allow them to effectively cover the intervals between them.The new forts abandoned the principle of the bastion, which had also been made obsolete by advances in arms. The outline was a much simplified polygon, surrounded by a ditch. These forts, built in masonry and shaped stone, were designed to shelter their garrison against bombardment. One organizing feature of the new system involved the construction of two defensive curtains: an outer line of forts, backed by an inner ring or line at critical points of terrain or junctions (see, for example, Séré de Rivières system in France).Traditional fortification however continued to be applied by European armies engaged in warfare in colonies established in Africa against lightly armed attackers from amongst the indigenous population. A relatively small number of defenders in a fort impervious to primitive weaponry could hold out against high odds, the only constraint being the supply of ammunition.Steel-and-concrete fortifications were common during the 19th and early 20th centuries. However the advances in modern warfare since World War I have made large-scale fortifications obsolete in most situations. In the 1930s and 1940s, some fortifications were built with designs taking into consideration the new threat of aerial warfare, for example Fort Campbell in Malta.[39] Despite this, only underground bunkers are still able to provide some protection in modern wars. Many historical fortifications were demolished during the modern age, but a considerable number survive as popular tourist destinations and prominent local landmarks today.The downfall of permanent fortifications had two causes:Instead field fortification rose to dominate defensive action. Unlike the trench warfare which dominated World War I, these defences were more temporary in nature. This was an advantage because since it was less extensive it formed a less obvious target for enemy force to be directed against.If sufficient power were massed against one point to penetrate it, the forces based there could be withdrawn and the line could be re-established relatively quickly. Instead of a supposedly impenetrable defensive line, such fortifications emphasized defence in depth, so that as defenders were forced to pull back or were overrun, the lines of defenders behind them could take over the defence.Because the mobile offensives practised by both sides usually focused on avoiding the strongest points of a defensive line, these defences were usually relatively thin and spread along the length of a line. The defence was usually not equally strong throughout however.The strength of the defensive line in an area varied according to how rapidly an attacking force could progress in the terrain that was being defended—both the terrain the defensive line was built on and the ground behind it that an attacker might hope to break out into. This was both for reasons of the strategic value of the ground, and its defensive value.This was possible because while offensive tactics were focused on mobility, so were defensive tactics. The dug in defences consisted primarily of infantry and antitank guns. Defending tanks and tank destroyers would be concentrated in mobile brigades behind the defensive line. If a major offensive was launched against a point in the line, mobile reinforcements would be sent to reinforce that part of the line that was in danger of failing.Thus the defensive line could be relatively thin because the bulk of the fighting power of the defenders was not concentrated in the line itself but rather in the mobile reserves. A notable exception to this rule was seen in the defensive lines at the Battle of Kursk during World War II, where German forces deliberately attacked into the strongest part of the Soviet defences seeking to crush them utterly.The terrain that was being defended was of primary importance because open terrain that tanks could move over quickly made possible rapid advances into the defenders' rear areas that were very dangerous to the defenders. Thus such terrain had to be defended at all cost.In addition, since in theory the defensive line only had to hold out long enough for mobile reserves to reinforce it, terrain that did not permit rapid advance could be held more weakly because the enemy's advance into it would be slower, giving the defenders more time to reinforce that point in the line. For example, the battle of the Hurtgen Forest in Germany during the closing stages of World War II is an excellent example of how difficult terrain could be used to the defenders' advantage.After World War II, ICBMs capable of reaching much of the way around the world were developed, and so speed became an essential characteristic of the strongest militaries and defenses. Missile silos were developed, so missiles could be fired from the middle of a country and hit cities and targets in another country, and airplanes (and air carriers) became major defenses and offensive weapons (leading to an expansion of the use of airports and airstrips as fortifications). Mobile defenses could be had underwater, too, in the form of nuclear submarines capable of firing missiles. Some bunkers in the mid to late 20th century came to be buried deep inside mountains and prominent rocks, such as Gibraltar and the Cheyenne Mountain Complex. On the ground itself, minefields have been used as hidden defences in modern warfare, often remaining long after the wars that produced them have ended.Demilitarized zones along borders are arguably another type of fortification, although a passive kind, providing a buffer between potentially hostile militaries.Military airfields offer a fixed 'target rich' environment for even relatively small enemy forces, using hit-and-run tactics by ground forces, stand-off attacks (mortars and rockets), air attacks, or ballistic missiles. Key targets – aircraft, munitions, fuel, and vital technical personnel – can be protected by fortifications.Aircraft can be protected by revetments, Hesco barriers, or hardened aircraft shelters which will protect from many types of attack. Larger aircraft types tend to be based outside the operational theatre.Munition storage follows safety rules which use fortifications (bunkers and bunds) to provide protection against accident and chain reactions (sympathetic detonations). Weapons for rearming aircraft can be stored in small fortified expense stores closer to the aircraft. At Bien Hoa South Vietnam on the morning of 16 May 1965, as aircraft were being re-fuelled and armed, a chain reaction explosion destroyed 13 aircraft, killed 34 personnel, and injured over 100; this, along with damage and losses of aircraft to enemy attack (by both infiltration and stand off attacks), led to the construction of revetments and shelters to protect aircraft throughout South Vietnam.Aircrew and ground personnel will need protection during enemy attacks and fortifications range from culvert section 'duck and cover' shelters to permanent air-raid shelters. Soft locations with high personnel densities such as accommodation and messing facilities can have limited protection by placing prefabricated concrete walls or barriers around them, examples of barriers are Jersey Barriers, T Barriers or Splinter Protection Units (SPUs). Older fortification may prove useful such as the old 'Yugo' pyramid shelters built in the 1980s which were used by US personnel on 8 Jan 2020 when Iran fired 11 ballistic missiles at Ayn al-Asad Airbase in Iraq.Fuel is volatile and has to comply with rules for storage which provide protection against accident. Fuel in underground bulk fuel installations is well protected though valves and controls are vulnerable to enemy action. Above ground tanks can be susceptible to attack.Ground support equipment will need to be protected by fortifications to be usable after an enemy attack.Permanent (concrete) guard fortifications are safer, stronger, last longer and are more cost effective than sandbag fortifications. Prefabricated positions can be made from concrete culvert sections. The British Yarnold Bunker is made from sections of a concrete pipe.Guard Towers provide increased field of view but a lower level of protection.Dispersal and camouflage of assets can supplement fortifications against some forms of airfield attack.Just as in colonial periods, comparatively obsolete fortifications are still used for low-intensity conflicts. Such fortifications range in size from small patrol bases or forward operating bases up to huge airbases such as Camp Bastion/Leatherneck in Afghanistan. Much like in the 18th and 19th century, because the enemy is not a powerful military force with the heavy weaponry required to destroy fortifications, walls of gabion, sandbag or even simple mud can provide protection against small arms and anti-tank weapons – although such fortifications are still vulnerable to mortar and artillery fire.Forts in modern American usage often refer to space set aside by governments for a permanent military facility; these often do not have any actual fortifications, and can have specializations (military barracks, administration, medical facilities, or intelligence).However, there are some modern fortifications that are referred to as forts. These are typically small semi permanent fortifications. In urban combat they are built by upgrading existing structures such as houses or public buildings. In field warfare they are often log, sandbag or gabion type construction.Such forts are typically only used in low level conflict, such as counterinsurgency conflicts or very low level conventional conflicts, such as the Indonesia–Malaysia confrontation, which saw the use of log forts for use by forward platoons and companies. The reason for this is that static above ground forts can not survive modern direct or indirect fire weapons larger than mortars, RPGs and small arms.Fortifications designed to keep the inhabitants of a facility in rather than attacker out can also be found, in prisons, concentration camps, and other such facilities, with supermaxes having some of the strongest of those. Those are covered in other articles, as most prisons and concentration camps are not primarily military forts (although forts, camps, and garrison towns have been used as prisons and/or concentration camps; such as Theresienstadt, Guantanamo Bay detention camp and the Tower of London for example).Fort componentsTypes of forts and fortificationFortification and siege warfareNotable experts", 'attributes': {'Fortification': {}}} (scraper.py:257)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Songyue_Pagoda>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Songyue Pagoda', 'url': 'https://en.wikipedia.org/wiki/Songyue_Pagoda', 'date': 202104171423, 'content': "The Songyue Pagoda (Chinese: 嵩岳寺塔; pinyin: Sōngyuè sìtǎ), constructed in AD 523, is located at the Songyue Monastery on Mount Song, in Henan province, China.[1] Built during the Northern Wei Dynasty, this pagoda is one of the few intact sixth-century pagodas in China and is also the earliest known Chinese brick pagoda.[1] Most structures from that period were made of wood and have not survived, although ruins of rammed earth fortifications still exist.[2][3] In 2010, the Pagoda was inscribed on the UNESCO World Heritage List along with other nearby monuments as part of the 'Historic Monuments of Dengfeng in “The Centre of Heaven and Earth”' site. [4]The spread of Buddhism dramatically influenced Chinese architecture. By the sixth century, Buddhism had spread with tremendous momentum throughout China: Chinese culture was adjusting and adapting its traditions to include Buddhism worship.[2] The Chinese transformed the rounded earthen mound of the South Asian stupa into the towering pagoda to house the sacred buried relics of Buddha at its core.[2][3][5]The pagoda has had a changing shape over time from its Indian Buddhist origins to its form in China.  The unique many-sided shape of the Songyue Pagoda suggests that it represents an early attempt to merge the Chinese architecture of straight edges with the circular style of Buddhism from the Indian subcontinent. The perimeter of the pagoda decreases as it rises, as this is seen in Indian and Central Asian Buddhist cave temple pillars and the later round pagodas in China.[2]The Songyue Pagoda is unique in form, being twelve-sided. The tower is 40\xa0m (131\xa0ft) high and built of yellowish brick held together with clay mortar.[6] It is the oldest surviving pagoda and was built at a time when, according to records, almost all pagodas were composed of wood.[3][5]The pagoda has a low, plain brick pedestal or base,  and a very high first story characteristic of pagodas with  multiple eaves, with balconies dividing the first story into two layers and doors connecting the two parts. The   ornamented arch doors and decorative apses or niches are intricately carved into teapots or lions. At the base of the door pillars are carvings shaped as lotus flowers and the  pillar capitals have carved  pearls and lotus flowers. After the first story there are fifteen  closely spaced roofs lined with eaves and  small lattice windows. The pagoda features densely clustered ornamental bracked eaves in the dougong style ornamenting each story. Inside the pagoda,  the wall is cylindrical with eight levels of projecting stone supports for what was probably  wooden flooring originally.[3] Beneath the pagoda is an underground series of   burial rooms to preserve  cultural objects buried with the dead. The inner most chamber contained Buddhist relics, transcripts of Buddhist scriptures and statues of Buddha.[7]", 'attributes': {'Songyue Pagoda': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Pagoda_of_Songyue_Temple%2C_2015-09-25_08.jpg/220px-Pagoda_of_Songyue_Temple%2C_2015-09-25_08.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Pagoda_of_Songyue_Temple%2C_2015-09-25_20.jpg/220px-Pagoda_of_Songyue_Temple%2C_2015-09-25_20.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1d/Map_Henan_adm.png/240px-Map_Henan_adm.png'], 'Affiliation': 'Buddhism', 'Country': 'Dengfeng, Zhengzhou, Henan', 'Geographic coordinates': '34°30′06″N 113°00′57″E\ufeff / \ufeff34.50167°N 113.01583°E\ufeff / 34.50167; 113.01583Coordinates: 34°30′06″N 113°00′57″E\ufeff / \ufeff34.50167°N 113.01583°E\ufeff / 34.50167; 113.01583'}}} (scraper.py:257)
[2022-03-10 02:02:24] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Kremlin_(fortification)>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Kremlin (fortification)', 'url': 'https://en.wikipedia.org/wiki/Kremlin_(fortification)', 'date': 202202280732, 'content': "A kremlin (Russian: кремль, romanized:\xa0kreml', ˈkrʲemlʲ) is a major fortified central complex found in historic Russian cities.[1][2] This word is often used to refer to the most famous one, the Moscow Kremlin,[3] or metonymically to the government that is based there.[4] Other such fortresses are called detinets, such as the Novgorod Detinets.The Russian word is of uncertain origin. Different versions include the word originating from the Turkic languages, the Greek language or from Baltic languages.[5][6][7][8][9][10] The word may share the same root as kremen' (Russian: кремень, krʲɪˈmʲenʲ, 'flint').[11]The Slavs began to build fortresses to protect their lands from enemies in the ninth century. It is known that the Scandinavians called the Slavic lands the land of fortresses - 'Gardariki'. Arabic geographer Al-Bakri wrote: 'And that is how the Slavs build a large part of their fortresses: they head for meadows, rich in water and reeds, and there mark a round or rectangular place, depending on the shape they want to make a fortress, and they dig around the moat, and the dugout earth is dumped in a rampart, reinforcing it with planks and piles, like beaten earth, until the wall reaches the desired height. Then they measure the door at whichever side they want, and approach by a wooden bridge'.[12] In ancient times, a wooden fence was built on the crest of a rampart, a palisade or zapolot (the wall made of logs, vertically one above the other, and connected with horizontally laid timbers). The way of defending the settlement was primitive; later wooden fortress walls became more preferable.In the VIII century, the earliest known stone and wooden fortress - Lubšanská fortress near Staraya Ladoga was built. The ancient stone and wooden kremlins include a fortress on Truvorov settlement near Izborsk (IX century) and the first Stara Ladoga Kremlin (the end of IX century, later rebuilt). Single stone towers, gates and bends of walls appeared in other cities (Vladimir, Kyiv, Novgorod, Pereyaslavl): the Golden Gate of Kievan citadel and the gate of the Vladimir Kremlin bearing the same name survived.[13]A special type of wooden and stone Kremlins appeared under the influence of architectural traditions of Poland and Hungary. They were characterised by the juxtaposition of wooden walls and towers with vezha - high stone towers standing inside the fortress, which were used as watchtowers. Constructions, called Volyn towers, were erected, for example, in the citadels of Kholmsk, Kamenets and Gorodeni.[13]During the Mongol-Tatar invasion, many Russian wooden and stone-wooden fortresses were taken and destroyed by the Mongols. The long-lasting Mongol-Tatar yoke slowed down the development of Russian fortification architecture for a century and a half, as internecine wars stopped and the need to build fortresses disappeared.The tradition of fortress construction was preserved in Novgorod and Pskov lands which were not damaged by the Mongol invasion. Here are built not only kremlins (Izborsk, Porkhov) but - for the first time in Russia - fortresses, which were not many cities in the full sense of the word, as defensive structures (Koporie, Oreshek, Yam, Korela, Ostrov, Kobyla). The strongest of the Russian fortresses was the Pskov Kremlin, which had no equal in Russia in the number of sustained sieges.[13]The term Kremlin (in the variant Kremnik) is first encountered in chronicles of 1317 in accounts of the construction of the Tver Kremlin, where a wooden city-fortress was erected, which was clayed and whitewashed.[14]Wooden fortresses were erected everywhere in the Russian state - from the Far East lands to the Swedish borders. They were numerous in the South, where they served as a link of fortified fortification zones cutting off the way to the central regions from Crimean Tatars. Aesthetically wooden fortresses were not inferior to stone ones - and we can regret that the towers of wooden kremlins have not survived to this day. Wooden fortresses were built quickly: in 1638 in Mtsensk fortress walls of Bolshoi Ostrog and Pletny Gorod with a total length of about 3 kilometres with 13 towers and almost one hundred meters long bridge over the River Zusha were erected in 20 days. The town of Sviyazhsk was built similarly during the Kazan campaign in the spring of 1551: fortress walls about 2.5 kilometres long, many churches and houses were erected in a month.Later on, many Kremlins were rebuilt and strengthened. Thus, the Moscow Kremlin under Ivan the Third was reconstructed of bricks.In the XVI-XVII centuries, about 30 stone fortresses were built in the Russian State. New Kremlins have regular geometric forms in plan (Zaraisky and Tula Kremlins). The Tula Kremlin is unique because it was built in a valley (which was possible because of undeveloped siege artillery of nomad Tatars).Construction of the Kremlin lasted until the turn of the XVII-XVIII centuries. The last Kremlin structure was built of stone in 1699-1717 in the town of Tobolsk (the easternmost Kremlin in Russia). [further explanation needed]After the disintegrations of the Kievan Rus, the Russian Empire and the USSR, some fortresses considered Kremlin-type, remained beyond the borders of modern Russia. Some are listed below:The same structure in Novgorodshina, Ukraine and other Old Russian territories is also called dytynets ( Ukrainian: дитинець, from dytyna – child). The term has been in use since the 11th century. The term kremlin first appeared in 14th century in various Russian territories, where it replaced dytynets.Many Russian monasteries have been built in a fortress-like style similar to that of a kremlin. For a partial list, see Monasteries in Russia.", 'attributes': {'Kremlin (fortification)': {}}} (scraper.py:257)
[2022-03-10 02:02:25] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Scorched_earth>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Scorched earth', 'url': 'https://en.wikipedia.org/wiki/Scorched_earth', 'date': 202203092202, 'content': "CategoriesA scorched-earth policy is a military strategy that aims to destroy anything that might be useful to the enemy. Any assets that could be used by the enemy may be targeted, which usually includes obvious weapons, transport vehicles, communication sites, and industrial resources. However, anything useful to the advancing enemy may be targeted, including food stores and agricultural areas, water sources, and even the local people themselves, though the last has been banned under the 1977 Geneva Conventions.[a]The practice can be carried out by the military in enemy territory or in its own home territory while it is being invaded. It may overlap with, but is not the same as, punitive destruction of the enemy's resources, which is usually done as part of political strategy, rather than operational strategy.Notable historic examples of scorched-earth tactics include William Tecumseh Sherman's March to the Sea in the American Civil War, Kit Carson's subjugation of the American Navajo Indians, Lord Kitchener's advance against the Boers, and the setting on fire of 605 to 732 oil wells by retreating Iraqi military forces during the Gulf War. Also notable were the Russian army's strategies during the failed Swedish invasion of Russia, the failed Napoleonic invasion of Russia, the initial Soviet retreat commanded by Joseph Stalin during the German Army's invasion during the Second World War,[2] and Nazi Germany's retreat on the Eastern Front.The concept of scorched-earth defense is sometimes applied figuratively to the business world in which a firm facing a takeover attempts to make itself less valuable by selling off its assets.[3]The Scythians used scorched-earth methods against the Persian Achaemenid Empire, led by King Darius the Great, during his European Scythian campaign. The Scythians, who were nomadic herders, evaded the Persian invaders and retreated into the depths of the steppes after they had destroyed food supplies and poisoned wells.The Greek general Xenophon recorded in his Anabasis that the Armenians, as they withdrew, burned their crops and food supplies before the Ten Thousand could advance.[citation needed]The Greek mercenary general Memnon of Rhodes unsuccessfully suggested to the Persian satraps to use a scorched-earth policy against Alexander the Great, who was moving into Asia Minor.The system of punitive destruction of property and subjugation of people when accompanying a military campaign was known as vastatio. Two of the first uses of scorched earth recorded both happened in the Gallic Wars. The first was used when the Celtic Helvetii were forced to evacuate their homes in Southern Germany and Switzerland because of incursions of unfriendly Germanic tribes: to add incentive to the march, the Helvetii destroyed everything they could not bring.[4] After the Helvetii were defeated by combined Roman and Gallic forces, the Helvetii were forced to rebuild themselves on the plains they themselves had destroyed.The second case shows actual military value: during the Great Gallic War the Gauls under Vercingetorix planned to lure the Roman armies into Gaul and then trap and obliterate them. They thus ravaged the countryside of what are now the Benelux countries and France. That caused immense problems for the Romans, but the Roman military triumphs over the Gallic alliance showed that alone not to be enough to save Gaul from subjugation by Rome.During the Second Punic War in 218–202 BCE, the Carthaginians used the method selectively while storming through Italy.[5] After the end of the Third Punic War in 146 BCE, the Roman Senate also elected to use this method to permanently destroy the Carthaginian capital city, Carthage (near modern-day Tunis). The buildings were torn down, their stones scattered so not even rubble remained, and the fields were burned. However, the story that they salted the earth is apocryphal.[6]In the year CE 363, the Emperor Julian's invasion of Persia was turned back by a scorched-earth policy:The extensive region that lies between the River Tigris and the mountains of Media\xa0...was in a very improved state of cultivation. Julian might expect, that a conqueror, who possessed the two forcible instruments of persuasion, steel and gold, would easily procure a plentiful subsistence from the fears or avarice of the natives. But, on the approach of the Romans, the rich and smiling prospect was instantly blasted. Wherever they moved\xa0... the cattle was driven away; the grass and ripe corn were consumed with fire; and, as soon as the flames had subsided which interrupted the march of Julian, he beheld the melancholy face of a smoking and naked desert. This desperate but effectual method of defence can only be executed by the enthusiasm of a people who prefer their independence to their property; or by the rigor of an arbitrary government, which consults the public safety without submitting to their inclinations the liberty of choice.[7]The British monk Gildas wrote in his 6th-century treatise 'On the Ruin of Britain' on an earlier invasion: 'For the fire of vengeance\xa0...\u200aspread from sea to sea\xa0...\u200aand did not cease, until, destroying the neighbouring towns and lands, it reached the other side of the island'.[8]During the First Fitna (656–661), Muawiyah I sent Busr ibn Abi Artat to a campaign in the Hejaz and Yemen to ravage territory loyal to Muawiyah's opponent Ali ibn Abi Talib. According to Tabari, 30,000 civilians are estimated to have been killed during that campaign of the civil war. Muawiyah also sent Sufyan ibn Awf to Iraq to burn the crops and homes of Ali's supporters.[9]During the great Viking invasion of England that was opposed by Alfred the Great and various other Saxon and Welsh rulers, the Viking chieftain Hastein marched his men to Chester in late summer 893 to occupy the ruined Roman fortress there. The refortified fortress would have made an excellent base for raiding northern Mercia, but the Mercians are recorded as having taken the drastic measure of destroying all crops and livestock in the surrounding countryside to starve the Vikings out.[10][self-published source?] They left Chester next year and marched into Wales.In the Harrying of the North, William the Conqueror's solution to stop a rebellion in 1069 was the brutal conquest and subjugation of northern England. William's men burnt whole villages from the Humber to Tees and slaughtered the inhabitants. Food stores and livestock were destroyed so that anyone surviving the initial massacre would soon succumb to starvation over the winter. The destruction is depicted in the Bayeux Tapestry.[11] The survivors were reduced to cannibalism,[12] with one report stating that the skulls of the dead were cracked open so that their brains could be eaten. Between 100,000 and 150,000 perished, and the area took centuries to recover from the damage.During 1019 and 1022\xa0AD the Chandela Kingdom was attacked by Mahmud of Ghazni. The Chandellas adopted a scorched earth policy. Mahmud, afraid of penetrating too far into the interior, had each time to retreat without much gain and ultimately established a friendly relationship with the Chandellas.[citation needed]During the Hundred Years' War, both the English and the French conducted chevauchée raids over the enemy territory to damage its infrastructure.Robert the Bruce counselled using those methods to hold off the forces of Edward I of England, who were Scotland, according to an anonymous 14th-century poem:[13]in strait places gar keep all store,And byrnen ye plainland them before,That they shall pass away in haistWhat that they find na thing but waist....\xa0This is the counsel and intentOf gud King Robert's testiment.In 1336, the defenders of Pilėnai, Lithuania, set their castle on fire and committed mass suicide to make the attacking Teutonic Order have only a Pyrrhic victory.The strategy was widely used in Wallachia and Moldavia, now mostly in Romania and Moldova. Prince Mircea I of Wallachia used it against the Ottoman Empire in 1395, and Prince Stephen III of Moldavia did the same as the Ottoman Army advanced in 1475 and 1476.A slighting is the deliberate destruction, whether partial or complete, of a fortification without opposition. Sometimes, such as during the Wars of Scottish Independence and the English Civil War, it was done to render the structure unusable as a fortress.[14][15][16] In England, adulterine (unauthorised) castles would usually be slighted if captured by a king.[17] During the Wars of Scottish Independence, Robert the Bruce adopted a strategy of slighting Scottish castles to prevent them being occupied by the invading English.[16][18] A strategy of slighting castles in Palestine was also adopted by the Mamelukes during their wars with the Crusaders.Further use of scorched-earth policies in a war was seen during the 16th century in Ireland, where it was used by English commanders such as Walter Devereux and Richard Bingham.The Desmond Rebellions were a famous case in Ireland. Much of the province of Munster was laid waste. The poet Edmund Spenser left an account of it:In those late wars in Munster; for notwithstanding that the same was a most rich and plentiful country, full of corn and cattle, that you would have thought they could have been able to stand long, yet ere one year and a half they were brought to such wretchedness, as that any stony heart would have rued the same. Out of every corner of the wood and glens they came creeping forth upon their hands, for their legs could not bear them; they looked Anatomies [of] death, they spoke like ghosts, crying out of their graves; they did eat of the carrions, happy where they could find them, yea, and one another soon after, in so much as the very carcasses they spared not to scrape out of their graves; and if they found a plot of water-cresses or shamrocks, there they flocked as to a feast for the time, yet not able long to continue therewithal; that in a short space there were none almost left, and a most populous and plentiful country suddenly left void of man or beast.In 1630, Field-Marshal General Torquato Conti was in command of the Holy Roman Empire's forces during the Thirty Years' War. Forced to retreat from the advancing Swedish army of King Gustavus Adolphus, Conti ordered his troops to burn houses, destroy villages and cause as much harm generally to property and people as possible. His actions were remembered thus:[19]To revenge himself upon the Duke of Pomerania, the imperial general permitted his troops, upon his retreat, to exercise every barbarity on the unfortunate inhabitants of Pomerania, who had already suffered but too severely from his avarice. On pretence of cutting off the resources of the Swedes, the whole country was laid waste and plundered; and often, when the Imperialists were unable any longer to maintain a place, it was laid in ashes, in order to leave the enemy nothing but ruins.During the Great Northern War, Russian Emperor Peter the Great's forces used scorched-earth tactics to hold back Swedish King Charles XII's campaign towards Moscow.In 1462, a massive Ottoman army, led by Sultan Mehmed II, marched into Wallachia. Vlad the Impaler retreated to Transylvania. During his departure, he conducted scorched-earth tactics to ward off Mehmed's approach. When the Ottoman forces approached Tirgoviste, they encountered over 20,000 people impaled by the forces of Vlad the Impaler, creating a 'forest' of dead or dying bodies on stakes. The atrocious, gut-wrenching sight caused Mehmed to withdraw from battle and to send instead Radu, Vlad's brother, to fight Vlad the Impaler.In early 1565, Grandmaster Jean Parisot de Valette ordered the harvesting of all the crops in Malta, including unripened grain, to deprive the Ottomans of any local food supplies since spies had warned of an imminent Ottoman attack. Furthermore, the Knights poisoned all of the wells with bitter herbs and dead animals. The Ottomans arrived on 18 May, and the Great Siege of Malta began. The Ottomans managed to capture one fort but were eventually defeated by the Knights, the Maltese militia and a Spanish relief force.In 1688, France attacked the German Electoral Palatinate. The German states responded by forming an alliance and assembling a sizeable armed force to push the French out of Germany. The French had not prepared for such an eventuality. Realising that the war in Germany was not going to end quickly and that the war would not be a brief and decisive parade of French glory, Louis XIV and War Minister Marquis de Louvois resolved upon a scorched-earth policy in the Palatinate, Baden and Württemberg. The French were intent on denying enemy troops local resources and on preventing the Germans from invading France.[20] By 20 December 1688, Louvois had selected all the cities, towns, villages and châteaux intended for destruction. On 2 March 1689, the Count of Tessé torched Heidelberg, and on 8 March, Montclar levelled Mannheim. Oppenheim and Worms were finally destroyed on 31 May, followed by Speyer on 1 June, and Bingen on 4 June. In all, French troops burnt over 20 substantial towns as well as numerous villages.[21]In the Maratha Empire, Shivaji Maharaj had introduced scorched-earth tactics, known as Ganimi Kava.[22] His forces looted traders and businessmen from Aurangzeb's Mughal Empire and burnt down his cities, but they were strictly ordered not to rape or hurt the innocent civilians and not to cause any sort of disrespect to any of the religious institutes.[23]Shivaji's son, Sambhaji Maharaj, was detested throughout the Mughal Empire for his scorched-earth tactics until he and his men were captured by Muqarrab Khan and his Mughal Army contingent of 25,000.[24] On 11 March 1689, a panel of Mughal qadis indicted and sentenced Sambhaji to death on accusations of casual torture, arson, looting, and massacres but most prominently for giving shelter to Sultan Muhammad Akbar, the fourth son of Aurangzeb, who sought Sambhaji's aid in winning the Mughal throne from the emperor, his father. Sambhaji was particularly condemned for the three days of ravaging committed after the Battle of Burhanpur.[25]During the third Napoleonic invasion of Portugal in 1810, the Portuguese population retreated towards Lisbon and was ordered to destroy all the food supplies the French might capture as well as forage and shelter in a wide belt across the country. (Although effective food-preserving techniques had recently been invented, they were still not fit for military use because a suitably-rugged container had not yet been invented.)[26] The command was obeyed as a result of French plundering and general ill-treatment of civilians in the previous invasions. The poor angry people would rather destroy anything that had to be left behind, rather than leave it to the French.After the Battle of Bussaco, André Masséna's army marched on to Coimbra, where much of the city's old university and library were vandalised. Houses and furniture were destroyed, and the few civilians who did not seek refuge farther south were murdered. While there were instances of similar behavior by British soldiers, since Portugal was their ally, such crimes were generally investigated and those found punished. Coimbra's sack made the populace even more determined to leave nothing, and when the French armies reached the Lines of Torres Vedras on the way to Lisbon, French soldiers reported that the country 'seemed to empty ahead of them'. When Massená reached the city of Viseu, he wanted to replenish his armies' dwindling food supplies, but none of the inhabitants remained, and all there was to eat were grapes and lemons that if eaten in large quantities would be better laxatives than sources of calories. Low morale, hunger, disease and indiscipline greatly weakened the French army and compelled the forces to retreat the next spring. That method was later recommended to Russia when Napoleon made his move.In 1812, Emperor Alexander I was able to render Napoleon's invasion of Russia useless by using a scorched-earth retreat policy, similar to that of Portugal.[27] As Russians withdrew from the advancing French army, they burned the countryside (and allegedly Moscow[28]) over which they passed, leaving nothing of value for the pursuing French army. Encountering only desolate and useless land Napoleon's Grande Armée was prevented from using its usual doctrine of living off the lands that it conquered. Pushing relentlessly on despite dwindling numbers, the Grand Army met with disaster as the invasion progressed. Napoleon's army arrived in a virtually-abandoned Moscow, which was a tattered starving shell of its former self, largely because of scorched-earth tactics by the retreating Russians. Having conquered essentially nothing, Napoleon's troops retreated, but the scorched-earth policy came into effect again because even though some large supply dumps had been established on the advance, the route between them had both been scorched and marched over once already. Thus, the French army starved as it marched along the resource-depleted invasion route.[29]In August 1812, Argentine General Manuel Belgrano led the Jujuy Exodus, a massive forced displacement of people from what is now Jujuy and Salta Provinces to the south. The Jujuy Exodus was conducted by the patriot forces of the Army of the North, which was battling a Royalist army.Belgrano, faced with the prospect of total defeat and territorial loss, ordered all people to pack their necessities, including food and furniture, and to follow him in carriages or on foot together with whatever cattle and beasts of burden that could endure the journey. The rest (houses, crops, food stocks and any objects made of iron) was to be burned to deprive the Royalists of resources. The strict scorched-earth policy made him ask on 29 July 1812 the people of Jujuy to 'show their heroism' and to join the march of the army under his command 'if, as you assure, you want to be free'. The punishment for ignoring the order was execution, with destruction of the defector's properties. Belgrano labored to win the support of the populace and later reported that most of the people had willingly followed him without the need of force.The exodus started on 23 August and gathered people from Jujuy and Salta. People travelled south about 250\xa0km and finally arrived at the banks of the Pasaje River, in Tucumán Province in the early hours of 29 August. They applied a scorched-earth policy and so the Spaniards advanced into a wasteland. Belgrano's army destroyed everything that could provide shelter or be useful to the Royalists.[30]In 1827, Ibrahim Pasha of Egypt led an Ottoman-Egyptian combined force in a campaign to crush Greek revolutionaries in the Peloponnese. In response to Greek guerrilla attacks on his forces in the Peloponnese, Ibrahim launched a scorched earth campaign which threatened the population with starvation and deported many civilians into slavery in Egypt. He also allegedly planned to bring in Arab settlers to replace the Greek population. The fires of burning villages and fields were clearly visible from Allied ships standing offshore. A British landing party reported that the population of Messinia was close to mass starvation.[31] Ibrahim's scorched-earth policy caused much outrage in Europe, which was one factor for the Great Powers (United Kingdom, the Kingdom of France and the Russian Empire) decisively intervening against him in the Battle of Navarino.The Philippine–American War often included scorched-earth campaigns in the countryside. Entire villages were burned and destroyed, with torture (water cure) and the concentration of civilians into 'protected zones.' Many civilian casualties were caused by disease and famine.[32][33]In the hunt for guerrilla leader Emilio Aguinaldo, American troops also poisoned water wells to try to force out the Filipino rebels.[34]In the American Civil War, Union forces under Philip Sheridan and William Tecumseh Sherman used the policy widely.[35] General Sherman used that policy during his March to the Sea.Sherman's tactics were an attempt to destroy the enemy's will and logistics through burning or destroying crops or other resources that might be used for the Confederate force. Later generations of American war leaders would use similar total war tactics in World War II, the Korean War, the Vietnam War, the Iraq war, and the Afghanistan War, largely through the use of air power.[36] During Sherman's campaign, his 'men piled all deed books in front of the courthouse and burned them. The logic was that the big plantations would not be able to prove land ownership. These actions are the bane of Georgia and South Carolina genealogists.”[37]Another event, in response to William Quantrill's raid on Lawrence, Kansas and the many civilian casualties, including the killing of 180 men, Brigadier General Thomas Ewing Jr., Sherman's brother-in-law, issued US Army General Order No. 11 (1863) to order the near-total evacuation of three-and-a-half counties in western Missouri, south of Kansas City, which were subsequently looted and burned by US Army troops.[38] Under Sherman's overall direction, General Philip Sheridan followed that policy in the Shenandoah Valley of Virginia and then in the Indian Wars of the Great Plains.When General Ulysses Grant's forces broke through the defenses of Richmond, Virginia, Confederate President Jefferson Davis ordered the destruction of Richmond's militarily-significant supplies. The resulting conflagration destroyed many buildings, most of which were commercial, as well as Confederate warships docked on the James River. Civilians in panic were forced to escape the fires that had been started.During the wars with Native American tribes of the American West, Kit Carson, under James Henry Carleton's direction, instituted a scorched-earth policy, burning Navajo fields and homes and stealing or killing their livestock. He was aided by other Indian tribes with long-standing enmity toward the Navajos, chiefly the Ute tribe. The Navajo were forced to surrender because of the destruction of their livestock and food supplies. In the spring of 1864, 8000 Navajo men, women, and children were forced to march 300 miles to Fort Sumner, New Mexico. Navajos call it 'The Long Walk.' Many died along the way or during their four years of internment.A military expedition, led by Colonel Ranald S. Mackenzie, was sent to the Texas Panhandle and the Oklahoma Territory Panhandle in 1874 to remove the Indians to reservations in Oklahoma. The Mackenzie expedition captured about 1,200 of the Indians' horses, drove them into Tule Canyon, and shot all of them. Denied their main source of livelihood and demoralized, the Comanche and the Kiowa abandoned the area (see Palo Duro Canyon).Lord Kitchener applied a scorched-earth policy towards the end of the Second Boer War (1899–1902). Numerous Boers, refusing to accept military defeat, adopted guerrilla warfare despite the capture of both of their capital cities. As a result, the British Army under Lord Kitchener's command initiated a policy of the destruction of the farms and the homes of civilians to prevent the Boers who were still fighting from obtaining food and supplies.[39] The policies left Boer women and children without means to survive since crops and livestock had also been destroyed.[40]The existence of the concentration camps was exposed by Emily Hobhouse, who toured the camps and began petitioning the British government to change its policy.[41][42] In an attempt to counter Hobhouse's activism, the British government commissioned the Fawcett Commission, but it confirmed Hobhouse's findings.[43] The British government later perceived the concentration camps as a humanitarian measure, to care for displaced persons until the war was ended, in response to both reports. Negligence by the British, lack of planning and supplies, and overcrowding led to much loss of life.[44] A decade after the war, P.L.A. Goldman officially determined that 27,927 Boers died in the concentration camps, 26,251 women and children (of whom more than 22,000 were under the age of 16) and 1676 men over the age of 16, with 1421 being aged persons.[45]In 1868, the Tūhoe, who had sheltered the Māori leader Te Kooti, were thus subjected to a scorched-earth policy in which their crops and buildings were destroyed and the people of fighting age were captured.On the Eastern Front of World War I, the Imperial Russian Army created a zone of destruction by using a massive scorched-earth strategy during their retreat from the Imperial German Army in the summer and the autumn of 1915. The Russian troops, retreating along a front of more than 600 miles, destroyed anything that might be of use to their enemy, including crops, houses, railways and entire cities. They also forcibly removed huge numbers of people. In pushing the Russian troops back into Russia's interior, the German army gained a large area of territory from the Russian Empire that is now Poland, Ukraine, Belarus, Latvia and Lithuania.[46]On the Western Front on 24 February 1917, the German army made a strategic scorched-earth withdrawal from the Somme battlefield to the prepared fortifications of the Hindenburg Line to shorten the line that had to be occupied. Since a scorched-earth campaign requires a war of movement, the Western Front provided little opportunity for the policy as the war was mostly a stalemate and was fought mostly in the same concentrated area for its entire duration.During the Greco-Turkish War (1919–22), the retreating Greek Army carried out a scorched-earth policy while it was fleeing from Anatolia in the final phase of the war.[47]  The historian Sydney Nettleton Fisher wrote, 'The Greek army in retreat pursued a burned-earth policy and committed every known outrage against defenceless Turkish villagers in its path'.[47]Norman Naimark noted that 'the Greek retreat was even more devastating for the local population than the occupation'.[48]During the Second Sino-Japanese War, the Imperial Japanese Army had a scorched-earth policy, known as 'Three Alls Policy', which caused immense environmental and infrastructure damage to be recorded. It contributed to the complete destruction of entire villages and partial destruction of entire cities.The Chinese National Revolutionary Army destroyed dams and levees in an attempt to flood the land to slow down the advancement of Japanese soldiers, which further added to the environmental impact and resulting in the 1938 Yellow River flood. In the 1938 Changsha fire, the city of Changsha was put on fire by the Kuomintang  to prevent any wealth from falling into enemy hands.[49]At the start of the Winter War in 1939, the Finns used the tactic in the vicinity of the border in order to deprive the invading Soviet Red Army's provisions and shelter for the forthcoming cold winter. In some cases, fighting took place in areas that were familiar to the Finnish soldiers who were fighting it. There were accounts of soldiers burning down their very own homes and parishes. One of the burned parishes was Suomussalmi.When Germany attacked the Soviet Union in June 1941, many district governments took the initiative to begin a partial scorched-earth policy to deny the invaders access to electrical, telecommunications, rail, and industrial resources. Parts of the telegraph network were destroyed, some rail and road bridges were blown up, most electrical generators were sabotaged through the removal of key components, and many mineshafts were collapsed.[citation needed] The process was repeated later in the war by the German forces of Army Group North and Erich von Manstein's Army Group Don, which stole crops, destroyed farms, and razed cities and smaller settlements during several military operations. The rationale for the policy was that it would slow pursuing Soviet forces by forcing them to save their own civilians, but in Manstein's postwar memoirs, the policy was justified as to have prevented the Soviets from stealing food and shelter from their own civilians. The best-known victims of the German scorched-earth policy were the people of the historic city of Novgorod, which was razed during the winter of 1944 to cover Army Group North's retreat from Leningrad.Near the end of the summer of 1944, Finland, which had made a separate peace with the Allies, was required to evict the German forces, which had been fighting against the Soviets alongside Finnish troops in northern Finland. The Finnish forces, under the leadership of General Hjalmar Siilasvuo, struck aggressively in late September 1944 by making a landfall at Tornio. That accelerated the German retreat, and by November 1944, the Germans had left most of northern Finland. The German forces, forced to retreat because of an overall strategic situation, covered their retreat towards Norway by devastating large areas of northern Finland by using a scorched-earth strategy. More than a third of the area's dwellings were destroyed, and the provincial capital Rovaniemi was burned to the ground. All but two bridges in Lapland Province were blown up, and all roads were mined.[50]In northern Norway, which was also being invaded by Soviet forces in pursuit of the retreating Wehrmacht in 1944, the Germans also undertook a scorched-earth policy of destroying every building that could offer shelter and thus interposing a belt of 'scorched earth' between themselves and the allies.[51]In 1945, Adolf Hitler ordered his minister of armaments, Albert Speer, to carry out a nationwide scorched-earth policy, in what became known as the Nero Decree. Speer, who was looking to the future, actively resisted the order, just as he had earlier refused Hitler's command to destroy French industry when the Wehrmacht was being driven out of France. Speer managed to continue doing so even after Hitler became aware of his actions.[52]During the Second World War, the railroad plough was used during retreats in Germany, Czechoslovakia and other countries to deny enemy use of railways by partially destroying them.Britain was the first nation to employ herbicides and defoliants (chiefly Agent Orange) to destroy the crops and the bushes of Malayan National Liberation Army (MNLA) insurgents in Malaya during the Malayan Emergency. The intent was to prevent MNLA insurgents from utilizing rice fields to resupply their rations and using them as a cover to ambush passing convoys of Commonwealth troops.In response to India's invasion of Portuguese Goa in December 1961 during the annexation of Portuguese India, orders delivered from Portuguese President Américo Tomás called for a scorched-earth policy for Goa to be destroyed before its surrender to India.[53]However, despite his orders from Lisbon, Governor General Manuel António Vassalo e Silva took stock of the superiority of the Indian troops and of his forces' supplies of food and ammunition and took the decision to surrender. He later described his orders to destroy Goa as 'a useless sacrifice' (um sacrifício inútil)'.The United States used Agent Orange as a part of its herbicidal warfare program Operation Ranch Hand to destroy crops and foliage to expose possible enemy hideouts during the Vietnam War. Agent Blue was used on rice fields to deny food to the Viet Cong.During the 1990 Gulf War, when Iraqi forces were driven out of Kuwait, they set more than 600 Kuwaiti oil wells on fire.[54] That was done as part of a scorched-earth policy during the retreat from Kuwait in 1991 after Iraqi forces had been driven out by Coalition military forces. The fires were started in January and February 1991, and the last one was extinguished by November 1991.[55]Efraín Ríos Montt used the policy in Guatemala's highlands in 1981 and 1982, but it had been used under the previous president, Fernando Romeo Lucas García. Upon entering office, Ríos Montt implemented a new counterinsurgency strategy that called for the use of scorched earth to combat the Guatemalan National Revolutionary Unity rebels. Plan Victoria 82 was more commonly known by the nickname of the rural pacification elements of the strategy, Fusiles y Frijoles (Bullets and Beans).[56]  Ríos Montt's policies resulted in the death of thousands, most of them indigenous Mayans.The Indonesian military used the method during Indonesian National Revolution when the British forces in Bandung gave an ultimatum for Indonesian fighters to leave the city. In response, the southern part of Bandung was deliberately burned down in an act of defiance as they left the city on 24 March 1946. This event is known as the Bandung Sea of Fire (Bandung Lautan Api).[57]The Indonesian military and pro-Indonesia militias also used the method in the 1999 East Timorese crisis. The Timor-Leste scorched-earth campaign was around the time of East Timor's referendum for independence in 1999.The method was used during the Yugoslav Wars, such as against the Serbs in Krajina by the Croatian Army,[58][59] and by Serbian paramilitary groups.[60]The Sudanese government has used scorched earth as a military strategy in Darfur.During the Sri Lankan Civil War in 2009 the United Nations Regional Information Centre (UNRIC) has accused the Sri Lankan government of utilizing scorched-earth tactics.[61][62][63]During the 2011 Libyan civil war, forces loyal to Moammar Gadhafi planted a large number of landmines within the petroleum port of Brega to prevent advancing rebel forces from utilizing the port facilities.[citation needed] Libyan rebel forces practiced scorched-earth policies when they completely demolished and refused to rebuild critical infrastructure[example  needed] in towns and cities formerly loyal to Moammar Gadhafi such as Sirte and Tawargha.[64]As part of the ceasefire agreement 2020 Nagorno-Karabakh war, Armenian forces agreed to relinquish control of areas of the Republic of Artsakh that fell outside of the borders of the old Soviet Nagorno-Karabakh Autonomous Oblast. Scorched-earth offensive tactic used by the Azerbaijani Armed Forces enabled quick advances in the populated areas. The Azerbaijani Armed Forces used scorched-earth tactics to advance and gain control over large forested and populated areas using incendiary weapons (possibly, white phosphorus).[65] The incendiary attacks[66] inflicted extensive damage to nature[67] and destroyed objects essential for the survival of the villages (i.e., livestock, wood for the winter, water sources, etc.)[68][69] in the vicinity of the affected areas. Some villages (e.g., Aknaghbyur[70]) were the object of direct incendiary attacks or arson. This led to a mass exodus of combatants and civilian population from villages facing violent takeover of the approaching Azerbaijani Armed Forces, as both military[71] and civilian casualties of the incendiary attacks[72] made holding positions unsustainable. This offensive tactic effectively allowed the Azerbaijani Armed Forces to progress rapidly and seize control of large populated areas of Nagorno-Karabakh (Artsakh) region.It is prohibited to attack, destroy, remove, or render useless objects indispensable to the survival of the civilian population, such as foodstuffs, agricultural areas for the production of foodstuffs, crops, livestock, drinking water installations and supplies, and irrigation works, for the specific purpose of denying them for their sustenance value to the civilian population or to the adverse Party, whatever the motive, whether in order to starve out civilians, to cause them to move away, or for any other motive.[1]", 'attributes': {'Scorched earth': {}}} (scraper.py:257)
[2022-03-10 02:02:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E6%B5%B7%E8%BB%8D%E6%B5%B7%E6%B4%8B%E7%9B%A3%E5%81%B5%E6%8C%87%E6%8F%AE%E9%83%A8> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A5%BF%E5%B1%BF%E9%9B%B7%E8%BE%BE%E7%AB%99&ns0=1) (engine.py:250)
[2022-03-10 02:02:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/SdKfz_252%E5%8D%8A%E5%B1%A5%E5%B8%A6%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E8%BF%90%E8%BE%93%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 02:02:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%95%91%E6%8A%A4%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 02:02:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%8A%B1%E8%8E%B2%E6%9C%BA%E5%9C%BA&ns0=1) (engine.py:250)
[2022-03-10 02:02:25] [   DEBUG] [scrapy.core.engine ] - Crawled (200) <GET https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6> (referer: https://zh.wikipedia.org/w/index.php?title=Special:%E6%90%9C%E7%B4%A2&limit=20&offset=0&profile=default&search=%E8%A3%85%E7%94%B2%E6%89%AB%E9%9B%B7%E8%BD%A6&ns0=1) (engine.py:250)
[2022-03-10 02:02:25] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4>
{'keyword': '澎湖机场', 'source': 'wiki', 'title': '澎湖机场', 'url': 'https://zh.wikipedia.org/wiki/%E6%BE%8E%E6%B9%96%E6%A9%9F%E5%A0%B4', 'date': ' ', 'content': "澎湖机场（闽南语白话字：.mw-parser-output .IPA{font-family:'Charis SIL','Doulos SIL','Linux Libertine','Segoe UI','Lucida Sans Unicode','Code2000','Gentium','Gentium Alternative','TITUS Cyberbit Basic','Arial Unicode MS','IPAPANNEW','Chrysanthi Unicode','GentiumAlt','Bitstream Vera','Bitstream Cyberbit','Hiragino Kaku Gothic Pro','Lucida Grande',sans-serif;text-decoration:none!important}.mw-parser-output .IPA a:link,.mw-parser-output .IPA a:visited{text-decoration:none!important}Phîⁿ-ô͘/Phêⁿ-ô͘ Ki-tiû；IATA代码：MZG；ICAO代码：RCQC），是一座位于台湾澎湖县湖西乡隘门村的军民合用机场，为该县主要联外机场，旧名“马公机场”。民用部分由交通部民用航空局马公航空站[注 1]管理及营运；军用部分为空军马公基地。由立荣航空、华信航空、德安航空营运台北松山、台中、台南、嘉义、高雄、金门及七美共7条航线，主要以ATR72-600、A321-200、DHC6-400等机型执飞。2019冠状病毒病疫情爆发，国际线需求下降，但离岛航线需求大增，华信航空部分航班由台湾虎航A320-200营运。", 'attributes': {'澎湖机场': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/ROCAF_F-5A_in_Makung_AB_1974.jpg/250px-ROCAF_F-5A_in_Makung_AB_1974.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%282%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg/250px-F-4_bubble_check_on_Makung_Air_Base%2C_Taiwan_%283%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Magong_Airport.jpg/150px-Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png/80px-%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%B8%80%E6%88%B0%E8%A1%93%E6%88%B0%E9%AC%A5%E6%A9%9F%E8%81%AF%E9%9A%8A.png', 'https://upload.wikimedia.org/wikipedia/commons/7/7d/Aerial_view_of_Magong_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Taiwan_location_map.svg/250px-Taiwan_location_map.svg.png'], '机场类型': '军民合用', '营运者': '军用： 中华民国空军民用： 交通部民用航空局', '服务城市': '澎湖县', '地理位置': '中华民国（台湾）澎湖县湖西乡隘门村126-5号', '启用日期': '军用：1937年民用：1977年8月1日(1977-08-01)', '海拔高度': '103英尺（31米）', '坐标': '23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833坐标：23°34′07″N 119°37′42″E\ufeff / \ufeff23.56861°N 119.62833°E\ufeff / 23.56861; 119.62833', '网址': 'www.mkport.gov.tw', '方向': ';;;方向;;长度;;表面;;;米;;英尺;;;02/20;;3,000;;9,843;;混凝土;;', '客运量': '客运量2,320,249 人次货运量6,060.863 公吨起降架次35,682 次', '繁体字': ' 澎湖機場 ', '简化字': ' 澎湖机场 ', '标音': "标音官话-汉语拼音 Péng hú Háng kōng zhàn -威妥玛拼音 Pʻêng2 hu2 hang2 k'ung chan4 -耶鲁拼音 Péng hú háng kūng jàn -注音符号ㄆㄥˊ ㄏㄨˊ ㄏㄤˊ ㄎㄨㄥ ㄓㄢˋ闽语-闽南语白话字 Phîⁿ-ô͘/Phêⁿ-ô͘  hái-khang-chām -台罗拼音 Phînn-ôo/Phênn-ôo hâng-khong-tsām 客家话-客家话拼音 Pang2 fu2 hong2 kung1 zam4 -客语白话字 Phàng-fù hòng-khûng chham ", '汉语': '澎湖航空站'}}} (scraper.py:257)
[2022-03-10 02:02:25] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6>
{'keyword': '装甲侦察车', 'source': 'wiki', 'title': '装甲车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6', 'date': ' ', 'content': '装甲车辆是具有装甲防护的各种车辆的统称。坦克和自走炮也是广义的重型装甲车辆，但是在习惯上通常因作战用途另外独立分类，而装甲车辆多半是指防护力与火力较坦克弱的车种，而自行炮在原则上不一定要有装甲。装甲车的特性为具有高度的越野机动性能，有一定的防护和火力，分为履带式和轮式两种。一般军用装甲车会装备一至三门中小口径火炮及数挺机枪，一些还装有反坦克导弹，结构以装甲车体、武器系统、动力装置等组成。为了增强防护和方便成员下车战斗。大多数军用装甲车辆可以在水上行驶，可以执行运输、侦察、指挥、救护、伴随、支援坦克及步兵作战等多种任务，还有执行专门任务的装甲车辆，如装甲回收车、装甲指挥车、装甲扫雷车、装甲架桥车等。在警用领域多用于镇压暴乱等问题。步兵战车和装甲输送车作用相近，都是运送步兵机动作战用的装甲车辆，两者不同的地方是步兵战车的防护力较好，火力较大，能够让步兵乘车作战，本身也能够伴随下车作战的步兵，提供火力支援速度较好，装甲输送车则更接近于有装甲的运输车辆。装甲输送车为在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。装甲侦察车指装有侦察设备的装甲车辆，速度较快但装甲比其它装甲车辆要薄，多用于战场侦察，一般可分为轮式和履带式两种。较著名的装甲侦察车，有德国的狐式轻型装甲侦察车、山猫装甲侦察车，法国的雷诺VBC90轮式侦察车（英语：VBC-90）等等。装甲指挥车是具有装甲保护的移动指挥站，提供指挥官与支援的参谋和其他人员协调部队的相关事宜。装甲指挥车是早期以卡车或者是拖车为基础的移动指挥所衍生出来的架构，用意在于提供指挥单位快速移动，持续掌握情势与下达命令命且提供一些保护。大部分的装甲指挥车是从装甲输送车改装而成，扩大内部的空间以容纳额外的人员，通讯器材与其他设备。在到达预定指挥地点之后，部分装甲指挥车还有另外设置的顶蓬可以伸出车外，进一步的扩大人员使用的空间。装甲通信车是指装有通信设备的装甲车辆，常见的设计有两种型态，一种是将通信装备与装甲指挥车合并在一起，因此并非单纯的通信车辆。另外一种是做为地面通信的活动中转站，以延伸无线电通信的有效距离，或者是克服地形对通信的遮蔽效应，强化地面单位之间的联络与资讯交换。目前各国陆军很少装备单纯的装甲通信车，不过有不少国家配备由一般运输车辆改装的通信车辆来支援地面部队的通信需求。装甲救护车，指在战场环境下实行人员救护的装甲车辆，一般只装备一至两挺机枪作为自卫武器，防护力亦很弱。主要用于抢救人员，并将重伤员运送至后方。装甲扫雷车特指装有清除地雷装置的装甲车辆，以协助地面部队扩速通过地雷区。装甲扫雷车可以是专门设计用来清除地雷，或者是将清除工具附加在一般用途的坦 克底盘上，无论是车轮或是履带型态的扫雷车都可见于不同国家的部队当中。装甲扫雷车并非用于清除整个被发现的地雷区，而是将地雷区清理出一至数条的安全通道，提供地面部队人员和车辆安全通过。排除的地雷可能在过程中加以引爆，或者是移动到安全的地方之后另外加以处理。由于清理的过程当中，扫雷车可能碰触或者是引爆其他尚未发现的地雷或者是爆裂物，车辆本身对于底盘和车辆底部的保护需要特别加强，以免被地雷或者是爆裂物瘫痪而无法完成清除的任务。装甲架桥车指装有车桥及其架设、撤收装置的装甲车辆，主要用于快速架设桥梁，令部队迅速通过河流，普遍装备于工兵部队。装甲架桥车可由一般坦克或自走炮底盘改装而成，部分会保留机枪作防卫用途。步兵坦 克和装甲输送车 - 当示威活动和抗争会转变成失控的暴乱或群众暴力时，警方有时会出动警用装甲车控制场面。一般具有水炮功能，而车窗经特别制造，不易打碎。各地警方大多都有装甲车，以防范暴乱发生。保安公司常用，用来运载现金或其他贵重物品，又称“解款车”或“运钞车”。另外政要及富豪也会使用经过改装、具有防弹甚至抗炸能力的汽车。', 'attributes': {'装甲车': {}}} (scraper.py:257)
[2022-03-10 02:02:25] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Bastion_fort>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Bastion fort', 'url': 'https://en.wikipedia.org/wiki/Bastion_fort', 'date': 202202061000, 'content': "A bastion fort or trace italienne (a phrase derived from non-standard French, literally meaning Italian outline) is a fortification in a style that evolved during the early modern period of gunpowder when the cannon came to dominate the battlefield. It was first seen in the mid-fifteenth century in Italy. Some types, especially when combined with ravelins and other outworks, resembled the related star fort of the same era.The design of the fort is normally a polygon with bastions at the corners of the walls. These outcroppings eliminated protected blind spots, called 'dead zones', and allowed fire along the curtain from positions protected from direct fire. Many bastion forts also feature cavaliers, which are raised secondary structures based entirely inside the primary structure.Their predecessors, medieval fortresses, were usually placed on high hills. From there, arrows were shot at the enemies. The enemies' hope was to either ram the gate or climb over the wall with ladders and overcome the defenders. For the invading force, these fortifications proved quite difficult to overcome, and accordingly, fortresses occupied a key position in warfare.Passive ring-shaped (Enceinte) fortifications of the Medieval era proved vulnerable to damage or destruction by cannon fire, when it could be directed from outside against a perpendicular masonry wall. In addition, an attacking force that could get close to the wall was able to conduct undermining operations in relative safety, as the defenders could not shoot at them from nearby walls, until the development of Machicolation. In contrast, the bastion fortress was a very flat structure composed of many triangular bastions, specifically designed to cover each other, and a ditch. To counteract the cannonballs, defensive walls were made lower and thicker. To counteract the fact that lower walls were easier to climb, the ditch was widened so that attacking infantry were still exposed to fire from a higher elevation, including enfilading fire from the bastions. The outer side of the ditch was usually provided with a glacis to deflect cannonballs aimed at the lower part of the main wall. Further structures, such as ravelins, tenailles, hornworks or crownworks, and even detached forts could be added to create complex outer works to further protect the main wall from artillery, and sometimes provide additional defensive positions. They were built of many materials, usually earth and brick, as brick does not shatter on impact from a cannonball as stone does.[2]Bastion fortifications were further developed in the late fifteenth and early sixteenth centuries, primarily in response to the French invasion of the Italian peninsula. The French army was equipped with new cannon and bombards that were easily able to destroy traditional fortifications built in the Middle Ages. Star forts were employed by Michelangelo in the defensive earthworks of Florence, and refined in the sixteenth century by Baldassare Peruzzi and Vincenzo Scamozzi. The design spread out of Italy in the 1530s and 1540s.It was employed heavily throughout Europe for the following three centuries. Italian engineers were heavily in demand throughout Europe to help build the new fortifications. The late-seventeenth-century architects Menno van Coehoorn and especially Vauban, Louis XIV's military engineer, are considered to have taken the form to its logical extreme. 'Fortresses... acquired ravelins and redoubts, bonnettes and lunettes, tenailles and tenaillons, counterguards and crownworks and hornworks and curvettes and fausse brayes and scarps and cordons and banquettes and counterscarps...'[3]The star-shaped fortification had a formative influence on the patterning of the Renaissance ideal city: 'The Renaissance was hypnotized by one city type which for a century and a half—from Filarete to Scamozzi—was impressed upon all utopian schemes: this is the star-shaped city.'[4] In the 19th century, the development of the explosive shell changed the nature of defensive fortifications. Elvas, in Portugal is considered by some to be the best surviving example of the Dutch school of fortifications.When the newly-effective manoeuvrable siege cannon came into military strategy in the fifteenth century, the response from military engineers was to arrange for the walls to be embedded into ditches fronted by earthen slopes (glacis) so that they could not be attacked by destructive direct fire and to have the walls topped by earthen banks that absorbed and largely dissipated the energy of plunging fire. Where conditions allowed, as in Fort Manoel in Malta, the ditches were cut into the native rock, and the wall at the inside of the ditch was simply unquarried native rock. As the walls became lower, they also became more vulnerable to assault.The rounded shape that had previously been dominant for the design of turrets created 'dead space', or 'dead zones', which were relatively sheltered from defending fire, because direct fire from other parts of the defences could not be directed around curved walls. To prevent this, what had previously been round or square turrets were extended into diamond-shaped points to eliminate potential cover for attacking troops. The ditches and walls channelled the attackers into carefully constructed zwinger, bailey, or similar 'kill zone' areas where the attackers had no place to shelter from the fire of the defenders.A further and more subtle change was to move from a passive model of defence to an active one. The lower walls were more vulnerable to being stormed, and the protection that the earthen banking provided against direct fire failed if the attackers could occupy the slope on the outside of the ditch and mount an attacking cannon there. Therefore, the shape was designed to make maximum use of enfilade (or flanking) fire against any attackers who should reach the base of any of the walls. The indentations in the base of each point on the star sheltered cannons. Those cannons would have a clear line of fire directly down the edge of the neighbouring points, while their point of the star was protected by fire from the base of those points. The evolution of these ideas can be seen in transitional fortifications such as Sarzana in northwest Italy.[5]Thus forts evolved complex shapes that allowed defensive batteries of cannon to command interlocking fields of fire. Forward batteries commanded the slopes which defended walls deeper in the complex from direct fire. The defending cannon were not simply intended to deal with attempts to storm the walls, but to actively challenge attacking cannon and deny them approach close enough to the fort to engage in direct fire against the vulnerable walls.The key to the fort's defence moved to the outer edge of the ditch surrounding the fort, known as the covered way, or covert way. Defenders could move relatively safely in the cover of the ditch and could engage in active countermeasures to keep control of the glacis, the open slope that lay outside the ditch, by creating defensive earthworks to deny the enemy access to the glacis and thus to firing points that could bear directly onto the walls and by digging counter mines to intercept and disrupt attempts to mine the fort walls.Compared to medieval fortifications, forts became both lower and larger in area, providing defence in depth, with tiers of defences that an attacker needed to overcome in order to bring cannon to bear on the inner layers of defences.Firing emplacements for defending cannon were heavily defended from bombardment by external fire, but open towards the inside of the fort, not only to diminish their usefulness to the attacker should they be overcome, but also to allow the large volumes of smoke that the defending cannon would generate to dissipate.Fortifications of this type continued to be effective while the attackers were armed only with cannon, where the majority of the damage inflicted was caused by momentum from the impact of solid shot. Because only low explosives such as black powder were available, explosive shells were largely ineffective against such fortifications. The development of mortars, high explosives, and the consequent large increase in the destructive power of explosive shells and thus plunging fire rendered the intricate geometry of such fortifications irrelevant. Warfare was to become more mobile. It took, however, many years to abandon the old fortress thinking.Bastion forts were very expensive. Amsterdam's 22 bastions cost 11 million florins, and Siena in 1544 bankrupted itself to pay for its defences. For this reason, bastion forts were often improvised from earlier defences. Medieval curtain walls were torn down, and a ditch was dug in front of them. The earth used from the excavation was piled behind the walls to create a solid structure. While purpose-built fortifications would often have a brick fascia because of the material's ability to absorb the shock of artillery fire, many improvised defences cut costs by leaving this stage out and instead opting for more earth. Improvisation could also consist of lowering medieval round towers and infilling them with earth to strengthen the structures.It was also often necessary to widen and deepen the ditch outside the walls to create a more effective barrier to frontal assault and mining. Engineers from the 1520s were also building massive, gently sloping banks of earth called glacis in front of ditches so that the walls were almost totally hidden from horizontal artillery fire. The main benefit of the glaces was to deny enemy artillery the ability to fire point-blank. The lower the angle of elevation, the higher the stopping power.The first key instance of a trace Italianate was at the Papal port of Civitavecchia, where the original walls were lowered and thickened because the stone tended to shatter under bombardment.The first major battle which truly showed the effectiveness of trace Italienne was the defence of Pisa in 1500 against a combined Florentine and French army. With the original medieval fortifications beginning to crumble to French cannon fire, the Pisans constructed an earthen rampart behind the threatened sector. It was discovered that the sloping earthen rampart could be defended against escalade and was also much more resistant to cannon fire than the curtain wall it had replaced.The second siege was that of Padua in 1509. A monk engineer named Fra Giocondo, trusted with the defence of the Venetian city, cut down the city's medieval wall and surrounded the city with a broad ditch that could be swept by flanking fire from gun ports set low in projections extending into the ditch. Finding that their cannon fire made little impression on these low ramparts, the French and allied besiegers made several bloody and fruitless assaults and then withdrew.The new type of fortification also played a role in the numerous Mediterranean wars, slowing down the Ottoman expansion. Although Rhodes had been partially upgraded to the new type of fortifications after the 1480 siege, it was still conquered in 1522; nevertheless it was a long and bloody siege, and the besieged had no hope of outside relief because the island was close to the Ottoman power base and far from any allies. On the other hand, the Ottomans failed to take Corfu in 1537 in no small part because of the new fortifications, and several attempts spanning almost two centuries (another major one was in 1716) also failed.[7][8]Two star forts were built by the Order of Saint John on the island of Malta in 1552, Fort Saint Elmo and Fort Saint Michael. Fort Saint Elmo played a critical role in the Ottoman siege of 1565 when it managed to hold out heavy bombardment for over a month. Eventually it fell, but the Ottoman casualties were very high, and it bought time for the relief force which arrived from Sicily to relieve the rest of the besieged island. The star fort therefore played a crucial and decisive role in the siege.[9]After the fall of Venice to Napoleon, Corfu was occupied in 1797 by the French republican armies. The now ancient fortifications were still of some value at this point. A Russian–Ottoman–English alliance led at sea by Admiral Ushakov and with troops sent by Ali Pasha retook Corfu in 1799 after a four-month siege, when the garrison led by general Louis François Jean Chabot, being short of provisions and having lost the key island of Vido at the entrance of the port, surrendered and was allowed passage back to France.[10][11]According to Geoffrey Parker in his article, The Military Revolution 1560–1660: A Myth?, the appearance of the trace Italienne in early modern Europe, and the difficulty of taking such fortifications, resulted in a profound change in military strategy, most importantly, Parker argued, an increase in army sizes necessary to attack these forts. 'Wars became a series of protracted sieges,' Parker suggests, and open-pitch battles became 'irrelevant' in regions where the trace Italienne existed. Ultimately, Parker argues, 'military geography', in other words, the existence or absence of the trace Italienne in a given area, shaped military strategy in the early modern period. This is a profound alteration of the Military Revolution thesis originally proposed by Michael Roberts in 1955.Parker's emphasis on the fortification as the key element has attracted substantial criticism from some academics, such as John A. Lynn and M. S. Kingra, particularly with respect to the claimed causal link between the new fortress design and increases in army sizes during this period.[12]In the nineteenth century, with the development of more powerful artillery and explosive shells, star forts were replaced by simpler but more robust polygonal forts. In the twentieth century, with the development of tanks and aerial warfare during and after the First World War, fixed fortifications became and have remained less important than in previous centuries.", 'attributes': {'Bastion fort': {}}} (scraper.py:257)
[2022-03-10 02:02:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Earth_structure>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Earth structure', 'url': 'https://en.wikipedia.org/wiki/Earth_structure', 'date': 202110022308, 'content': "An earth structure is a building or other structure made largely from soil. Since soil is a widely available material, it has been used in construction since prehistoric times.It may be combined with other materials, compressed and/or baked to add strength. Soil is still an economical material for many applications, and may have low environmental impact both during and after construction.Earth structure materials may be as simple as mud, or mud mixed with straw to make cob. Sturdy dwellings may be also built from sod or turf. Soil may be stabilized by the addition of lime or cement, and may be compacted into rammed earth. Construction is faster with pre-formed adobe or mudbricks, compressed earth blocks, earthbags or fired clay bricks.[a]Types of earth structure include earth shelters, where a dwelling is wholly or partly embedded in the ground or encased in soil. Native American earth lodges are examples. Wattle and daub houses use a 'wattle' of poles interwoven with sticks to provide stability for mud walls. Sod houses were built on the northwest coast of Europe, and later by European settlers on the North American prairies. Adobe or mud-brick buildings are built around the world and include houses, apartment buildings, mosques and churches. Fujian Tulous are large fortified rammed earth buildings in southeastern China that shelter as many as 80 families. Other types of earth structure include mounds and pyramids used for religious purposes, levees, mechanically stabilized earth retaining walls, forts, trenches and embankment dams.Soil is created from rock that has been chemically or physically weathered, transported, deposited and precipitated.[2]Soil particles include sand, silt and clay. Sand particles are the largest at 2 to 0.05 millimetres (0.0787 to 0.0020\xa0in) in diameter and clay the smallest at less than 0.002 millimetres (7.9×10−5\xa0in) in diameter.[3]Both sand and silt are mostly inert rock particles, including quartz, calcite, feldspar and mica.[4]Clays typically are phyllosilicate minerals with a sheet-like structure.[3]The very small clay particles interact with each other physically and chemically. Even a small proportion of clay affects the physical properties of the soil much more than might be expected.[4]Clays such as kaolinite do not expand or contract when wetted or dried, and are useful for brick-making. Others, such as smectites, expand or contract considerably when wet or dry, and are not suitable for building.[3]Loam is a mix of sand, silt and clay in which none predominates. Soils are given different names depending on the relative proportions of sand, silt and clay such as 'Silt Loam', 'Clay Loam' and 'Silty Clay'.[5]Loam construction, the subject of this article, referred to as adobe construction when it uses unfired clay bricks, is an ancient building technology. It was used in the early civilizations of the Mediterranean, Egypt and Mesopotamia, in the Indus, Ganges and Yellow river valleys, in Central and South America. As of 2005 about 1.5 billion people lived in houses built of loam.[6][b]In recent years, interest in loam construction has revived in the developed world. It is seen as a way to minimize use of fossil fuels and pollution, particularly carbon dioxide, during manufacture, and to create a comfortable living environment through the high mass and high absorption of the material.[7]The two main technologies are stamped or rammed earth, clay or loam, called pise de terre in French, and adobe, typically using sun-dried bricks made of a mud and straw mixture.[7][c]Earth usually requires some sort of processing for use in construction. It may be combined with water to make mud, straw may be added, some form of stabilizing material such as lime or cement may be used to harden the earth, and the earth may be compacted to increase strength.[8]Coursed mud construction is one of the oldest approaches to building walls. Moist mud is formed by hand to make the base of a wall, and allowed to dry. More mud is added and allowed to dry to form successive courses until the wall is complete. With puddled mud, a hand-made mud form is filled with wetter mud and allowed to dry.[9]In Iran, puddled mud walls are called chine construction. Each course is about 18 to 24 inches (460 to 610\xa0mm) thick, and about 18 to 24 inches (460 to 610\xa0mm) high. Typically the technique is used for garden walls but not for house construction, presumably because of concern about the strength of walls made in this way.[10]A disadvantage to the approach is that a lot of time can be spent waiting for each course to dry.[11]Another technique, used in areas where wood is plentiful, is to build a wood-frame house and to infill it with mud, primarily to provide insulation. In parts of England a similar technique was used with cob.[9]Cob, sometimes referred to as 'monolithic adobe',[12] is a natural building material made from soil that includes clay, sand or small stones and an organic material such as straw. Cob walls are usually built up in courses, have no mortar joints and need 30% or more clay in the soil. Cob can be used as in-fill in post-and-beam buildings, but is often used for load bearing walls, and can bear up to two stories. A cob wall should be at least 16 inches (410\xa0mm) thick, and the ratio of width to height should be no more than one to ten.[12] It will typically be plastered inside and out with a mix of lime, soil and sand. Cob is fireproof, and its thermal mass helps stabilize indoor temperatures.[12] Tests have shown that cob has some resistance to seismic activity. However, building codes in the developed world may not recognize cob as an approved material.[13]Cut sod bricks, called terrone in Spanish, can be used to make tough and durable walls. The sod is cut from soil that has a heavy mat of grass roots, which may be found in river bottom lands. It is stood on edge to dry before being used in construction.[11]European settlers on the North American Prairies found that the sod least likely to deteriorate due to freezing or rain came from dried sloughs.[14] Turf was once extensively used for the walls of houses in Ireland, Scotland and Iceland, where some turf houses may still be found. A turf house may last fifty years or longer if well-maintained in a cold climate.[15]The Icelanders find that the best quality turf is the Strengur, the top 5 centimetres (2.0\xa0in) of the grass turf.[16]Clay is usually hard and strong when dry, but becomes very soft when it absorbs water. The dry clay helps hold an earth wall together, but if the wall is directly exposed to rain, or to water leaking down from the roof, it may become saturated.[17]Earth may be 'stabilized' to make it more weather resistant. The practice of stabilizing earth by adding burnt lime is centuries old.[18]Portland cement or bitumen may also be added to earth intended for construction which adds strength, although the stabilized earth is not as strong as fired clay or concrete.[18] Mixtures of cement and lime, or pozzolana and lime, may also be used for stabilization.[19]Preferably the sand content of the soil will be 65% – 75%. Soils with low clay content, or with no more than 15% non-expansive clay, are suitable for stabilized earth.[20] The clay percentage may be reduced by adding sand, if available.[21]If there is more than 15% clay it may take more than 10% cement to stabilize the soil, which adds to the cost.[20]If earth contains little clay and holds 10% or more cement, it is in effect concrete.Cement is not particularly environmentally friendly, since the manufacturing process generates large amounts of carbon dioxide.[22]Low-density stabilized earth will be porous and weak. The earth must therefore be compacted either by a machine that makes blocks or within the wall using the 'rammed earth' technique.[19]Rammed earth is a technique for building walls using natural raw materials such as earth, chalk, lime or gravel.A rammed earth wall is built by placing damp soil in a temporary form. The soil is manually or mechanically compacted and then the form is removed.[23]Rammed earth is generally made without much water, and so does not need much time to dry as the building rises. It is susceptible to moisture, so must be laid on a course that stops rising dampness, must be roofed or covered to keep out water from above, and may need protection through some sort of plaster, paint or sheathing.[22]In China, rammed earth walls were built by the Longshan people in 2600–1900 BC, during the period when cities first appeared in the region. Thick sloping walls made of rammed earth became a characteristic of traditional Buddhist monasteries throughout the Himalayas and became very common in northern Indian areas such as Sikkim.[24] The technique spread to the Middle East, and to North Africa, and the city of Carthage was built of rammed earth. From there the technology was brought to Europe by the Romans.[25]Rammed earth structures may be long lasting. Most of the Great Wall of China was made from rammed earth, as was the Alhambra in the Kingdom of Granada. In Northern Europe there are rammed earth buildings up to seven stories high and two hundred years old.[22]The Romans made durable concrete strong enough for load-bearing walls.[26] Roman concrete contains a rubble of broken bricks and rocks set in mortar. The mortar included lime and pozzolana, a volcanic material that contributed significantly to its strength.[27] Roman concrete structures such as the Colosseum, completed in 80 AD, still stand.[28]Their longevity may be explained by the fact that the builders used a relatively dry mix of mortar and aggregate and compacted it by pounding it down to eliminate air pockets.[29] Although derived from earth products, concrete structures would not usually be considered earth structures.[1]Mudbricks or Adobe bricks are preformed modular masonry units of sun-dried mud that were invented at different times in different parts of the world as civilization developed.[30] Construction with bricks avoids the delays while each course of puddled mud dries. Wall murals show that adobe production techniques were highly advanced in Egypt by 2500 BC.[11] Adobe construction is common throughout much of Africa today.[31] Adobe bricks are traditionally made from sand and clay mixed with water to a plastic consistency, with straw or grass as a binder.[32][d]The mud is prepared, placed in wooden forms, tamped and leveled, and then turned out of the mold to dry for several days. The bricks are then stood on end to air-cure for a month or more.[32]In the southwest United States and Mexico adobe buildings had massive walls and were rarely more than two stories high. Adobe mission churches were never more than about 35 feet (11\xa0m).[33]Since adobe surfaces are fragile, coatings are used to protect them. These coatings, periodically renewed, have included mud plaster, lime plaster, whitewash[e] or stucco.[34]Adobe walls were historically made by laying the bricks with mud mortar, which swells and shrinks at the same rate as the bricks when wetted or dried, heated or cooled. Modern adobe may be stabilized with cement and bonded with cement mortars, but cement mortars will cause unstabilized adobe bricks to deteriorate due to the different rates of thermal expansion and contraction.[33]Compressed earth blocks (CEB) were traditionally made by using a stick to ram soil into a wooden mold. Today they are usually made from subsoil compressed in a hand-operated or powered machine. In the developing world, manual machines can be a cost-effective solution for making uniform building blocks, while the more complex and expensive motorized machines are less likely to be appropriate. Although labor-intensive, CEB construction avoids the cost of buying and transporting materials.[35]Block-making machines may form blocks that have interlocking shapes to reduce the requirement for mortar.The block may have holes or grooves so rods such as bamboo can be inserted to improve earthquake resistance.[36]Suitable earth must be used, with enough clay to hold the block together and resist erosion, but not too much expansive clay.[37]When the block has been made from stabilized earth, which contains cement, the concrete must be given perhaps three weeks to cure.During this time the blocks should be stacked and kept from drying out by sprinkling water over them. This may be a problem in hot, dry climates where water is scarce.Closely stacking the blocks and covering them with a polythene sheet may help reduce water loss.[38]Earthbag construction is a natural building technique that has evolved from historic military construction techniques for bunkers.[39]Local subsoil of almost any composition can be used, although an adobe mix would be preferable.The soil is moistened so it will compact into a stable structure when packed into woven polypropylene or burlap sacks or tubes. Plastic mesh is sometimes used. Polypropylene (pp) sacks are most common, since they are durable when covered, cheap, and widely available.[39]The bags are laid in courses, with barbed wire between each course to prevent slipping. Each course is tamped after it is laid.[40]The structure in pp bags is similar to adobe but more flexible. With mesh tubing the structure is like rammed earth.[39]Earthbags may be used to make dome-shaped or vertical wall buildings. With soil stabilization they may also be used for retaining walls.[41]The technique of firing clay bricks in a kiln dates to about 3500 BC. Fired bricks were being used to build durable masonry across Europe, Asia and North Africa by 1200 BC and still remain an important building material.[42] Modern fired clay bricks are formed from clays or shales, shaped and then fired in a kiln for 8–12 hours at a temperature of 900–1150\xa0°C.[43][f]The result is a ceramic that is mainly composed of silica and alumina, with other ingredients such as quartz sand. The porosity of the brick depends on the materials and on the firing temperature and duration. The bricks may vary in color depending on the amount of iron and calcium carbonate in the materials used, and the amount of oxygen in the kiln.[43]Bricks may decay due to crystallization of salts on the brick or in its pores, from frost action and from acidic gases.[45]Bricks are laid in courses bonded with mortar, a combination of Portland cement, lime and sand.[46]A wall that is one brick thick will include stretcher bricks with their long, narrow side exposed and header bricks crossing from side to side. There are various brickwork 'bonds', or patterns of stretchers and headers, including the English, Dutch and Flemish bonds.[47]Earth sheltering has been used for thousands of years to make energy-efficient dwellings.[48]There are various configurations. At one extreme, an earth sheltered dwelling is completely underground, with perhaps an open courtyard to provide air and light. An earth house may be set into a slope, with windows or door openings in one or more of its sides, or the building may be on ground level, but with earth mounded against the walls, and perhaps with an earth roof.[49]Pit houses made by Hohokam farmers between 100 and 900 AD, in what is now the southwest of the US, were bermed structures, partially embedded in south-facing slopes. Their successful design was used for hundreds of years.[50]At Matmata, Tunisia, most of the ancient homes were built 12 metres (39\xa0ft) below ground level, and surrounded courtyards about 12 metres (39\xa0ft) square.[51][g]The homes were reached through tunnels. Other examples of subterranean, semi-subterranean or cliff-based dwellings in both hot and cold climates are found in Turkey, northern China and the Himalayas, and the southwest USA.[51] A number of Buddhist monasteries built from earth and other materials into cliff sides or caves in Himalayan areas such as Tibet, Bhutan, Nepal and northern India are often perilously placed. Starting in the 1970s, interest in the technique has revived in developed countries.[48] By setting an earth house into the ground, the house will be cooler in the warm season and warmer in the cool season.[49]An earth lodge is a circular building made by some of the Native Americans of North America. They have wood post and beam construction and are dome-shaped.[53]A typical structure would have four or more central posts planted in the ground and connected at the top by cross beams. The smoke hole would be left open in the center. Around the central structure there was a larger ring of shorter posts, also connected by cross beams. Rafters radiated from the central cross beams to the outside cross beams, and then split planks or beams formed the slanting or vertical side walls.[54]The structure was covered by sticks and brush or grass, covered in turn by a heavy layer of earth or sod.Some groups plastered the whole structure with mud, which dried to form a shell.[54]Wattle and daub is an old building technique in which vines or smaller sticks are interwoven between upright poles, and then mud mixed with straw and grass is plastered over the wall.[55]The technique is found around the world, from the Nile Delta to Japan, where bamboo was used to make the wattle.[56]In Cahokia, now in Illinois, USA, wattle and daub houses were built with the floor lowered by 1 to 3 feet (0.30 to 0.91\xa0m) below the ground. A variant of the technique is called bajareque in Colombia.[55]In prehistoric Britain simple circular wattle and daub shelters were built wherever adequate clay was available.[57]Wattle and daub is still found as the panels in timber-framed buildings.[58] Generally the walls are not structural, and in interior use the technique in the developed world was replaced by lath and plaster, and then by gypsum wallboard.[56]European pioneer farmers in the prairies of North America, where there is no wood for construction, often made their first home in a dug-out cave in the side of a hill or ravine, with a covering over the entrance. When they had time, they would build a sod house. The farmer would use a plow to cut the sod into bricks 1 by 2 feet (0.30 by 0.61\xa0m), which were then piled up to form the walls.[59]The sod strips were piled grass-side down, staggered in the same way as brickwork, in three side-by-side rows, resulting in a wall over 3 feet (0.91\xa0m) thick. The sod wall was built around door and window frames, and the corners of the wall were secured by rods driven vertically through them. The roof was made with poles or brush, covered with prairie grass, and then sealed with a layer of sod.[60]Sod houses were strong and often lasted many years, but they were damp and dirty unless the interior walls were plastered.[59]The roofs tended to leak, and sometimes collapsed in a rainstorm.[60]There are innumerable examples of mud brick or adobe building around the world. The walled city of Shibam in Yemen, designated a World Heritage Site in 1982, is known fr its ten-story unreinforced mud-brick buildings.[61]The Djinguereber Mosque of Timbuktu, Mali, was first built at the start of the 14th century AD (8th century AH) from round mud bricks and a stone-mud misture, and was rebuilt several times afterwards, steadily growing in size.[62]Further south in Mali, the Great Mosque of Djenné, a dramatic example of Sahel mudbrick architecture. was built in 1907, based on the design of an earlier Great Mosque first built on the site in 1280. Mudbrick requires maintenance, and the fundamentalist ruler Seku Amadu had let the previous mosque collapse.[63]The Casa Grande Ruins, now a national monument in Arizona protected by a modern roof, is a massive four-story adobe structure built by Hohokam people between 1200 and 1450 AD.[64]The first European to record the great house was a Jesuit priest, Father Eusebio Kino, who visited the site in 1694. At that time it had long been abandoned.[65]By the time a temporary roof was installed in 1903 the adobe building had been standing empty and unmaintained for hundreds of years.[66]Huaca de la Luna in what is now northern Peru is a large adobe temple built by the Moche people. The building went through a series of construction phases, growing eventually to a height of about 32 metres (105\xa0ft), with three main platforms, four plazas and many smaller rooms and enclosures. The walls were covered by striking multi-colored murals and friezes; those visible today date from about 400–610 AD.[67]High-rise mud brick buildings in ShibamMud wall and mosque in TimbuktuOld mud dwellings and modern mud mosque in MaliGreat Mosque of Djenné, Mali, in 1972Casa Grande Ruins National Monument in ArizonaSan Francisco de Asis Mission Church at Ranchos de Taos, New MexicoInterior of Huaca de la Luna, Trujillo, PeruArt on an adobe building at Shantiniketan University, Bolpur, West BengalA Fujian Tulou is a type of rural dwelling of the Hakka people in the mountainous areas in southeastern Fujian, China.[68]They were mostly built between the 13th and the 20th centuries.[69] A tulou is a large, enclosed and fortified earth building, rectangular or circular, with very thick load-bearing rammed earth walls between three and five stories high.A toulou might house up to 80 families. Smaller interior buildings are often enclosed by these huge peripheral walls which can contain halls, storehouses, wells and living areas.The structure resembles a small fortified city.[70]The walls are formed by compacting earth mixed with stone, bamboo, wood and other readily available materials, and are to 6 feet (1.8\xa0m) thick. The result is a well-lit, well-ventilated, windproof and earthquake-proof building that is warm in winter and cool in summer.[70]Ziggurats were elevated temples constructed by the Sumerians between the end of the 4th millennium BC and the 2nd millennium BC, rising in a series of terraces to a temple up to 200 feet (61\xa0m) above ground level. The Ziggurat of Ur contained about three million bricks, none more than 15 inches (380\xa0mm) in length, so construction would have been a huge project.[71]The largest ziggurat was in Babylon, and is thought by some to be the Tower of Babel mentioned in the Bible. It was destroyed by Alexander the Great and only the foundations remain, but originally it stood 300 feet (91\xa0m) high on a base about 660 feet (200\xa0m) square.[72]Sun-dried bricks were used for the interior and kiln-fired bricks for the facing. The bricks were held together by clay or bitumen.[73]Many pre-Columbian Native American societies of ancient North America built large pyramidal earth structures known as platform mounds. Among the largest and best-known of these structures is Monks Mound at the site of Cahokia in what became Illinois, completed around 1100 AD, which has a base larger than that of the Great Pyramid at Giza. Many of the mounds underwent multiple episodes of mound construction at periodic intervals, some becoming quite large. They are believed to have played a central role in the mound-building peoples' religious life and documented uses include semi-public chief's house platforms, public temple platforms, mortuary platforms, charnel house platforms, earth lodge/town house platforms, residence platforms, square ground and rotunda platforms, and dance platforms.[74][75]The 207 feet (63\xa0m) Pyramid of the Sun in Teotihuacan, Mexico, was started in 100 AD. The stone-faced structure contains two million tons of rammed earth.[25]Earthworks are engineering works created through moving or processing quantities of soil or unformed rock. The material may be moved to another location and formed into a desired shape for a purpose.[76]Levees, embankments and dams are types of earthwork.A levee, floodbank or stopbank is an elongated natural ridge or artificially constructed dirt fill wall that regulates water levels. It is usually earthen and often runs parallel to the course of a river in its floodplain or along low-lying coastlines.[77]Mechanically stabilized earth (MSE) retaining walls may be used for embankments.[78]MSE walls combine a concrete leveling pad, wall facing panels, coping, soil reinforcement and select backfill.[79]A variety of designs of wall facing panels may be used.[79]After the leveling pad has been laid and the first row of panels has been placed and braced, the first layer of earth backfill is brought in behind the wall and compacted.The first set of reinforcements is then laid over the earth.[80]The reinforcements, which may be tensioned polymer or galvanized metal strips or grids, are attached to the facing panels.[81]This process is repeated with successive layers of panels, earth and reinforcements.The panels are thus tied into the earth embankment to make a stable structure with balanced stresses.[82]Although construction using the basic principles of MSE has a long history, MSE was developed in its current form in the 1960s. The reinforcing elements used can vary but include steel and geosynthetics. The term MSE is usually used in the US to distinguish it from 'Reinforced Earth', a trade name of the Reinforced Earth Company, but elsewhere Reinforced Soil is the generally accepted term.[78] MSE construction is relatively fast and inexpensive, and although labor-intensive, it does not demand high levels of skill. It is therefore suitable for developing as well as developed countries.[83]Earth has been used to construct fortifications for thousands of years, including strongholds and walls, often protected by ditches.Aerial photography in Europe has revealed traces of earth fortifications from the Roman era, and later medieval times.[84]Offa's Dyke is a huge earthwork that stretches along the disputed border between England and Wales.[85]Little is known about the period or the builder, King Offa of Mercia, who died in 796 AD.[86]An early timber and earth fortification might later be succeeded by a brick or stone structure on the same site.[87]Trenches were used by besieging forces to approach a fortification while protected from missiles.Sappers would build 'saps', or trenches, that zig-zagged towards the fortress being attacked.They piled the excavated dirt to make a protective wall or gabion. The combined trench depth and gabion height might be 8 to 10 feet (2.4 to 3.0\xa0m). Sometimes the sap was a tunnel, dug several feet below the surface. Sappers were highly skilled and highly paid due to the extreme danger of their work.[88]In the American Civil War (1861−1865) trenches were used for defensive positions throughout the struggle, but played an increasingly important role in the campaigns of the last two years.[89]Military earthworks perhaps culminated in the vast network of trenches built during World War I (1914−1918) that stretched from Switzerland to the North Sea by the end of 1914.[90]The two lines of trenches faced each other, manned by soldiers living in appalling conditions of cold, damp and filth.[91]Conditions were worst in the Allied trenches. The Germans were more willing to accept the trenches as long-term positions, and used concrete blocks to build secure shelters deep underground, often with electrical lighting and heating.[92]An embankment dam is a massive artificial water barrier. It is typically created by the emplacement and compaction of a complex semi-plastic mound of various compositions of soil, sand, clay and/or rock. It has a semi-permanent natural waterproof covering for its surface, and a dense, waterproof core. This makes such a dam impervious to surface or seepage erosion.[93]The force of the impoundment creates a downward thrust upon the mass of the dam, greatly increasing the weight of the dam on its foundation. This added force effectively seals and makes waterproof the underlying foundation of the dam, at the interface between the dam and its stream bed.[94] Such a dam is composed of fragmented independent material particles. The friction and interaction of particles binds the particles together into a stable mass rather than by the use of a cementing substance.[95]The Syncrude Mildred Lake Tailings Dyke in Alberta, Canada, is an embankment dam about 18 kilometres (11\xa0mi) long and from 40 to 88 metres (131 to 289\xa0ft) high. By volume of fill, as of 2001 it was believed to be the largest earth structure in the world.[96]Regions with low seismic risk are safe for most earth buildings, but historic construction techniques often cannot resist even medium earthquake levels effectively because of earthen buildings' three highly undesirable qualities as a seismic building material: being relatively 'weak, heavy and brittle'. However, earthen buildings can be built to resist seismic loads.[97]Key factors to improved seismic performance are soil strength, construction quality, robust layout and seismic reinforcement.[98]Stronger soils make stronger walls. Adobe builders can test cured blocks for strength by dropping from a specific height or by breaking them with a lever.[99] Builders using immediate techniques like earthbag, cob, or rammed earth may prefer approximate crushing tests on smaller samples that can be oven-dried and crushed under a small lever.[100]Builders must understand construction processes and be able to produce consistent quality for strong buildings.[101]Robust layout means buildings more square than elongated, and symmetrical not L-shaped,[102] as well as no 'soft' first stories (stories with large windows, buildings on unbraced columns). New Zealand's earthen building guidelines check for enough bracing wall length in each of the two principal directions, based on wall thickness, story height, bracing wall spacing, and the roof, loft and second story weight above earthen walls.[103]Building techniques that are more ductile than brittle, like the contained earth type of earthbag, or tire walls of earthships, may better avoid collapse than brittle unreinforced earth. Contained gravel base courses may add base isolation potential.Wall containment can be added to techniques like adobe to resist loss of material that leads to collapse.[104] Confined masonry is effective for adobe against quake forces of 0.3 g[105][106] may be useful with earthen masonry.Many types of reinforcement can increase wall strength, such as plastic or wire mesh and reinforcing rods of steel or fiberglass or bamboo. Earth resists compression well but is weak when twisted. Tensile reinforcement must span potential damage points and be well-anchored to increase out-of-plane stability. Bond beams at wall tops are vital and must be well attached to walls.[107]Builders should be aware that organic reinforcements embedded in walls may be destroyed before the building is retired. Attachment details of reinforcement are critical to resist higher forces. Best adobe shear strength came from horizontal reinforcement attached directly to vertical rebar spanning from footing to bond beam.[108]Interlaced wood in earthen walls reduces quake damage if wood is not damaged by dry rot or insects. Timberlacing includes finely webbed Dhajji,[109] and other types.[110]", 'attributes': {'Earth structure': {}}} (scraper.py:257)
[2022-03-10 02:02:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Palanka_(fortification)>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': 'Palanka (fortification)', 'url': 'https://en.wikipedia.org/wiki/Palanka_(fortification)', 'date': 202107252158, 'content': "A palanka (Turkish pronunciation:\xa0[paˈɫaŋka]), also known as parkan in Southern Hungary and palanga,[3][4] was a wooden fortification used by the Ottoman Empire extensively in certain regions of Southeast Europe, including Hungary, the Balkans and the Black Sea coast against rival states, especially the Archduchy of Austria and the Kingdom of Hungary.[5][6] Such wooden forts could be built and expanded quickly, and usually contained a small garrison. These fortifications varied in size and shape but were primarily constructed of palisades. Palankas could be adjacent to a town[7] and later they could be replaced by a more formidable stone fortress as in the case of Uyvar.[8] Palankas could also be built as an extension of the main fortress.[9] Many Ottoman forts were a mixture of palanka type fortifications and stonework.[10] Evliya Çelebi describes the word palanka also as a technique of timber masonry.[1][9]Some palankas developed into larger settlements and word palanga has been also used to describe rural settlements which originates from palankas in Erzincan, Eastern Anatolia.[6]The word comes from Hungarian 'palánkvár' which itself comes from Middle Latin 'palanca' meaning log which is derived from Ancient Greek 'phálanks' or 'phalang' (φάλανξ, φαλαγγ) also meaning log.[11]Typical palanka had a rectangular plan and its entrance could be guarded by a watchtower called ağaçtan lonca köşkü. Walls of a palanka could be made of a single palisade as well as two rows of stockade, creating a gap in between which is filled with earth which might be acquired from the ditch dug around the fortification, called şarampa, thus creating a protected walkway.[7][1] The inner and outer palisades were held together by transverse beams, whose ends were fixed to the outer walls by wooden pins, to counter the pressure of earth filling.[10] In order to increase resistance against cannon fire, wooden walls could be strengthened by applying mortar in a technique called horasani palanka.[2] After that, military buildings such as bastions which cannons are placed, towers, barracks and civilian buildings such as inns, marketplaces, mosques, cisterns could be added. Lastly, a stockade could be constructed around the palanka as a secondary fortification.[5][1]Palankas were the basis of Ottoman frontier defence system in Europe[5] and their purpose was to protect military and riverine routes, which had strategic value, and travellers, who were passing through these routes, against plunderers. These routes connected palankas, thus leading to creation of a defense network.[1] They also allowed effective communication between strategic areas.[12] When Ottoman reached the limit of their conquests in Europe, they used these structures to stabilize the frontier.[4]Although palankas were not indestructible on their own, they were interconnected structures, and if an army too strong to resist attacked, the forces of the other palankas would come to their aid.[5] Wooden walls of palankas were difficult to ignite since they were filled with earth; and stakes used to build them were damp.[7] Most of the troops in palankas were azaps[13] and a palanka functioning in the frontier could have a higher ratio of cavalry troops compared to a fortress defended by cannons.[14]Palankas showed similarities to Roman limes system. In the pre-Ottoman period, there used to be fortifications, where palankas were constructed, and after the conquests these fortifications were rebuilt with remarkable Ottoman characteristics. Due to their makeshift aspect few palankas survive today but researches show that this kind of structures were used between 14th and late 19th century.[12]Havale, which is the fortification that palanka was inspired, acted as a base for troops and artillery during sieges of early Ottoman era. 15th century Ottoman historian Aşıkpaşazade mentions that this kind of fortresses were built during the Siege of Bursa (1326). Havale type forts were also built during the Siege of Sivrihisar in Karaman, and in Giurgiu during the campaign to Hungary (1435–36) by Murad II.[1]Palanka ÁdonyPalanka BaranyavarPalanka PaksPalanka Szeksard", 'attributes': {'Palanka (fortification)': {}}} (scraper.py:257)
[2022-03-10 02:02:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://en.wikipedia.org/wiki/Serpent%27s_Wall>
{'keyword': 'earth fortification', 'source': 'wiki', 'title': "Serpent's Wall", 'url': 'https://en.wikipedia.org/wiki/Serpent%27s_Wall', 'date': 202201272224, 'content': "Serpent's Wall (Ukrainian: Змієві вали, romanized:\xa0Zmiievi valy is an ancient system of earthen earthworks (valla) located in the middle Dnieper Ukraine (Naddniprianshchyna)[1] that stretch across primarily Kyiv Oblast, Ukraine. They seem to be similar in purpose and character to Trajan's Wall situated to the southwest in Bessarabia. The remaining ancient walls have a total length of 1,000\xa0km and constitute less than 20% of the original wall system.[1]According to a legend, the earthworks are results of ancient events when a mythical hero (bohatyr) Kozmodemian (or Borysohlib) in order to slay gargantuan Dragon (Serpent) harnessed it in a giant plow and furrowed.[1] The Dragon (Serpent) bit the dust and from plowing there were left furrows on both sides of which towered immense chunks of earth that among people were named as Serpent's Wall.[1]The ancient walls were built between the 2nd century BC and 7th century AD, according to carbon dating. There are three theories as to what peoples built the walls: either the Sarmatians against the Scythians, or the Goths of Oium against the Huns, or the Early East Slavs against the nomads of the southern steppes. In Slavic culture, the warlike nomads are often associated with the winged dragon, hence the name.On the right bank of Dnieper between its tributaries Teteriv and Ros the remnants of wall create six lines elongated from west to east.[1] One Serpent's Wall was passed over the left bank of Dnieper and its tributary Sula.[1]The 1974-85 explorations has established that Serpent's Wall is a remnant of wooded earth fortifications built at the end of 10th and the first half of 11th centuries, smaller part in the 12th century, to protect middle Dnieper Ukraine and Kyiv from pechenegs and cumans.[1]Vallums near village of Ivankovychi, Vasylkiv RaionWall near village of IvankovycheThis Ukrainian history-related article is a stub. You can help Wikipedia by expanding it.", 'attributes': {"Serpent's Wall": {}}} (scraper.py:257)
[2022-03-10 02:02:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E6%B5%B7%E8%BB%8D%E6%B5%B7%E6%B4%8B%E7%9B%A3%E5%81%B5%E6%8C%87%E6%8F%AE%E9%83%A8>
{'keyword': '西屿雷达站', 'source': 'wiki', 'title': '中华民国海军海洋监侦指挥部', 'url': 'https://zh.wikipedia.org/wiki/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E6%B5%B7%E8%BB%8D%E6%B5%B7%E6%B4%8B%E7%9B%A3%E5%81%B5%E6%8C%87%E6%8F%AE%E9%83%A8', 'date': ' ', 'content': '海军海洋监侦指挥部为中华民国海军岸置地对海雷达部队。', 'attributes': {'中华民国海军海洋监侦指挥部': {'存在时期': '1965年至今', '国家或地区': '中华民国', '效忠于': '中华民国', '军种': ' 中华民国海军', '种类': '雷达部队', '规模': '指挥部', '隶属于': '海军舰队指挥部', '装备': '机动雷达车、维星车、电战车、机动诱标车', '别称': '海侦部', 'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/ROCN_Rear_Admiral%27s_Flag.svg/25px-ROCN_Rear_Admiral%27s_Flag.svg.png']}}} (scraper.py:257)
[2022-03-10 02:02:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/SdKfz_252%E5%8D%8A%E5%B1%A5%E5%B8%A6%E8%BD%A6>
{'keyword': '装甲运输车', 'source': 'wiki', 'title': 'SdKfz 252半履带车', 'url': 'https://zh.wikipedia.org/wiki/SdKfz_252%E5%8D%8A%E5%B1%A5%E5%B8%A6%E8%BD%A6', 'date': ' ', 'content': '第252号特种车辆（德语：Sonderkraftfahrzeug 252，简称：Sd.Kfz. 252），又称轻型装甲弹药运输车（leichter gepanzerter Munitionskraftwagen），是纳粹德国在二战期间使用的一款轻型半履带装甲运输车。Sd.Kfz. 252的设计基于Sd.Kfz. 250半履带车，并使用同款底盘。1940年6月至12月由德马格（英语：Demag）和韦格曼（英语：Krauss-Maffei Wegmann）负责生产。1941年1月至9月则由德意志造船厂负责生产，一共制造了413辆[1]。主要用途是为突击炮部队运输弹药，在东西线皆有使用。为了增加弹药运载能力，使用Sd.Ah. 32/1（Sonder-Anhänger 32/1） 拖车，可以额外运载36枚75毫米炮弹[2]。法国战役期间，第640和659突击炮连使用了Sd.Kfz. 252。在东线，使用者为第184、190和210突击炮营[3]。1941年之后停止生产，被Sd.Kfz. 250/6半履带车取代[4]。', 'attributes': {'SdKfz 252半履带车': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Bundesarchiv_Bild_101I-154-1968-16%2C_Russland%2C_Sch%C3%BCtzenpanzer_im_Gel%C3%A4nde.jpg/181px-Bundesarchiv_Bild_101I-154-1968-16%2C_Russland%2C_Sch%C3%BCtzenpanzer_im_Gel%C3%A4nde.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Balkenkreuz.svg/30px-Balkenkreuz.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/Sd.Kfz._252_01.png/300px-Sd.Kfz._252_01.png'], '类型': '轻型半履带装甲弹药运输车', '原产地': '纳粹德国', '服役期间': '1940年-？', '参与战争／冲突': '二战', '研发者': '德马格（英语：Demag）', '生产商': '德马格（英语：Demag）、韦格曼（英语：Krauss-Maffei Wegmann）、德意志造船厂', '生产日期': '1940年6月至12月（德马格、韦格曼)，1941年1月至9月（德意志造船厂）', '制造数量': '413', '重量': '5.73吨', '长度': '4.7米', '宽度': '1.95米', '高度': '1.8米', '操作人数': '2', '发动机': '迈巴赫HL42 TRKM 6缸水冷引擎', '作战范围': '320公里 公路175公里 越野', '速度': '65公里/小时'}}} (scraper.py:257)
[2022-03-10 02:02:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6>
{'keyword': '装甲救护车', 'source': 'wiki', 'title': '装甲车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6', 'date': ' ', 'content': '装甲车辆是具有装甲防护的各种车辆的统称。坦克和自走炮也是广义的重型装甲车辆，但是在习惯上通常因作战用途另外独立分类，而装甲车辆多半是指防护力与火力较坦克弱的车种，而自行炮在原则上不一定要有装甲。装甲车的特性为具有高度的越野机动性能，有一定的防护和火力，分为履带式和轮式两种。一般军用装甲车会装备一至三门中小口径火炮及数挺机枪，一些还装有反坦克导弹，结构以装甲车体、武器系统、动力装置等组成。为了增强防护和方便成员下车战斗。大多数军用装甲车辆可以在水上行驶，可以执行运输、侦察、指挥、救护、伴随、支援坦克及步兵作战等多种任务，还有执行专门任务的装甲车辆，如装甲回收车、装甲指挥车、装甲扫雷车、装甲架桥车等。在警用领域多用于镇压暴乱等问题。步兵战车和装甲输送车作用相近，都是运送步兵机动作战用的装甲车辆，两者不同的地方是步兵战车的防护力较好，火力较大，能够让步兵乘车作战，本身也能够伴随下车作战的步兵，提供火力支援速度较好，装甲输送车则更接近于有装甲的运输车辆。装甲输送车为在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。装甲侦察车指装有侦察设备的装甲车辆，速度较快但装甲比其它装甲车辆要薄，多用于战场侦察，一般可分为轮式和履带式两种。较著名的装甲侦察车，有德国的狐式轻型装甲侦察车、山猫装甲侦察车，法国的雷诺VBC90轮式侦察车（英语：VBC-90）等等。装甲指挥车是具有装甲保护的移动指挥站，提供指挥官与支援的参谋和其他人员协调部队的相关事宜。装甲指挥车是早期以卡车或者是拖车为基础的移动指挥所衍生出来的架构，用意在于提供指挥单位快速移动，持续掌握情势与下达命令命且提供一些保护。大部分的装甲指挥车是从装甲输送车改装而成，扩大内部的空间以容纳额外的人员，通讯器材与其他设备。在到达预定指挥地点之后，部分装甲指挥车还有另外设置的顶蓬可以伸出车外，进一步的扩大人员使用的空间。装甲通信车是指装有通信设备的装甲车辆，常见的设计有两种型态，一种是将通信装备与装甲指挥车合并在一起，因此并非单纯的通信车辆。另外一种是做为地面通信的活动中转站，以延伸无线电通信的有效距离，或者是克服地形对通信的遮蔽效应，强化地面单位之间的联络与资讯交换。目前各国陆军很少装备单纯的装甲通信车，不过有不少国家配备由一般运输车辆改装的通信车辆来支援地面部队的通信需求。装甲救护车，指在战场环境下实行人员救护的装甲车辆，一般只装备一至两挺机枪作为自卫武器，防护力亦很弱。主要用于抢救人员，并将重伤员运送至后方。装甲扫雷车特指装有清除地雷装置的装甲车辆，以协助地面部队扩速通过地雷区。装甲扫雷车可以是专门设计用来清除地雷，或者是将清除工具附加在一般用途的坦 克底盘上，无论是车轮或是履带型态的扫雷车都可见于不同国家的部队当中。装甲扫雷车并非用于清除整个被发现的地雷区，而是将地雷区清理出一至数条的安全通道，提供地面部队人员和车辆安全通过。排除的地雷可能在过程中加以引爆，或者是移动到安全的地方之后另外加以处理。由于清理的过程当中，扫雷车可能碰触或者是引爆其他尚未发现的地雷或者是爆裂物，车辆本身对于底盘和车辆底部的保护需要特别加强，以免被地雷或者是爆裂物瘫痪而无法完成清除的任务。装甲架桥车指装有车桥及其架设、撤收装置的装甲车辆，主要用于快速架设桥梁，令部队迅速通过河流，普遍装备于工兵部队。装甲架桥车可由一般坦克或自走炮底盘改装而成，部分会保留机枪作防卫用途。步兵坦 克和装甲输送车 - 当示威活动和抗争会转变成失控的暴乱或群众暴力时，警方有时会出动警用装甲车控制场面。一般具有水炮功能，而车窗经特别制造，不易打碎。各地警方大多都有装甲车，以防范暴乱发生。保安公司常用，用来运载现金或其他贵重物品，又称“解款车”或“运钞车”。另外政要及富豪也会使用经过改装、具有防弹甚至抗炸能力的汽车。', 'attributes': {'装甲车': {}}} (scraper.py:257)
[2022-03-10 02:02:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4>
{'keyword': '花莲机场', 'source': 'wiki', 'title': '花莲机场', 'url': 'https://zh.wikipedia.org/wiki/%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4', 'date': ' ', 'content': '花莲机场（阿美语：Pahikukiyan nu Kalinku，太鲁阁语：Rduwan Msangay Asu Skiya Skangki，IATA代码：HUN；ICAO代码：RCYU）是位于台湾花莲县新城乡的机场，场区位在花莲市中心北方，横亘整个新城乡最南部。该机场为一军民合用机场（英语：Civil enclave），也是东台湾第一座国际机场，主要由中华民国空军管理，分为山侧的空军佳山基地、以及海侧的空军花莲基地；民用部分位于海侧，称为花莲航空站，由交通部民用航空局经营。由于本场为军民合用，机场内有大量军事设施，故禁止于起降时对机场内摄影。花莲机场的前身是日治时期的“花莲港北飞行场”，兴建于1936年，属于军民共用的机场，由日本航空运输（日语：日本航空輸送）经营。第二次世界大战结束后，由中华民国政府接收。※视评估扩充5~7号登机门及空桥，扩建工程第一期第一阶段并无建设。国内航线由立荣航空及华信航空营运台北松山、台中及高雄共3条航线，主要以ATR72-600机型执飞。国际航线由韩国低成本航空公司易斯达航空营运韩国首尔仁川、釜山共2条包机航线，主要以B737-800机型执飞，目前因2019冠状病毒病关系停航。', 'attributes': {'花莲机场': {'img_url': ['https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Hualien_Air_Force_Base_entrance_20120210.jpg/220px-Hualien_Air_Force_Base_entrance_20120210.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/%E5%8D%B3%E5%B0%87%E9%99%8D%E8%90%BD%E6%96%BC%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4%E7%9A%84%E8%8F%AF%E4%BF%A1%E8%88%AA%E7%A9%BA%28%E6%94%9D%E6%96%BC%E8%8A%B1%E8%93%AE%E5%B8%82%E5%9C%8B%E5%BC%B7%E9%87%8C%29.jpg/220px-%E5%8D%B3%E5%B0%87%E9%99%8D%E8%90%BD%E6%96%BC%E8%8A%B1%E8%93%AE%E6%A9%9F%E5%A0%B4%E7%9A%84%E8%8F%AF%E4%BF%A1%E8%88%AA%E7%A9%BA%28%E6%94%9D%E6%96%BC%E8%8A%B1%E8%93%AE%E5%B8%82%E5%9C%8B%E5%BC%B7%E9%87%8C%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Road_signs_in_Hualien_Airport.jpg/220px-Road_signs_in_Hualien_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%BA%94%E6%88%B0%E8%A1%93%E6%B7%B7%E5%90%88%E8%81%AF%E9%9A%8A.png/80px-%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E7%A9%BA%E8%BB%8D%E7%AC%AC%E4%BA%94%E6%88%B0%E8%A1%93%E6%B7%B7%E5%90%88%E8%81%AF%E9%9A%8A.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/HuaLien_Airport.jpg/280px-HuaLien_Airport.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Taiwan_location_map.svg/250px-Taiwan_location_map.svg.png'], '机场类型': '军民合用', '所有者': '交通部民用航空局国防部空军司令部', '营运者': '军用： 中华民国空军民用： 交通部民用航空局', '服务城市': '花莲市', '地理位置': '中华民国（台湾）花莲县新城乡嘉里村机场一号', '启用日期': '1962年5月16日(1962-05-16)', '海拔高度': '51英尺（16米）', '坐标': '24°01′24″N 121°36′36″E\ufeff / \ufeff24.02333°N 121.61000°E\ufeff / 24.02333; 121.61000坐标：24°01′24″N 121°36′36″E\ufeff / \ufeff24.02333°N 121.61000°E\ufeff / 24.02333; 121.61000', '网址': 'www.hulairport.gov.tw', '方向': ';;;方向;;长度;;表面;;;米;;英尺;;;03/21;;2,751;;9,026;;混凝土;;', '客运量': '客运量214,279人次货运量402.2公吨起降架次4,799次', '国家（地区）': '中华民国（台湾）', '位置': '花莲县', '类型': '航空安检站', '出入境管理机关': '内政部移民署国境事务大队基隆港国境事务队', '海关': '财政部关务署基隆关', '繁体字': ' 花蓮機場 ', '简化字': ' 花莲机场 ', '标音': "标音官话-汉语拼音 Huā lián  Jī chǎng -威妥玛拼音 hua lien2 chi ch'ang3 -耶鲁拼音 Hwā lyán Jī chǎng -注音符号ㄏㄨㄚ ㄌㄧㄢˊ ㄐㄧ ㄔㄤˇ闽语-闽南语白话字 Hoa-liân Ki-tiûⁿ -台罗拼音 Hua-liân Ki-tiûnn 客家话-客家话拼音 Fa1 lian2  Gi1 cong2 -客语白话字 Fâ-lièn Kî-chhòng "}}} (scraper.py:257)
[2022-03-10 02:02:26] [   DEBUG] [scrapy.core.scraper ] - Scraped from <200 https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6>
{'keyword': '装甲扫雷车', 'source': 'wiki', 'title': '装甲车', 'url': 'https://zh.wikipedia.org/wiki/%E8%A3%85%E7%94%B2%E8%BD%A6', 'date': ' ', 'content': '装甲车辆是具有装甲防护的各种车辆的统称。坦克和自走炮也是广义的重型装甲车辆，但是在习惯上通常因作战用途另外独立分类，而装甲车辆多半是指防护力与火力较坦克弱的车种，而自行炮在原则上不一定要有装甲。装甲车的特性为具有高度的越野机动性能，有一定的防护和火力，分为履带式和轮式两种。一般军用装甲车会装备一至三门中小口径火炮及数挺机枪，一些还装有反坦克导弹，结构以装甲车体、武器系统、动力装置等组成。为了增强防护和方便成员下车战斗。大多数军用装甲车辆可以在水上行驶，可以执行运输、侦察、指挥、救护、伴随、支援坦克及步兵作战等多种任务，还有执行专门任务的装甲车辆，如装甲回收车、装甲指挥车、装甲扫雷车、装甲架桥车等。在警用领域多用于镇压暴乱等问题。步兵战车和装甲输送车作用相近，都是运送步兵机动作战用的装甲车辆，两者不同的地方是步兵战车的防护力较好，火力较大，能够让步兵乘车作战，本身也能够伴随下车作战的步兵，提供火力支援速度较好，装甲输送车则更接近于有装甲的运输车辆。装甲输送车为在战场上输送步兵的装甲车辆，一般具有高速、较低的防护力和战斗力等特点。装甲输送车除了可以运输步兵外，还可以运输物资或补给品，暂时充当装甲补给车。装甲侦察车指装有侦察设备的装甲车辆，速度较快但装甲比其它装甲车辆要薄，多用于战场侦察，一般可分为轮式和履带式两种。较著名的装甲侦察车，有德国的狐式轻型装甲侦察车、山猫装甲侦察车，法国的雷诺VBC90轮式侦察车（英语：VBC-90）等等。装甲指挥车是具有装甲保护的移动指挥站，提供指挥官与支援的参谋和其他人员协调部队的相关事宜。装甲指挥车是早期以卡车或者是拖车为基础的移动指挥所衍生出来的架构，用意在于提供指挥单位快速移动，持续掌握情势与下达命令命且提供一些保护。大部分的装甲指挥车是从装甲输送车改装而成，扩大内部的空间以容纳额外的人员，通讯器材与其他设备。在到达预定指挥地点之后，部分装甲指挥车还有另外设置的顶蓬可以伸出车外，进一步的扩大人员使用的空间。装甲通信车是指装有通信设备的装甲车辆，常见的设计有两种型态，一种是将通信装备与装甲指挥车合并在一起，因此并非单纯的通信车辆。另外一种是做为地面通信的活动中转站，以延伸无线电通信的有效距离，或者是克服地形对通信的遮蔽效应，强化地面单位之间的联络与资讯交换。目前各国陆军很少装备单纯的装甲通信车，不过有不少国家配备由一般运输车辆改装的通信车辆来支援地面部队的通信需求。装甲救护车，指在战场环境下实行人员救护的装甲车辆，一般只装备一至两挺机枪作为自卫武器，防护力亦很弱。主要用于抢救人员，并将重伤员运送至后方。装甲扫雷车特指装有清除地雷装置的装甲车辆，以协助地面部队扩速通过地雷区。装甲扫雷车可以是专门设计用来清除地雷，或者是将清除工具附加在一般用途的坦 克底盘上，无论是车轮或是履带型态的扫雷车都可见于不同国家的部队当中。装甲扫雷车并非用于清除整个被发现的地雷区，而是将地雷区清理出一至数条的安全通道，提供地面部队人员和车辆安全通过。排除的地雷可能在过程中加以引爆，或者是移动到安全的地方之后另外加以处理。由于清理的过程当中，扫雷车可能碰触或者是引爆其他尚未发现的地雷或者是爆裂物，车辆本身对于底盘和车辆底部的保护需要特别加强，以免被地雷或者是爆裂物瘫痪而无法完成清除的任务。装甲架桥车指装有车桥及其架设、撤收装置的装甲车辆，主要用于快速架设桥梁，令部队迅速通过河流，普遍装备于工兵部队。装甲架桥车可由一般坦克或自走炮底盘改装而成，部分会保留机枪作防卫用途。步兵坦 克和装甲输送车 - 当示威活动和抗争会转变成失控的暴乱或群众暴力时，警方有时会出动警用装甲车控制场面。一般具有水炮功能，而车窗经特别制造，不易打碎。各地警方大多都有装甲车，以防范暴乱发生。保安公司常用，用来运载现金或其他贵重物品，又称“解款车”或“运钞车”。另外政要及富豪也会使用经过改装、具有防弹甚至抗炸能力的汽车。', 'attributes': {'装甲车': {}}} (scraper.py:257)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 02:02:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1568,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 49200,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.207933,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 2, 2, 26, 806007),
 'httpcompression/response_bytes': 199808,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 73,
 'memusage/max': 66564096,
 'memusage/startup': 66564096,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 2, 2, 21, 598074)} (statscollectors.py:47)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 02:02:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1586,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 41674,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.132021,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 2, 2, 26, 810369),
 'httpcompression/response_bytes': 155252,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 20,
 'memusage/max': 67805184,
 'memusage/startup': 67805184,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 2, 2, 21, 678348)} (statscollectors.py:47)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 02:02:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 6645,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 429949,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'elapsed_time_seconds': 5.235215,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 2, 2, 26, 814406),
 'httpcompression/response_bytes': 1896597,
 'httpcompression/response_count': 12,
 'item_scraped_count': 11,
 'log_count/DEBUG': 63,
 'log_count/INFO': 93,
 'memusage/max': 66297856,
 'memusage/startup': 66297856,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2022, 3, 10, 2, 2, 21, 579191)} (statscollectors.py:47)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 02:02:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1676,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 44150,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.219202,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 2, 2, 26, 824903),
 'httpcompression/response_bytes': 179734,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 75,
 'memusage/max': 66834432,
 'memusage/startup': 66834432,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 2, 2, 21, 605701)} (statscollectors.py:47)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 02:02:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1604,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 38688,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.174354,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 2, 2, 26, 830913),
 'httpcompression/response_bytes': 140641,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 43,
 'memusage/max': 67538944,
 'memusage/startup': 67538944,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 2, 2, 21, 656559)} (statscollectors.py:47)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 02:02:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1586,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 41250,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.16382,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 2, 2, 26, 832800),
 'httpcompression/response_bytes': 151064,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 39,
 'memusage/max': 67805184,
 'memusage/startup': 67805184,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 2, 2, 21, 668980)} (statscollectors.py:47)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 02:02:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1568,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 51679,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.218546,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 2, 2, 26, 835079),
 'httpcompression/response_bytes': 226328,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 77,
 'memusage/max': 66834432,
 'memusage/startup': 66834432,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 2, 2, 21, 616533)} (statscollectors.py:47)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Closing spider (finished) (engine.py:309)
[2022-03-10 02:02:26] [    INFO] [scrapy.statscollectors ] - Dumping Scrapy stats:
{'downloader/request_bytes': 1586,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 41568,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 5.189998,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 10, 2, 2, 26, 836787),
 'httpcompression/response_bytes': 151557,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 63,
 'log_count/INFO': 59,
 'memusage/max': 67538944,
 'memusage/startup': 67538944,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 10, 2, 2, 21, 646789)} (statscollectors.py:47)
[2022-03-10 02:02:26] [    INFO] [scrapy.core.engine ] - Spider closed (finished) (engine.py:340)
[2022-03-10 02:02:26] [    INFO] [DataCleaning ] - 本次清洗用时：0:00:00.009909 (DataCleaning.py:41)
[2022-03-10 02:02:26] [    INFO] [  __main__ ] - 上传文件：/code/./result/wiki/wiki_装甲救护车_装甲救护车_20220310020226588034.json (MultisiteSchedule.py:276)
[2022-03-10 02:02:26] [   ERROR] [  __main__ ] - 'NoneType' object has no attribute 'upload_file' (MultisiteSchedule.py:291)
Traceback (most recent call last):
  File "MultisiteSchedule.py", line 277, in upload_crawl_file
    connect.upload_file(file, "/text_crawl_file/")
AttributeError: 'NoneType' object has no attribute 'upload_file'
[2022-03-10 02:02:26] [    INFO] [  __main__ ] - upload crawl file failure (MultisiteSchedule.py:395)
[2022-03-10 02:02:26] [    INFO] [  __main__ ] - upload crawl file success (MultisiteSchedule.py:398)
[2022-03-10 02:02:26] [    INFO] [  __main__ ] - scrapy finished (MultisiteSchedule.py:403)
